# REAFME — Описание проекта CTR (Avazu‑style) с акцентом на MLP→LightGBM и RAT→LightGBM

Этот документ — человеческое описание проекта без примеров кода. Он объясняет, как устроен пайплайн для предсказания клика (CTR) на Avazu‑подобных данных, и почему две ключевые связки — «MLP поверх категорий → LightGBM с init_score» и «RAT с контекстом соседей → LightGBM с init_score» — дают сильный прирост качества.

---

## 1) Назначение и общая идея

Проект строит гибридную систему прогнозирования CTR. Нейросетевые блоки (MLP и RAT) выдают «априорный» логит для каждой записи. Деревья решений (LightGBM) принимают этот логит в поле init_score и дообучаются на остаточные закономерности по инженерным признакам. Это позволяет объединить сильные стороны подходов: нейросети лучше схватывают сложные пересечения категорий, а деревья — устойчиво обрабатывают табличные числовые признаки и взаимодействия.

**Вывод:** гибрид «нейросеть + деревья» стабильно сильнее, чем каждый компонент по отдельности.

---

## 2) Формат и предпосылки данных

Сценарий ориентирован на формат данных, близкий к Avazu: есть таблицы train, test и эталонный sample_submission. В train присутствуют поле-класс (click), отметка времени (hour, приводится к часовому штампу), а также категориальные поля высокой и средней кардинальности (например, C15…C21, параметры устройства и позиции баннера) и несколько базовых числовых признаков.

**Вывод:** достаточно стандартной «кликстрим» таблицы с временной осью и категориальными полями.

---

## 3) Валидация по времени

Валидация имитирует онлайн-режим: последний по дате день используется как валидационный, всё более раннее — для обучения и расчёта статистик. Самый первый день обычно исключается из обучения, чтобы корректно накапливать счётчики и сглаженные CTR. Любые агрегаты, статистики и ретривел строятся без заглядывания в будущее.

**Вывод:** строгая временная схема исключает утечки и делает метрику честной.

---

## 4) Инженерия признаков (без кода)

• Временные признаки: день недели, час суток, их компактные циклические представления, а также свёртка индекса «час в неделе».  
• Сглаженные CTR-признаки (out-of-fold во времени): для выбранных категорий формируются частотные оценки, сглаженные байесовским параметром; при этом каждый период видит только прошлые данные.  
• Cumcount/частоты: накапливаем счётчики встречаемости категорий; для будущих периодов используем только то, что уже известно из прошлого.  
• Базовые категориальные поля: тип устройства, тип соединения, позиция баннера и т. п. переводятся в компактные числовые представления для деревьев.

**Вывод:** комбинация сезонности, частот и аккуратных OOF‑оценок даёт устойчивую табличную основу.

---

## 5) Бейзлайн на LightGBM

Базовый бустинг по табличным признакам быстро даёт разумное качество и служит контрольной точкой: он показывает, чего можно добиться без сложных нейросетей. Параметры стартуют консервативно (умеренная глубина/число листьев, субсемплирование признаков и объектов, ранняя остановка). При наличии GPU ускорение приятно, но не обязательно.

**Вывод:** это надёжный ориентир; дальнейшие блоки должны его уверенно превосходить.

---

## 6) Связка MLP → LightGBM (init_score) — подробно

### 6.1. Зачем
Категориальные признаки с высокой кардинальностью и их пересечения трудны для деревьев. Полносвязная сеть с обучаемыми эмбеддингами строит плотные представления категорий и их нелинейных комбинаций, выдавая логит клика. Этот логит передаётся в LightGBM как начальная «вера» модели (init_score), а деревья доучивают остаток по инженерным фичам.

**Вывод:** MLP раскрывает сложные пересечения категорий, LightGBM дополняет и стабилизирует результат.

### 6.2. Что важно в обучении MLP
• Эмбеддинги на каждое категориальное поле; числовые признаки при необходимости подаются как дополнительные входы.  
• Работа с дисбалансом: фиксированная доля позитивов в батче или корректные веса, чтобы сеть не «залипала» на нуле.  
• Калибровка выхода: сеть обучается на логитах (функция потерь для бинарной классификации), на валидации контролируются logloss и AUC.  
• Аккуратная работа с порядком и масками данных: валидационные прогнозы должны соответствовать точным строкам валидации без перемешивания.  
• Экономия ресурсов: при наличии GPU используется смешанная точность; размер батчей подбирается под память.

**Вывод:** стабильность MLP обеспечивается балансировкой, корректной валидацией и бережным расходом памяти.

### 6.3. Передача в LightGBM
Из вероятностей MLP вычисляются логиты (строго избегаем значений 0 и 1), затем эти логиты подаются в init_score как для обучающей, так и для валидационной выборки. Бустинг учится быстрее и часто даёт заметный прирост к базовой метрике.

**Вывод:** правильно подготовленный init_score — это быстрый и бесплатный буст качества.

### 6.4. Типичные проблемы
• Перепутан порядок строк между предсказаниями MLP и наборами LightGBM — приводит к деградации.  
• Поданы вероятности вместо логитов — калибровка нарушается.  
• Недооценка дисбаланса — сеть игнорирует редкие «единицы».  
• Переобучение эмбеддингов — помогает регуляризация, дропаут и ранняя остановка.

**Вывод:** 80% ошибок — организационные, а не алгоритмические.

---

## 7) Связка RAT → LightGBM (init_score) — подробно

### 7.1. Зачем
Даже хороший MLP не знает конкретного локального контекста вокруг события. Retrieval‑Augmented Transformer добавляет для каждой записи несколько релевантных прошлых событий (соседей), на которые модель «смотрит» вниманием. Это позволяет уловить паттерны уровня «похожие показы в похожее время на похожем устройстве уже кликали (или нет)».

**Вывод:** контекст ближайшей истории особенно полезен для редких и холодных комбинаций признаков.

### 7.2. Как формируется контекст
• Для каждой записи ищутся K прошлых соседей: по совпадениям ключевых полей и/или по близости в плотных векторных представлениях.  
• Используются только записи из прошлого, строго исключая будущее относительно целевой строки.  
• Ограничивается число соседей на «частую» комбинацию, чтобы не получить перекос в сторону сверхпопулярных ведер.

**Вывод:** честный и умеренный ретривел — основа качества RAT.

### 7.3. Как устроена модель
• Вход — «пачка токенов»: целевая запись и её K соседей по каждому полю.  
• Два типа внимания чередуются: внутри одного поля по токенам (intra‑field) и между различными полями (cross‑field).  
• После нескольких таких блоков представления агрегируются и превращаются в логит клика.

**Вывод:** модель извлекает закономерности «по соседям» и «между полями», создавая богатый контекстный признак.

### 7.4. Обучение и передача в LightGBM
• Те же принципы честной валидации и аккуратной калибровки, что и у MLP.  
• Логиты RAT переводятся в init_score для LightGBM, который дообучается на табличных признаках.  
• По ресурсам RAT тяжелее MLP; помогает снижение числа соседей, размерности внутренних представлений и аккуратная работа с памятью.

**Вывод:** даже упрощённый RAT даёт ощутимый прирост за счёт контекста, а деревья «дочищают» хвосты.

### 7.5. Типичные проблемы
• Утечка во времени при сборе соседей мгновенно «портит» честность метрики.  
• Слишком много соседей или слишком большие размерности — перерасход памяти и время обучения.  
• Сильные перекосы популярных корзин — требуется отсечение и равномерность.

**Вывод:** ключ к успеху RAT — дисциплина времени и контроль бюджетов.

---

## 8) Производительность и устойчивость

• Оптимальные типы данных, разумные размеры батчей, по возможности использование ускорителей.  
• Предсказания и вычисление init_score — партиями, без попыток держать всё в оперативной памяти.  
• Отдельный контроль калибровки: итоговый ансамбль при необходимости можно докалибровать на валидации.

**Вывод:** грамотное управление ресурсами столь же важно, как и архитектура моделей.

---

## 9) Частые вопросы

• Почему не ограничиться одними деревьями? — Деревьям сложно учесть редкие пересечения категорий; MLP с эмбеддингами это делает лучше.  
• Почему не ограничиться MLP? — На табличных числах и частотах деревья часто устойчивее и дают дополнительный прирост.  
• Для чего нужен init_score? — Чтобы стартовать обучение деревьев с уже информативной «базы», а не с нулевого предположения.

**Вывод:** каждая часть решает «свою» задачу, вместе они работают сильнее.

---

## 10) Куда развивать дальше

• Более насыщенный ретривел: смешивать точные совпадения и поиск по плотным векторным представлениям с помощью специализированных библиотек.  
• Расширение OOF‑feature store: больше полей и скользящих окон, более тонкая регуляризация сглаженных CTR.  
• Финальная калибровка ансамбля: например, изотоническая регрессия по валидации.  
• Добавление альтернативных верхних моделей: помимо LightGBM, можно рассмотреть иные алгоритмы поверх init_score.

**Вывод:** основной потенциальный прирост — в качестве ретривела и богатстве OOF‑статистик.

---

## 11) Итог

Проект демонстрирует практичный ансамбль для CTR: нейросетевые логиты служат «фундаментом», а бустинг по признакам доводит модель до высокого качества. Ключевые блоки — MLP→LightGBM и RAT→LightGBM — комплементарны: первый ловит универсальные нелинейные пересечения категорий, второй добавляет локальный исторический контекст.
