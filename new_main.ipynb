{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Секция \"сабмит\" - это полное решение от загрузки данных до формирования сабмита на хакатоне\n",
    "\n",
    "- Секции \"без сабмита\" - это экспериментальная работа с train, без test, без сабмитов. Там идеи и реализация\n",
    "\n",
    "- Осталное можно не смотреть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Baseline\n",
    "   - Время/календарь: weekday, hour_of_day, hour_week, hod_sin, hod_cos, wkd_sin, wkd_cos\n",
    "   - CTR (time-aware, бета-сглаживание, без утечек): C15, C16, C17, C18, C19, C20, C21 - это  фичи вида Cxx_ctr\n",
    "   - Частотность появлений: cumcount для C15–C21 → фичи Cxx_cumcount\n",
    "   - Базовые категориальные (в модели): banner_pos, device_type, device_conn_type, C1\n",
    "\n",
    "2. SOTA\n",
    "   - Время/календарь: weekday, hour_of_day, hour_week, hod_sin, hod_cos, wkd_sin, wkd_cos\n",
    "   - CTR (time-aware, бета-сглаживание, без утечек): C15–C21, site_category, app_category, banner_pos, C1, device_type, device_conn_type → *_ctr\n",
    "   - OOF-CTR (для низко/средне-кардинальных): site_category, app_category, banner_pos, C1 → *_ctr_oof\n",
    "   - Частотность появления:\n",
    "     1. cumcount для C15–C21\n",
    "     2. дополнительные cumcount для: site_id, site_domain, app_id, app_domain, device_model\n",
    "     3. logcount = log1p(cumcount) для SOLO-колонок это *_logcount\n",
    "   - Базовые категориальные (в модели): banner_pos, device_type, device_conn_type, C1, weekday, hour_of_day (кодировались как каткоды)\n",
    "\n",
    "   - Примечание: recency и кросс-признаки сознательно не добавлялись (ограничения памяти и анти-утечки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## смотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18993</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20362</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17262</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1872</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100173</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23160</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2667</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20969</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2372</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16859</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100194</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22257</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>100084</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ... device_type  \\\n",
       "0           f3845767      28905ebd  ecad2386  ...           1   \n",
       "1           f3845767      28905ebd  ecad2386  ...           1   \n",
       "2           f3845767      28905ebd  ecad2386  ...           1   \n",
       "3           9166c161      0569f928  ecad2386  ...           1   \n",
       "4           25d4cfcd      f028772b  ecad2386  ...           1   \n",
       "...              ...           ...       ...  ...         ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ...           1   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ...           1   \n",
       "40388932    6b59f079      f028772b  ecad2386  ...           1   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ...           1   \n",
       "40388934    f3845767      28905ebd  ecad2386  ...           1   \n",
       "\n",
       "         device_conn_type    C14  C15 C16   C17  C18  C19     C20  C21  \n",
       "0                       2  15706  320  50  1722    0   35      -1   79  \n",
       "1                       0  15704  320  50  1722    0   35  100084   79  \n",
       "2                       0  15704  320  50  1722    0   35  100084   79  \n",
       "3                       0  18993  320  50  2161    0   35      -1  157  \n",
       "4                       0  20362  320  50  2333    0   39      -1  157  \n",
       "...                   ...    ...  ...  ..   ...  ...  ...     ...  ...  \n",
       "40388930                0  17262  320  50  1872    3   39  100173   23  \n",
       "40388931                2  23160  320  50  2667    0   47      -1  221  \n",
       "40388932                0  20969  320  50  2372    0  813      -1   46  \n",
       "40388933                0  16859  320  50  1887    3   39  100194   23  \n",
       "40388934                0  22257  320  50  2545    0  431  100084  221  \n",
       "\n",
       "[40388935 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40388935, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'id', 'click', 'hour', 'C1', 'banner_pos', 'site_id',\n",
       "       'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category',\n",
       "       'device_id', 'device_ip', 'device_model', 'device_type',\n",
       "       'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20',\n",
       "       'C21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                 float64\n",
       "id                  float64\n",
       "click                 int64\n",
       "hour                  int64\n",
       "C1                    int64\n",
       "banner_pos            int64\n",
       "site_id              object\n",
       "site_domain          object\n",
       "site_category        object\n",
       "app_id               object\n",
       "app_domain           object\n",
       "app_category         object\n",
       "device_id            object\n",
       "device_ip            object\n",
       "device_model         object\n",
       "device_type           int64\n",
       "device_conn_type      int64\n",
       "C14                   int64\n",
       "C15                   int64\n",
       "C16                   int64\n",
       "C17                   int64\n",
       "C18                   int64\n",
       "C19                   int64\n",
       "C20                   int64\n",
       "C21                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                 40228967\n",
       "id                         0\n",
       "click                      0\n",
       "hour                       0\n",
       "C1                         0\n",
       "banner_pos                 0\n",
       "site_id                    0\n",
       "site_domain                0\n",
       "site_category              0\n",
       "app_id                     0\n",
       "app_domain                 0\n",
       "app_category               0\n",
       "device_id                  0\n",
       "device_ip                  0\n",
       "device_model               0\n",
       "device_type                0\n",
       "device_conn_type           0\n",
       "C14                        0\n",
       "C15                        0\n",
       "C16                        0\n",
       "C17                        0\n",
       "C18                        0\n",
       "C19                        0\n",
       "C20                        0\n",
       "C21                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click\n",
       "0    33530927\n",
       "1     6858008\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"click\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                   159968\n",
       "id                  40388935\n",
       "click                      2\n",
       "hour                     240\n",
       "C1                         7\n",
       "banner_pos                 7\n",
       "site_id                 4736\n",
       "site_domain             7742\n",
       "site_category             26\n",
       "app_id                  8550\n",
       "app_domain               559\n",
       "app_category              36\n",
       "device_id            2684975\n",
       "device_ip            6725249\n",
       "device_model            8249\n",
       "device_type                5\n",
       "device_conn_type           4\n",
       "C14                     2626\n",
       "C15                        8\n",
       "C16                        9\n",
       "C17                      435\n",
       "C18                        4\n",
       "C19                       68\n",
       "C20                      172\n",
       "C21                       60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hour_dt\"] = pd.to_datetime(train[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "test[\"hour_dt\"]  = pd.to_datetime(test[\"hour\"].astype(str),  format=\"%y%m%d%H\", utc=True)\n",
    "\n",
    "train[\"weekday\"]     = train[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "train[\"hour_of_day\"] = train[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "test[\"weekday\"]      = test[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "test[\"hour_of_day\"]  = test[\"hour_dt\"].dt.hour.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman(hour_of_day, CTR) = -0.230\n",
      "Spearman(weekday, CTR) = 0.571\n"
     ]
    }
   ],
   "source": [
    "for c in [\"hour_of_day\", \"weekday\"]:\n",
    "    if c in train.columns:\n",
    "        g = train.groupby(c)[\"click\"].mean().sort_index()\n",
    "        rho = pd.Series(g.index).corr(pd.Series(g.values), method=\"spearman\")\n",
    "        print(f\"Spearman({c}, CTR) = {rho:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1872</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100173</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2667</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2372</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100194</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>100084</td>\n",
       "      <td>221</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...  C15 C16   C17 C18  C19  \\\n",
       "0           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "1           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "2           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "3           9166c161      0569f928  ecad2386  ...  320  50  2161   0   35   \n",
       "4           25d4cfcd      f028772b  ecad2386  ...  320  50  2333   0   39   \n",
       "...              ...           ...       ...  ...  ...  ..   ...  ..  ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ...  320  50  1872   3   39   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ...  320  50  2667   0   47   \n",
       "40388932    6b59f079      f028772b  ecad2386  ...  320  50  2372   0  813   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ...  320  50  1887   3   39   \n",
       "40388934    f3845767      28905ebd  ecad2386  ...  320  50  2545   0  431   \n",
       "\n",
       "             C20  C21                   hour_dt  weekday  hour_of_day  \n",
       "0             -1   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "1         100084   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "2         100084   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "3             -1  157 2014-10-21 00:00:00+00:00        1            0  \n",
       "4             -1  157 2014-10-21 00:00:00+00:00        1            0  \n",
       "...          ...  ...                       ...      ...          ...  \n",
       "40388930  100173   23 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388931      -1  221 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388932      -1   46 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388933  100194   23 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388934  100084  221 2014-10-30 23:00:00+00:00        3           23  \n",
       "\n",
       "[40388935 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5\n",
    "cols_ctr = [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = train[\"hour_dt\"].dt.date.max()\n",
    "\n",
    "mask_past  = train[\"hour_dt\"].dt.date < last_day\n",
    "mask_valid = train[\"hour_dt\"].dt.date == last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1698596491451188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_global = train.loc[mask_past, \"click\"].mean()\n",
    "p_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...                   hour_dt  \\\n",
       "0           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "1           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "2           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "3           9166c161      0569f928  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "4           25d4cfcd      f028772b  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "...              ...           ...       ...  ...                       ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ... 2014-10-30 23:00:00+00:00   \n",
       "40388932    6b59f079      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ... 2014-10-30 23:00:00+00:00   \n",
       "40388934    f3845767      28905ebd  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "\n",
       "         weekday hour_of_day C15_ctr C16_ctr  C17_ctr  C18_ctr  C19_ctr  \\\n",
       "0              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "1              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "2              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "3              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "4              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "...          ...         ...     ...     ...      ...      ...      ...   \n",
       "40388930       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388931       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388932       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388933       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388934       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "\n",
       "          C20_ctr  C21_ctr  \n",
       "0             NaN      NaN  \n",
       "1             NaN      NaN  \n",
       "2             NaN      NaN  \n",
       "3             NaN      NaN  \n",
       "4             NaN      NaN  \n",
       "...           ...      ...  \n",
       "40388930      NaN      NaN  \n",
       "40388931      NaN      NaN  \n",
       "40388932      NaN      NaN  \n",
       "40388933      NaN      NaN  \n",
       "40388934      NaN      NaN  \n",
       "\n",
       "[40388935 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in cols_ctr:\n",
    "    new_col = f\"{c}_ctr\"\n",
    "    train[new_col] = np.nan\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols_ctr:\n",
    "    past = train.loc[mask_past, [c, \"click\"]]\n",
    "    shows  = past.groupby(c)[\"click\"].count()\n",
    "    clicks = past.groupby(c)[\"click\"].sum()\n",
    "\n",
    "    ctr_raw = clicks / shows\n",
    "    ctr_raw.loc[shows < m] = p_global\n",
    "\n",
    "    new_col = f\"{c}_ctr\"\n",
    "\n",
    "    train.loc[mask_valid, new_col] = train.loc[mask_valid, c].map(ctr_raw.to_dict()).fillna(p_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.302971</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.267409</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.138729</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.164029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.097772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.082037</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.222410</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.252750</td>\n",
       "      <td>0.213928</td>\n",
       "      <td>0.164029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...                   hour_dt  \\\n",
       "0           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "1           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "2           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "3           9166c161      0569f928  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "4           25d4cfcd      f028772b  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "...              ...           ...       ...  ...                       ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ... 2014-10-30 23:00:00+00:00   \n",
       "40388932    6b59f079      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ... 2014-10-30 23:00:00+00:00   \n",
       "40388934    f3845767      28905ebd  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "\n",
       "         weekday hour_of_day   C15_ctr   C16_ctr   C17_ctr   C18_ctr  \\\n",
       "0              1           0       NaN       NaN       NaN       NaN   \n",
       "1              1           0       NaN       NaN       NaN       NaN   \n",
       "2              1           0       NaN       NaN       NaN       NaN   \n",
       "3              1           0       NaN       NaN       NaN       NaN   \n",
       "4              1           0       NaN       NaN       NaN       NaN   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "40388930       3          23  0.158597  0.158331  0.302971  0.148226   \n",
       "40388931       3          23  0.158597  0.158331  0.105378  0.159072   \n",
       "40388932       3          23  0.158597  0.158331  0.114030  0.159072   \n",
       "40388933       3          23  0.158597  0.158331  0.147488  0.148226   \n",
       "40388934       3          23  0.158597  0.158331  0.222410  0.159072   \n",
       "\n",
       "           C19_ctr   C20_ctr   C21_ctr  \n",
       "0              NaN       NaN       NaN  \n",
       "1              NaN       NaN       NaN  \n",
       "2              NaN       NaN       NaN  \n",
       "3              NaN       NaN       NaN  \n",
       "4              NaN       NaN       NaN  \n",
       "...            ...       ...       ...  \n",
       "40388930  0.243136  0.267409  0.211582  \n",
       "40388931  0.138729  0.193124  0.164029  \n",
       "40388932  0.114030  0.193124  0.097772  \n",
       "40388933  0.243136  0.082037  0.211582  \n",
       "40388934  0.252750  0.213928  0.164029  \n",
       "\n",
       "[40388935 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C15_ctr filled: 1.0\n",
      "C16_ctr filled: 1.0\n",
      "C17_ctr filled: 1.0\n",
      "C18_ctr filled: 1.0\n",
      "C19_ctr filled: 1.0\n",
      "C20_ctr filled: 1.0\n",
      "C21_ctr filled: 1.0\n"
     ]
    }
   ],
   "source": [
    "# быстрый контроль: сколько заполнилось в валид-день\n",
    "for c in cols_ctr:\n",
    "    nc = f\"{c}_ctr\"\n",
    "    print(nc, \"filled:\", train.loc[mask_valid, nc].notna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>click</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36169997</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2695</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100019</td>\n",
       "      <td>51</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.166601</td>\n",
       "      <td>0.164256</td>\n",
       "      <td>0.183651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169998</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2695</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100020</td>\n",
       "      <td>51</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.166601</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.183651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169999</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1973</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100148</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.181369</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.234147</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170000</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2227</td>\n",
       "      <td>0</td>\n",
       "      <td>935</td>\n",
       "      <td>-1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.112823</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.119831</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.138517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170001</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2716</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.204518</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.138729</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           hour_dt  click  C15  C16   C17  C18  C19     C20  \\\n",
       "36169997 2014-10-30 00:00:00+00:00      0  320   50  2695    0   35  100019   \n",
       "36169998 2014-10-30 00:00:00+00:00      0  320   50  2695    0   35  100020   \n",
       "36169999 2014-10-30 00:00:00+00:00      0  320   50  1973    3   39  100148   \n",
       "36170000 2014-10-30 00:00:00+00:00      0  320   50  2227    0  935      -1   \n",
       "36170001 2014-10-30 00:00:00+00:00      0  320   50  2716    3   47      -1   \n",
       "\n",
       "          C21   C15_ctr   C16_ctr   C17_ctr   C18_ctr   C19_ctr   C20_ctr  \\\n",
       "36169997   51  0.158597  0.158331  0.114623  0.159072  0.166601  0.164256   \n",
       "36169998   51  0.158597  0.158331  0.114623  0.159072  0.166601  0.072760   \n",
       "36169999   23  0.158597  0.158331  0.181369  0.148226  0.243136  0.234147   \n",
       "36170000   48  0.158597  0.158331  0.112823  0.159072  0.119831  0.193124   \n",
       "36170001   23  0.158597  0.158331  0.204518  0.148226  0.138729  0.193124   \n",
       "\n",
       "           C21_ctr  \n",
       "36169997  0.183651  \n",
       "36169998  0.183651  \n",
       "36169999  0.211582  \n",
       "36170000  0.138517  \n",
       "36170001  0.211582  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[mask_valid, [\"hour_dt\",\"click\"] + cols_ctr + [f\"{c}_ctr\" for c in cols_ctr]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сабмит: SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Обучение (валидация последним днём)...\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid's auc: 0.693136\n",
      "[200]\tvalid's auc: 0.694732\n",
      "[300]\tvalid's auc: 0.696154\n",
      "[400]\tvalid's auc: 0.698204\n",
      "[500]\tvalid's auc: 0.700364\n",
      "[600]\tvalid's auc: 0.701686\n",
      "[700]\tvalid's auc: 0.701683\n",
      "[800]\tvalid's auc: 0.701823\n",
      "[900]\tvalid's auc: 0.702071\n",
      "[1000]\tvalid's auc: 0.701895\n",
      "Early stopping, best iteration is:\n",
      "[885]\tvalid's auc: 0.702134\n",
      "Evaluated only: auc\n",
      "Best iteration: 885\n",
      "===> Финальное обучение на всём train (train+valid)...\n",
      "===> Предсказания...\n",
      "Сохранено: submission.csv\n",
      "Готово за 1509.4 c\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            mn, mx = df[col].min(), df[col].max()\n",
    "            if mn >= 0:\n",
    "                if mx < 2**8:    df[col] = df[col].astype(\"uint8\")\n",
    "                elif mx < 2**16: df[col] = df[col].astype(\"uint16\")\n",
    "                elif mx < 2**32: df[col] = df[col].astype(\"uint32\")\n",
    "                else:            df[col] = df[col].astype(\"uint64\")\n",
    "            else:\n",
    "                if   -2**7  <= mn < 2**7:   df[col] = df[col].astype(\"int8\")\n",
    "                elif -2**15 <= mn < 2**15:  df[col] = df[col].astype(\"int16\")\n",
    "                elif -2**31 <= mn < 2**31:  df[col] = df[col].astype(\"int32\")\n",
    "                else:                        df[col] = df[col].astype(\"int64\")\n",
    "    return df\n",
    "\n",
    "def create_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"hour_dt\"]    = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "    df[\"weekday\"]    = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "    df[\"hour_of_day\"]= df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "    df[\"hour_week\"]  = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "    df[\"hod_sin\"]    = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "    df[\"hod_cos\"]    = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "    df[\"wkd_sin\"]    = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "    df[\"wkd_cos\"]    = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "def time_aware_ctr_for_train(train: pd.DataFrame, cols: list, alpha: float=10.0):\n",
    "    dates = np.sort(train[\"hour_dt\"].dt.date.unique())\n",
    "    p_gl  = float(train[\"click\"].mean())\n",
    "    outnames=[]\n",
    "    for col in cols:\n",
    "        out=f\"{col}_ctr\"; train[out]=np.nan; outnames.append(out)\n",
    "    for i,d in enumerate(dates):\n",
    "        if i==0: continue\n",
    "        m_day  = (train[\"hour_dt\"].dt.date == d)\n",
    "        m_prev = (train[\"hour_dt\"].dt.date <  d)\n",
    "        prior  = float(train.loc[m_prev, \"click\"].mean()) if m_prev.any() else p_gl\n",
    "        for col in cols:\n",
    "            stats  = train.loc[m_prev, [col,\"click\"]].groupby(col, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "            smooth = (stats[\"sum\"] + alpha*prior) / (stats[\"count\"] + alpha)\n",
    "            train.loc[m_day, f\"{col}_ctr\"] = train.loc[m_day, col].map(smooth.to_dict()).fillna(prior).astype(\"float32\")\n",
    "    for col in cols:\n",
    "        train[f\"{col}_ctr\"] = train[f\"{col}_ctr\"].fillna(p_gl).astype(\"float32\")\n",
    "    return outnames\n",
    "\n",
    "def ctr_map_from_full_train(train: pd.DataFrame, cols: list, alpha: float=10.0):\n",
    "    p = float(train[\"click\"].mean()); maps={}\n",
    "    for col in cols:\n",
    "        agg = train.groupby(col, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        maps[col] = ((agg[\"sum\"] + alpha*p) / (agg[\"count\"] + alpha)).astype(\"float32\").to_dict()\n",
    "    return maps, p\n",
    "\n",
    "def apply_ctr_map(df: pd.DataFrame, maps: dict, default_ctr: float):\n",
    "    for col, mp in maps.items():\n",
    "        out=f\"{col}_ctr\"\n",
    "        df[out] = df[col].map(mp).fillna(default_ctr).astype(\"float32\")\n",
    "\n",
    "def add_oof_ctr_train_only(train_df: pd.DataFrame, col: str, dates_sorted, mask_past, mask_valid, alpha=5.0):\n",
    "    out=f\"{col}_ctr_oof\"; train_df[out]=np.nan\n",
    "    p_gl = float(train_df.loc[mask_past,\"click\"].mean())\n",
    "    agg  = train_df.loc[mask_past,[col,\"click\"]].groupby(col)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    ctr_valid = (agg[\"sum\"] + alpha*p_gl)/(agg[\"count\"] + alpha)\n",
    "    train_df.loc[mask_valid, out] = train_df.loc[mask_valid, col].map(ctr_valid.to_dict()).fillna(p_gl)\n",
    "    for i,d in enumerate(dates_sorted):\n",
    "        if i==0: continue\n",
    "        m_day  = (train_df[\"hour_dt\"].dt.date == d)\n",
    "        m_prev = (train_df[\"hour_dt\"].dt.date <  d)\n",
    "        p_prev = float(train_df.loc[m_prev,\"click\"].mean())\n",
    "        agg_p  = train_df.loc[m_prev,[col,\"click\"]].groupby(col)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        ctr_p  = (agg_p[\"sum\"] + alpha*p_prev)/(agg_p[\"count\"] + alpha)\n",
    "        train_df.loc[m_day,out] = train_df.loc[m_day,col].map(ctr_p.to_dict()).fillna(p_prev)\n",
    "    train_df[out] = train_df[out].astype(\"float32\"); return out\n",
    "\n",
    "def cumcount_train_and_test_map(train_df: pd.DataFrame, test_df: pd.DataFrame, col: str, time_col=\"hour_dt\"):\n",
    "    tmp = train_df[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = train_df.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False).cumcount().astype(\"int32\")\n",
    "    out = f\"{col}_cumcount\"\n",
    "    train_df[out] = 0\n",
    "    train_df.loc[tmp[\"_idx\"].values, out] = cc.values\n",
    "    train_df[out] = train_df[out].astype(\"float32\")\n",
    "    freq_map = train_df.groupby(col, observed=True).size().astype(\"int32\").to_dict()\n",
    "    test_df[out] = test_df[col].map(freq_map).fillna(0).astype(\"float32\")\n",
    "    del tmp, cc, freq_map; gc.collect()\n",
    "    return out\n",
    "\n",
    "def encode_cats_threeway(tr_df, va_df, te_df, cols):\n",
    "    code_cols=[]\n",
    "    for c in cols:\n",
    "        tr_cat = tr_df[c].astype(\"category\"); va_cat = va_df[c].astype(\"category\"); te_cat = te_df[c].astype(\"category\")\n",
    "        cats = tr_cat.cat.categories.union(va_cat.cat.categories).union(te_cat.cat.categories)\n",
    "        tr_df[f\"{c}__code\"] = tr_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        va_df[f\"{c}__code\"] = va_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        te_df[f\"{c}__code\"] = te_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        code_cols.append(f\"{c}__code\")\n",
    "    return code_cols\n",
    "\n",
    "def main():\n",
    "    t0 = time.perf_counter()\n",
    "    train  = pd.read_csv(\"train.csv\")\n",
    "    test   = pd.read_csv(\"test.csv\")\n",
    "    sample = pd.read_csv(\"sample_submission.csv\")\n",
    "    if \"idx\" not in sample.columns:\n",
    "        raise ValueError(\"В sample_submission.csv нет колонки 'idx'.\")\n",
    "\n",
    "    # Время/календарь\n",
    "    train = create_time_features(train)\n",
    "    test  = create_time_features(test)\n",
    "\n",
    "    # Даты/маски\n",
    "    dates_sorted = np.sort(train[\"hour_dt\"].dt.date.unique())\n",
    "    if len(dates_sorted) < 2:\n",
    "        raise ValueError(\"Нужно >=2 уникальных дат в train.\")\n",
    "    last_day  = dates_sorted[-1]\n",
    "    first_day = dates_sorted[0]\n",
    "    mask_valid = (train[\"hour_dt\"].dt.date == last_day)\n",
    "    mask_train = (train[\"hour_dt\"].dt.date < last_day) & (train[\"hour_dt\"].dt.date != first_day)\n",
    "    mask_past  = (train[\"hour_dt\"].dt.date < last_day)\n",
    "\n",
    "    # CTR: time-aware (train) + map (test)\n",
    "    ctr_cols = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\",\n",
    "                            \"device_type\",\"device_conn_type\",\n",
    "                            \"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in train.columns]\n",
    "    ctr_cols_created = time_aware_ctr_for_train(train, ctr_cols, alpha=10.0)\n",
    "    ctr_maps, default_ctr = ctr_map_from_full_train(train, ctr_cols, alpha=10.0)\n",
    "    apply_ctr_map(test, ctr_maps, default_ctr)\n",
    "\n",
    "    # OOF-CTR только для low-card\n",
    "    low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in train.columns]\n",
    "    ctr_low_cols=[]\n",
    "    for c in low_card_for_ctr:\n",
    "        ctr_low_cols.append(add_oof_ctr_train_only(train, c, dates_sorted, mask_past, mask_valid, alpha=5.0))\n",
    "    maps_low, def_low = ctr_map_from_full_train(train, low_card_for_ctr, alpha=5.0)\n",
    "    for col, mp in maps_low.items():\n",
    "        out = f\"{col}_ctr_oof\"\n",
    "        test[out] = test[col].map(mp).fillna(def_low).astype(\"float32\")\n",
    "\n",
    "    # Cumcount ТОЛЬКО для C15–C21: train честный, test = train_count map\n",
    "    cumcount_cols=[]\n",
    "    for c in [x for x in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if x in train.columns]:\n",
    "        cumcount_cols.append(cumcount_train_and_test_map(train, test, c))\n",
    "\n",
    "    # Признаки\n",
    "    base_cats = [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\",\"weekday\",\"hour_of_day\"]\n",
    "    base_cats = [c for c in base_cats if c in train.columns and c in test.columns]\n",
    "    time_num_cols = [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]\n",
    "    time_num_cols = [c for c in time_num_cols if c in train.columns]\n",
    "\n",
    "    num_cols = time_num_cols + cumcount_cols + ctr_low_cols + ctr_cols_created\n",
    "\n",
    "    cols_for_tr = base_cats + num_cols + [\"click\"]\n",
    "    cols_for_te = [c for c in base_cats + num_cols if c in test.columns]\n",
    "\n",
    "    mask_drop_first = (train[\"hour_dt\"].dt.date == first_day)\n",
    "    train_df = train.loc[mask_train & ~mask_drop_first, cols_for_tr].copy()\n",
    "    valid_df = train.loc[mask_valid,                          cols_for_tr].copy()\n",
    "    test_df  = test[cols_for_te].copy()\n",
    "\n",
    "    train_df = optimize_dtypes(train_df); valid_df = optimize_dtypes(valid_df); test_df = optimize_dtypes(test_df)\n",
    "    for df in (train_df, valid_df, test_df):\n",
    "        for c in num_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(\"float32\", copy=False)\n",
    "\n",
    "    cat_code_cols = encode_cats_threeway(train_df, valid_df, test_df, base_cats)\n",
    "\n",
    "    X_tr = pd.concat([train_df[cat_code_cols], train_df[num_cols]], axis=1)\n",
    "    X_va = pd.concat([valid_df[cat_code_cols], valid_df[num_cols]], axis=1)\n",
    "    X_te = pd.concat([test_df[cat_code_cols],  test_df[num_cols]],  axis=1)\n",
    "    y_tr = train_df[\"click\"].astype(np.uint8).values\n",
    "    y_va = valid_df[\"click\"].astype(np.uint8).values\n",
    "\n",
    "    cat_idx = list(range(len(cat_code_cols)))\n",
    "\n",
    "    del train, test, train_df, valid_df, test_df\n",
    "    gc.collect()\n",
    "\n",
    "    lgb_params = dict(\n",
    "        objective=\"binary\", metric=\"auc\",\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=256,             \n",
    "        max_depth=-1,\n",
    "        min_data_in_leaf=50,        \n",
    "        lambda_l2=2.0,              \n",
    "        feature_fraction=0.75,\n",
    "        bagging_fraction=0.8, bagging_freq=1,\n",
    "        max_bin=255,\n",
    "        device_type=\"cuda\", gpu_device_id=0,\n",
    "        seed=42, verbosity=-1, num_threads=-1\n",
    "    )\n",
    "\n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_idx, free_raw_data=True)\n",
    "    dvalid = lgb.Dataset(X_va, label=y_va, categorical_feature=cat_idx, reference=dtrain, free_raw_data=True)\n",
    "\n",
    "    print(\"===> Обучение (валидация последним днём)...\")\n",
    "    cb = [lgb.early_stopping(stopping_rounds=75, first_metric_only=True),\n",
    "          lgb.log_evaluation(period=100)]\n",
    "    bst = lgb.train(lgb_params, dtrain, num_boost_round=700,\n",
    "                    valid_sets=[dvalid], valid_names=[\"valid\"], callbacks=cb)\n",
    "    best_iter = bst.best_iteration or bst.current_iteration()\n",
    "    print(f\"Best iteration: {best_iter}\")\n",
    "\n",
    "    # Финальное обучение (OOM-safe, GPU→CPU fallback)\n",
    "    print(\"===> Финальное обучение на всём train (train+valid)...\")\n",
    "    try:\n",
    "        X_full = pd.concat([X_tr, X_va], axis=0, ignore_index=True)\n",
    "        y_full = np.concatenate([y_tr, y_va])\n",
    "        del dtrain, dvalid, X_tr, X_va, y_tr, y_va, bst\n",
    "        gc.collect()\n",
    "        dfull = lgb.Dataset(X_full, label=y_full, categorical_feature=cat_idx, free_raw_data=True)\n",
    "        try:\n",
    "            bst_full = lgb.train(lgb_params, dfull, num_boost_round=best_iter)\n",
    "        except Exception as e:\n",
    "            print(\"GPU OOM, fallback CPU:\", repr(e))\n",
    "            lgb_params_cpu = {**lgb_params, \"device_type\": \"cpu\"}\n",
    "            bst_full = lgb.train(lgb_params_cpu, dfull, num_boost_round=best_iter)\n",
    "        del dfull, X_full, y_full\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(\"Не удалось собрать full train, используем модель с валидации:\", repr(e))\n",
    "        bst_full = bst\n",
    "\n",
    "    print(\"===> Предсказания...\")\n",
    "    test_pred = bst_full.predict(X_te, num_iteration=best_iter).astype(\"float32\")\n",
    "\n",
    "    test_idx = pd.read_csv(\"test.csv\", usecols=[\"idx\"]) if os.path.exists(\"test.csv\") else None\n",
    "    if test_idx is not None and len(test_idx)==len(test_pred):\n",
    "        pred_df = pd.DataFrame({\"idx\": test_idx[\"idx\"].values, \"click\": test_pred})\n",
    "        submit = sample[[\"idx\"]].merge(pred_df, on=\"idx\", how=\"left\")\n",
    "    else:\n",
    "        submit = pd.DataFrame({\"idx\": sample[\"idx\"].values, \"click\": test_pred})\n",
    "\n",
    "    if submit[\"click\"].isna().any():\n",
    "        submit[\"click\"] = submit[\"click\"].fillna(float(submit[\"click\"].mean()))\n",
    "\n",
    "    submit.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Сохранено: submission.csv\")\n",
    "    print(f\"Готово за {time.perf_counter()-t0:.1f} c\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сабмит: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5432663, number of negative: 26654371\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.399629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 589\n",
      "[LightGBM] [Info] Number of data points in the train set: 32087034, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.169310 -> initscore=-1.590524\n",
      "[LightGBM] [Info] Start training from score -1.590524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.42877\n",
      "[100]\tvalid_0's binary_logloss: 0.428194\n",
      "[150]\tvalid_0's binary_logloss: 0.427182\n",
      "[200]\tvalid_0's binary_logloss: 0.426687\n",
      "[250]\tvalid_0's binary_logloss: 0.426539\n",
      "[300]\tvalid_0's binary_logloss: 0.427236\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's binary_logloss: 0.426025\n",
      "LightGBM обучался 430.57 c, best_iter = 225\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    # \"device\": \"gpu\",\n",
    "}\n",
    "\n",
    "lgb_tr = lgb.Dataset(X_tr, label=y_tr, free_raw_data=False)\n",
    "lgb_va = lgb.Dataset(X_va, label=y_va, reference=lgb_tr, free_raw_data=False)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_tr,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_va],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(50)]\n",
    ")\n",
    "print(f\"LightGBM обучался {time.perf_counter()-t0:.2f} c, best_iter =\", model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM VAL logloss: 0.426025\n",
      "LightGBM VAL ROC-AUC: 0.672475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "p_va_lgb = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "print(\"LightGBM VAL logloss:\", f\"{log_loss(y_va, p_va_lgb):.6f}\")\n",
    "print(\"LightGBM VAL ROC-AUC:\", f\"{roc_auc_score(y_va, p_va_lgb):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP + lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/lgbm_cuda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch import amp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "torch.backends.cudnn.benchmark = True \n",
    "t0 = time.perf_counter()\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# =========================\n",
    "# Время/календарь\n",
    "# =========================\n",
    "df[\"hour_dt\"]     = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "df[\"weekday\"]     = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "df[\"hour_of_day\"] = df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "df[\"hour_week\"]   = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "df[\"hod_sin\"]     = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"hod_cos\"]     = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"wkd_sin\"]     = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "df[\"wkd_cos\"]     = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "\n",
    "# =========================\n",
    "# Временной сплит: valid = последний день\n",
    "# =========================\n",
    "dates = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "if len(dates) < 2:\n",
    "    raise ValueError(\"Нужно >= 2 уникальных дат для валидации.\")\n",
    "last_day = dates[-1]\n",
    "first_day = dates[0]\n",
    "mask_val = (df[\"hour_dt\"].dt.date == last_day)\n",
    "mask_trn = ~mask_val\n",
    "mask_drop_first = (df[\"hour_dt\"].dt.date == first_day)\n",
    "\n",
    "y = df[\"click\"].astype(np.uint8).values\n",
    "y_tr = y[mask_trn & ~mask_drop_first]\n",
    "y_va = y[mask_val]\n",
    "\n",
    "# =========================\n",
    "# CTR (time-aware, бета-сглаживание)\n",
    "# =========================\n",
    "alpha_ctr = 5.0\n",
    "cols_ctr = [c for c in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in df.columns]\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = np.nan\n",
    "\n",
    "p_global_all  = df.loc[mask_trn, \"click\"].mean()\n",
    "p_global_past = df.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "\n",
    "# валидный день\n",
    "for c in cols_ctr:\n",
    "    past = df.loc[mask_trn & ~mask_drop_first, [c, \"click\"]]\n",
    "    agg = past.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    smooth = (agg[\"sum\"] + alpha_ctr*p_global_past) / (agg[\"count\"] + alpha_ctr)\n",
    "    df.loc[mask_val, f\"{c}_ctr\"] = df.loc[mask_val, c].map(smooth.to_dict()).fillna(p_global_past)\n",
    "\n",
    "# прошлые дни\n",
    "dates_sorted = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "for i, d in enumerate(dates_sorted):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    mask_day  = (df[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "    mask_prev = (df[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "    if not mask_day.any():\n",
    "        continue\n",
    "    p_prev = df.loc[mask_prev, \"click\"].mean()\n",
    "    for c in cols_ctr:\n",
    "        prev = df.loc[mask_prev, [c, \"click\"]]\n",
    "        agg  = prev.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        smooth = (agg[\"sum\"] + alpha_ctr*p_prev) / (agg[\"count\"] + alpha_ctr)\n",
    "        df.loc[mask_day, f\"{c}_ctr\"] = df.loc[mask_day, c].map(smooth.to_dict()).fillna(p_prev)\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = df[f\"{c}_ctr\"].fillna(p_global_all).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Cumcount (train only) + logcount\n",
    "# =========================\n",
    "def cumcount_train_only(df_in, col, time_col=\"hour_dt\"):\n",
    "    tmp = df_in[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = df_in.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False, observed=True).cumcount().astype(\"int32\")\n",
    "    out = np.zeros(len(df_in), dtype=np.float32)\n",
    "    out[tmp[\"_idx\"].values] = cc.values\n",
    "    del tmp, cc\n",
    "    gc.collect()\n",
    "    return out\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_cumcount\"] = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "\n",
    "solo_high = [c for c in [\"site_id\",\"site_domain\",\"app_id\",\"app_domain\",\"device_model\"] if c in df.columns]\n",
    "for c in solo_high:\n",
    "    cc = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "    df[f\"{c}_cumcount\"] = cc\n",
    "    df[f\"{c}_logcount\"] = np.log1p(cc).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# OOF-CTR low-card (time-aware)\n",
    "# =========================\n",
    "def add_oof_ctr_train_only(df_in, col, alpha=5.0):\n",
    "    out_col = f\"{col}_ctr_oof\"\n",
    "    df_in[out_col] = np.nan\n",
    "\n",
    "    past = df_in.loc[mask_trn & ~mask_drop_first, [col, \"click\"]]\n",
    "    agg  = past.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "    p_gl = df_in.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "    ctr_map_valid = (agg[\"sum\"] + alpha * p_gl) / (agg[\"count\"] + alpha)\n",
    "    df_in.loc[mask_val, out_col] = df_in.loc[mask_val, col].map(ctr_map_valid.to_dict()).fillna(p_gl)\n",
    "\n",
    "    for i, d in enumerate(dates_sorted):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        mask_day  = (df_in[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "        mask_prev = (df_in[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "        if not mask_day.any():\n",
    "            continue\n",
    "        p_prev = df_in.loc[mask_prev, \"click\"].mean()\n",
    "        prev = df_in.loc[mask_prev, [col, \"click\"]]\n",
    "        agg_prev = prev.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "        ctr_map = (agg_prev[\"sum\"] + alpha * p_prev) / (agg_prev[\"count\"] + alpha)\n",
    "        df_in.loc[mask_day, out_col] = df_in.loc[mask_day, col].map(ctr_map.to_dict()).fillna(p_prev)\n",
    "\n",
    "    df_in[out_col] = df_in[out_col].astype(\"float32\", copy=False)\n",
    "    gc.collect()\n",
    "    return out_col\n",
    "\n",
    "low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in df.columns]\n",
    "ctr_low_cols = [add_oof_ctr_train_only(df, c, alpha=5.0) for c in low_card_for_ctr]\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Финальный список фич\n",
    "# =========================\n",
    "base_cat_cols = [c for c in [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\"] if c in df.columns]\n",
    "time_num_cols = [c for c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"] if c in df.columns]\n",
    "\n",
    "num_cols = []\n",
    "num_cols += [f\"{c}_ctr\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in solo_high]\n",
    "num_cols += [f\"{c}_logcount\"  for c in solo_high]\n",
    "num_cols += ctr_low_cols\n",
    "num_cols += time_num_cols\n",
    "\n",
    "# =========================\n",
    "# Санитация числовых фич — никаких NaN\n",
    "# =========================\n",
    "def sanitize_numeric_features(df_whole: pd.DataFrame, cols: list, default_ctr: float):\n",
    "    for c in cols:\n",
    "        if c.endswith(\"_ctr\") or c.endswith(\"_ctr_oof\"):\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(default_ctr)\n",
    "        elif c.endswith(\"_cumcount\") or c.endswith(\"_logcount\") or c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "        else:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "\n",
    "sanitize_numeric_features(df, num_cols, default_ctr=p_global_all)\n",
    "assert not df[num_cols].isna().any().any(), \"NaN в числовых фичах после санитации\"\n",
    "\n",
    "# маски\n",
    "use_mask_tr = mask_trn & ~mask_drop_first\n",
    "use_mask_va = mask_val\n",
    "\n",
    "# =========================\n",
    "# Фреймы для LGBM (категории кодами + numeric)\n",
    "# =========================\n",
    "train_df = pd.DataFrame(index=df.index[use_mask_tr])\n",
    "valid_df = pd.DataFrame(index=df.index[use_mask_va])\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    codes = df[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
    "    train_df[c] = codes[use_mask_tr].values\n",
    "    valid_df[c] = codes[use_mask_va].values\n",
    "cat_indices = [train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    train_df[c] = df.loc[use_mask_tr, c].astype(\"float32\").values\n",
    "    valid_df[c] = df.loc[use_mask_va, c].astype(\"float32\").values\n",
    "\n",
    "y_tr = df.loc[use_mask_tr, \"click\"].astype(np.uint8).values\n",
    "y_va = df.loc[use_mask_va, \"click\"].astype(np.uint8).values\n",
    "\n",
    "# =========================\n",
    "# Подготовка данных для MLP\n",
    "# =========================\n",
    "emb_cols_all = [\"site_id\",\"app_id\",\"device_model\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]\n",
    "emb_cols = [c for c in emb_cols_all if c in df.columns]\n",
    "\n",
    "id_mappings = {}\n",
    "for c in emb_cols:\n",
    "    cats = pd.Series(df.loc[use_mask_tr, c].astype(str).unique())\n",
    "    id_mappings[c] = {cat: i+1 for i, cat in enumerate(cats)}\n",
    "\n",
    "emb_arrays_full = {}\n",
    "for c in emb_cols:\n",
    "    emb_arrays_full[c] = df[c].astype(str).map(id_mappings[c]).fillna(0).astype(\"int64\").values\n",
    "\n",
    "# Числовые фичи для MLP\n",
    "num_cols_mlp = []\n",
    "for c in num_cols:\n",
    "    if c.endswith(\"_cumcount\"):\n",
    "        base = c[:-9]  \n",
    "        logc = f\"{base}_logcount\"\n",
    "        if logc in df.columns:\n",
    "            if logc not in num_cols_mlp:\n",
    "                num_cols_mlp.append(logc)\n",
    "        else:\n",
    "            tmp_col = f\"{c}__log1p_tmp\"\n",
    "            df[tmp_col] = np.log1p(df[c]).astype(\"float32\")\n",
    "            num_cols_mlp.append(tmp_col)\n",
    "    else:\n",
    "        if c not in num_cols_mlp:\n",
    "            num_cols_mlp.append(c)\n",
    "\n",
    "# Массивы для MLP\n",
    "X_num_full = df[num_cols_mlp].astype(\"float32\").values\n",
    "emb_tr = [emb_arrays_full[c][use_mask_tr] for c in emb_cols]\n",
    "emb_va = [emb_arrays_full[c][use_mask_va] for c in emb_cols]\n",
    "X_num_tr = X_num_full[use_mask_tr]\n",
    "X_num_va = X_num_full[use_mask_va]\n",
    "\n",
    "assert not np.isnan(X_num_tr).any(), \"NaN в X_num_tr\"\n",
    "assert not np.isnan(X_num_va).any(), \"NaN в X_num_va\"\n",
    "\n",
    "emb_sizes = []\n",
    "for c in emb_cols:\n",
    "    n_tok = len(id_mappings[c]) + 1\n",
    "    dim = int(min(32, max(4, round(n_tok**0.25 * 8))))\n",
    "    emb_sizes.append((n_tok, dim))\n",
    "\n",
    "# =========================\n",
    "# Torch Dataset + BalancedBatchSampler + OneCycleLR + AMP\n",
    "# =========================\n",
    "class CTRDataset(Dataset):\n",
    "    def __init__(self, emb_arrays, num_array, y=None):\n",
    "        self.emb_arrays = emb_arrays\n",
    "        self.num_array = num_array\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.num_array.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        cats = [torch.tensor(a[idx], dtype=torch.long) for a in self.emb_arrays]\n",
    "        nums = torch.tensor(self.num_array[idx], dtype=torch.float32)\n",
    "        if self.y is None:\n",
    "            return cats, nums\n",
    "        else:\n",
    "            return cats, nums, torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, y_array, batch_size, pos_frac, num_batches, seed=42):\n",
    "        self.y = y_array\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pos_bs = max(1, int(round(batch_size * pos_frac)))\n",
    "        self.neg_bs = self.batch_size - self.pos_bs\n",
    "        self.num_batches = int(num_batches)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.pos_idx = np.where(self.y == 1)[0]\n",
    "        self.neg_idx = np.where(self.y == 0)[0]\n",
    "        if len(self.pos_idx) == 0 or len(self.neg_idx) == 0:\n",
    "            raise ValueError(\"Нет положительных или отрицательных примеров.\")\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            pos = self.rng.choice(self.pos_idx, size=self.pos_bs, replace=True)\n",
    "            neg = self.rng.choice(self.neg_idx, size=self.neg_bs, replace=True)\n",
    "            idx = np.concatenate([pos, neg])\n",
    "            self.rng.shuffle(idx)\n",
    "            yield idx.tolist()\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "tr_dataset = CTRDataset(emb_tr, X_num_tr, y_tr)\n",
    "va_dataset = CTRDataset(emb_va, X_num_va, y_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [train]: 100%|██████████| 306/306 [01:13<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 1 train loss: 0.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [valid]: 100%|██████████| 129/129 [01:39<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 1  Val AUC: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [train]: 100%|██████████| 306/306 [01:11<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 2 train loss: 0.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [valid]: 100%|██████████| 129/129 [01:32<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 2  Val AUC: 0.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [train]: 100%|██████████| 306/306 [01:10<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 3 train loss: 0.4927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [valid]: 100%|██████████| 129/129 [01:36<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 3  Val AUC: 0.7290\n"
     ]
    }
   ],
   "source": [
    "target_pos_frac = 0.25\n",
    "bs_train = 16384\n",
    "\n",
    "epoch_samples = min(len(y_tr), 5_000_000)\n",
    "num_batches = math.ceil(epoch_samples / bs_train)\n",
    "\n",
    "balanced_sampler = BalancedBatchSampler(y_tr, batch_size=bs_train, pos_frac=target_pos_frac, num_batches=num_batches)\n",
    "tr_loader = DataLoader(tr_dataset, batch_sampler=balanced_sampler,\n",
    "                       num_workers=4, prefetch_factor=1, pin_memory=True, persistent_workers=True)\n",
    "va_loader = DataLoader(va_dataset, batch_size=32768, shuffle=False,\n",
    "                       num_workers=2, prefetch_factor=1, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# =========================\n",
    "# Модель MLP\n",
    "# =========================\n",
    "class MLPEmbModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, num_dim, hidden_dims=[128,64], dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(n, d) for n, d in emb_sizes])\n",
    "        emb_total = sum(d for _, d in emb_sizes)\n",
    "        in_dim = emb_total + num_dim\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(last, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            last = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.out = nn.Linear(last, 1)\n",
    "    def forward(self, cats, nums):\n",
    "        if len(self.emb_layers) > 0:\n",
    "            emb_outs = [emb(c) for emb, c in zip(self.emb_layers, cats)]\n",
    "            x = torch.cat(emb_outs + [nums], dim=1)\n",
    "        else:\n",
    "            x = nums\n",
    "        h = self.mlp(x) if len(self.mlp) > 0 else x\n",
    "        logit = self.out(h)\n",
    "        return logit, h\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPEmbModel(emb_sizes=emb_sizes, num_dim=X_num_tr.shape[1], hidden_dims=[128,64], dropout=0.2).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "total_steps = num_epochs * len(tr_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, total_steps=total_steps,\n",
    "    pct_start=0.1, div_factor=10, final_div_factor=100\n",
    ")\n",
    "scaler = amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))\n",
    "\n",
    "# =========================\n",
    "# Обучение MLP (AMP + clip grad + OneCycleLR)\n",
    "# =========================\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for cats, nums, tgt in tqdm(tr_loader, desc=f\"Epoch {ep}/{num_epochs} [train]\"):\n",
    "        cats = [c.to(device, non_blocking=True) for c in cats]\n",
    "        nums = nums.to(device, non_blocking=True)\n",
    "        tgt  = tgt.to(device, non_blocking=True).view(-1,1).float()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logit, _ = model(cats, nums)\n",
    "        loss = criterion(logit.float(), tgt)\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            continue\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running += float(loss.detach().cpu())\n",
    "\n",
    "    print(f\"[MLP] Epoch {ep} train loss: {running/max(1,len(tr_loader)):.4f}\")\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_preds, val_tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for cats, nums, tgt in tqdm(va_loader, desc=f\"Epoch {ep}/{num_epochs} [valid]\"):\n",
    "            cats = [c.to(device, non_blocking=True) for c in cats]\n",
    "            nums = nums.to(device, non_blocking=True)\n",
    "            with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                logit, _ = model(cats, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            val_preds.append(prob.cpu().numpy())\n",
    "            val_tgts.append(tgt.numpy())\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_tgts  = np.concatenate(val_tgts)\n",
    "    if np.isnan(val_preds).any():\n",
    "        val_preds = np.nan_to_num(val_preds, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "    va_auc = roc_auc_score(val_tgts, val_preds)\n",
    "    print(f\"[MLP] Epoch {ep}  Val AUC: {va_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract MLP probs: 100%|██████████| 1959/1959 [18:03<00:00,  1.81it/s]\n",
      "Extract MLP probs: 100%|██████████| 258/258 [02:32<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Final Val AUC = 0.7290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Извлекаем вероятности MLP (экономно по памяти)\n",
    "# =========================\n",
    "from torch import amp\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def extract_probs(ds, model, device, bs=16384):\n",
    "    dl = DataLoader(\n",
    "        ds,\n",
    "        batch_size=bs,\n",
    "        shuffle=False,\n",
    "        num_workers=0,          \n",
    "        pin_memory=False,     \n",
    "        prefetch_factor=None,   \n",
    "        persistent_workers=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    n = len(ds)\n",
    "    out = np.empty(n, dtype=np.float16) \n",
    "    idx = 0\n",
    "    with torch.inference_mode():       \n",
    "        for cats, nums in tqdm(dl, desc=\"Extract MLP probs\"):\n",
    "            bsz = nums.shape[0]\n",
    "            cats = [c.to(device, non_blocking=False) for c in cats]\n",
    "            nums = nums.to(device, non_blocking=False)\n",
    "            with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                logit, _ = model(cats, nums)\n",
    "            prob = torch.sigmoid(logit).squeeze(1)\n",
    "\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            out[idx:idx+bsz] = prob.detach().cpu().to(torch.float16).numpy()\n",
    "            idx += bsz\n",
    "\n",
    "    # небольшая уборка\n",
    "    del dl\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return out\n",
    "\n",
    "# инференс вероятностей\n",
    "tr_infer_ds = CTRDataset(emb_tr, X_num_tr, None)\n",
    "va_infer_ds = CTRDataset(emb_va, X_num_va, None)\n",
    "tr_probs = extract_probs(tr_infer_ds, model, device, bs=16384)   \n",
    "va_probs = extract_probs(va_infer_ds, model, device, bs=16384)\n",
    "\n",
    "mlp_val_auc = roc_auc_score(y_va, va_probs.astype(np.float32))\n",
    "print(f\"[MLP] Final Val AUC = {mlp_val_auc:.4f}\")\n",
    "\n",
    "del tr_loader, va_loader, tr_dataset, va_dataset, tr_infer_ds, va_infer_ds\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Training on GPU with init_score (memory-friendly)...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's auc: 0.731453\n",
      "[200]\tvalid's auc: 0.732525\n",
      "[300]\tvalid's auc: 0.732944\n",
      "[400]\tvalid's auc: 0.733358\n",
      "[500]\tvalid's auc: 0.733622\n",
      "[600]\tvalid's auc: 0.73369\n",
      "[700]\tvalid's auc: 0.73363\n",
      "[800]\tvalid's auc: 0.733819\n",
      "[900]\tvalid's auc: 0.733763\n",
      "Early stopping, best iteration is:\n",
      "[784]\tvalid's auc: 0.733855\n",
      "Evaluated only: auc\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# LGBM с init_score от MLP\n",
    "# =========================\n",
    "\n",
    "safe_ctr = [c for c in train_df.columns if c.endswith(\"_ctr\") and not c.endswith(\"_ctr_oof\")]\n",
    "oof_ctr  = [c for c in train_df.columns if c.endswith(\"_ctr_oof\")]\n",
    "logcnt   = [c for c in train_df.columns if c.endswith(\"_logcount\")]\n",
    "time_num_present = [c for c in time_num_cols if c in train_df.columns]\n",
    "\n",
    "num_cols_lgb = safe_ctr + oof_ctr + logcnt + time_num_present\n",
    "num_cols_lgb = [c for c in num_cols_lgb if not c.endswith(\"_cumcount\")]\n",
    "\n",
    "lgb_train_df = pd.DataFrame(index=train_df.index)\n",
    "lgb_valid_df = pd.DataFrame(index=valid_df.index)\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"int32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"int32\")\n",
    "cat_indices = [lgb_train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols_lgb:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"float32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"float32\")\n",
    "\n",
    "def probs_to_logit(p):\n",
    "    p = np.asarray(p, dtype=np.float32)\n",
    "    p = np.clip(p, 1e-6, 1-1e-6)\n",
    "    return np.log(p/(1-p)).astype(np.float32)\n",
    "\n",
    "tr_logit = probs_to_logit(tr_probs)\n",
    "va_logit = probs_to_logit(va_probs)\n",
    "\n",
    "del train_df, valid_df\n",
    "gc.collect()\n",
    "\n",
    "dtrain = lgb.Dataset(lgb_train_df, label=y_tr,\n",
    "                     categorical_feature=cat_indices, free_raw_data=True)\n",
    "dvalid = lgb.Dataset(lgb_valid_df, label=y_va,\n",
    "                     categorical_feature=cat_indices, reference=dtrain, free_raw_data=True)\n",
    "\n",
    "dtrain.set_init_score(tr_logit)\n",
    "dvalid.set_init_score(va_logit)\n",
    "\n",
    "del lgb_train_df, lgb_valid_df, tr_logit, va_logit\n",
    "gc.collect()\n",
    "\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=255,\n",
    "    max_depth=-1,\n",
    "    min_data_in_leaf=50,\n",
    "    feature_fraction=0.70,\n",
    "    bagging_fraction=0.70,\n",
    "    bagging_freq=1,\n",
    "    lambda_l2=1.0,\n",
    "    max_bin=63, \n",
    "    bin_construct_sample_cnt=100000,\n",
    "    device_type=\"cuda\",\n",
    "    gpu_device_id=0,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "print(\"[LGBM] Training on GPU with init_score (memory-friendly)...\")\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=200, first_metric_only=True),\n",
    "    lgb.log_evaluation(period=100),\n",
    "]\n",
    "\n",
    "booster = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dvalid],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/lgbm_cuda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc, time, math\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch import amp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from scipy.special import expit \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "torch.backends.cudnn.benchmark = True\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# =========================\n",
    "# Время/календарь\n",
    "# =========================\n",
    "df[\"hour_dt\"]     = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "df[\"weekday\"]     = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "df[\"hour_of_day\"] = df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "df[\"hour_week\"]   = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "df[\"hod_sin\"]     = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"hod_cos\"]     = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"wkd_sin\"]     = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "df[\"wkd_cos\"]     = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "\n",
    "# =========================\n",
    "# Временной сплит: valid = последний день\n",
    "# =========================\n",
    "dates = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "if len(dates) < 2:\n",
    "    raise ValueError(\"Нужно >= 2 уникальных дат для валидации.\")\n",
    "last_day  = dates[-1]\n",
    "first_day = dates[0]\n",
    "mask_val = (df[\"hour_dt\"].dt.date == last_day)\n",
    "mask_trn = ~mask_val\n",
    "mask_drop_first = (df[\"hour_dt\"].dt.date == first_day)\n",
    "\n",
    "y = df[\"click\"].astype(np.uint8).values\n",
    "y_tr = y[mask_trn & ~mask_drop_first]\n",
    "y_va = y[mask_val]\n",
    "\n",
    "# =========================\n",
    "# CTR (time-aware, бета-сглаживание)\n",
    "# =========================\n",
    "alpha_ctr = 5.0\n",
    "cols_ctr = [c for c in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in df.columns]\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = np.nan\n",
    "\n",
    "p_global_all  = df.loc[mask_trn, \"click\"].mean()\n",
    "p_global_past = df.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "\n",
    "# валидный день\n",
    "for c in cols_ctr:\n",
    "    past = df.loc[mask_trn & ~mask_drop_first, [c, \"click\"]]\n",
    "    agg = past.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    smooth = (agg[\"sum\"] + alpha_ctr*p_global_past) / (agg[\"count\"] + alpha_ctr)\n",
    "    df.loc[mask_val, f\"{c}_ctr\"] = df.loc[mask_val, c].map(smooth.to_dict()).fillna(p_global_past)\n",
    "\n",
    "# прошлые дни\n",
    "dates_sorted = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "for i, d in enumerate(dates_sorted):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    mask_day  = (df[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "    mask_prev = (df[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "    if not mask_day.any():\n",
    "        continue\n",
    "    p_prev = df.loc[mask_prev, \"click\"].mean()\n",
    "    for c in cols_ctr:\n",
    "        prev = df.loc[mask_prev, [c, \"click\"]]\n",
    "        agg  = prev.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        smooth = (agg[\"sum\"] + alpha_ctr*p_prev) / (agg[\"count\"] + alpha_ctr)\n",
    "        df.loc[mask_day, f\"{c}_ctr\"] = df.loc[mask_day, c].map(smooth.to_dict()).fillna(p_prev)\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = df[f\"{c}_ctr\"] .fillna(p_global_all).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Cumcount (train only) + logcount\n",
    "# =========================\n",
    "def cumcount_train_only(df_in, col, time_col=\"hour_dt\"):\n",
    "    tmp = df_in[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = df_in.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False, observed=True).cumcount().astype(\"int32\")\n",
    "    out = np.zeros(len(df_in), dtype=np.float32)\n",
    "    out[tmp[\"_idx\"].values] = cc.values\n",
    "    del tmp, cc\n",
    "    gc.collect()\n",
    "    return out\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_cumcount\"] = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "\n",
    "solo_high = [c for c in [\"site_id\",\"site_domain\",\"app_id\",\"app_domain\",\"device_model\"] if c in df.columns]\n",
    "for c in solo_high:\n",
    "    cc = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "    df[f\"{c}_cumcount\"] = cc\n",
    "    df[f\"{c}_logcount\"] = np.log1p(cc).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# OOF-CTR low-card (time-aware)\n",
    "# =========================\n",
    "def add_oof_ctr_train_only(df_in, col, alpha=5.0):\n",
    "    out_col = f\"{col}_ctr_oof\"\n",
    "    df_in[out_col] = np.nan\n",
    "\n",
    "    past = df_in.loc[mask_trn & ~mask_drop_first, [col, \"click\"]]\n",
    "    agg  = past.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "    p_gl = df_in.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "    ctr_map_valid = (agg[\"sum\"] + alpha * p_gl) / (agg[\"count\"] + alpha)\n",
    "    df_in.loc[mask_val, out_col] = df_in.loc[mask_val, col].map(ctr_map_valid.to_dict()).fillna(p_gl)\n",
    "\n",
    "    for i, d in enumerate(dates_sorted):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        mask_day  = (df_in[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "        mask_prev = (df_in[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "        if not mask_day.any():\n",
    "            continue\n",
    "        p_prev = df_in.loc[mask_prev, \"click\"].mean()   \n",
    "        prev = df_in.loc[mask_prev, [col, \"click\"]]\n",
    "        agg_prev = prev.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "        ctr_map = (agg_prev[\"sum\"] + alpha * p_prev) / (agg_prev[\"count\"] + alpha)\n",
    "        df_in.loc[mask_day, out_col] = df_in.loc[mask_day, col].map(ctr_map.to_dict()).fillna(p_prev)\n",
    "\n",
    "    df_in[out_col] = df_in[out_col].astype(\"float32\", copy=False)\n",
    "    gc.collect()\n",
    "    return out_col\n",
    "\n",
    "low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in df.columns]\n",
    "ctr_low_cols = [add_oof_ctr_train_only(df, c, alpha=5.0) for c in low_card_for_ctr]\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Финальный список фич\n",
    "# =========================\n",
    "base_cat_cols = [c for c in [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\"] if c in df.columns]\n",
    "time_num_cols = [c for c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"] if c in df.columns]\n",
    "\n",
    "num_cols = []\n",
    "num_cols += [f\"{c}_ctr\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in solo_high]\n",
    "num_cols += [f\"{c}_logcount\"  for c in solo_high]\n",
    "num_cols += ctr_low_cols\n",
    "num_cols += time_num_cols\n",
    "\n",
    "# =========================\n",
    "# Санитация числовых фич — никаких NaN\n",
    "# =========================\n",
    "def sanitize_numeric_features(df_whole: pd.DataFrame, cols: list, default_ctr: float):\n",
    "    for c in cols:\n",
    "        if c.endswith(\"_ctr\") or c.endswith(\"_ctr_oof\"):\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(default_ctr)\n",
    "        elif c.endswith(\"_cumcount\") or c.endswith(\"_logcount\") or c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "        else:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "\n",
    "sanitize_numeric_features(df, num_cols, default_ctr=p_global_all)\n",
    "assert not df[num_cols].isna().any().any(), \"NaN в числовых фичах после санитации\"\n",
    "\n",
    "# маски\n",
    "use_mask_tr = mask_trn & ~mask_drop_first\n",
    "use_mask_va = mask_val\n",
    "\n",
    "# =========================\n",
    "# Фреймы для LGBM (категории кодами + numeric)\n",
    "# =========================\n",
    "train_df = pd.DataFrame(index=df.index[use_mask_tr])\n",
    "valid_df = pd.DataFrame(index=df.index[use_mask_va])\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    codes = df[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
    "    train_df[c] = codes[use_mask_tr].values\n",
    "    valid_df[c] = codes[use_mask_va].values\n",
    "cat_indices = [train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    train_df[c] = df.loc[use_mask_tr, c].astype(\"float32\").values\n",
    "    valid_df[c] = df.loc[use_mask_va, c].astype(\"float32\").values\n",
    "\n",
    "y_tr = df.loc[use_mask_tr, \"click\"].astype(np.uint8).values\n",
    "y_va = df.loc[use_mask_va, \"click\"].astype(np.uint8).values\n",
    "\n",
    "# =========================\n",
    "# Подготовка данных для эмбеддингов \n",
    "# =========================\n",
    "emb_cols_all = [\"site_id\",\"app_id\",\"device_model\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]\n",
    "emb_cols = [c for c in emb_cols_all if c in df.columns]\n",
    "\n",
    "emb_arrays_full = {}\n",
    "n_tokens_per_col = {}\n",
    "for c in emb_cols:\n",
    "    train_cats = pd.Categorical(df.loc[use_mask_tr, c]).categories\n",
    "    cat_all = pd.Categorical(df[c], categories=train_cats)\n",
    "\n",
    "    codes_i32 = cat_all.codes.astype(np.int32, copy=False)  \n",
    "    codes_i32 += 1                                      \n",
    "    emb_arrays_full[c] = codes_i32.astype(np.uint32, copy=False)\n",
    "\n",
    "    n_tokens_per_col[c] = len(train_cats) + 1 \n",
    "\n",
    "\n",
    "num_cols_mlp = []\n",
    "_seen = set()\n",
    "for c in num_cols:\n",
    "    if c.endswith(\"_cumcount\"):\n",
    "        base = c[:-9]\n",
    "        logc = f\"{base}_logcount\"\n",
    "        key = logc if logc in df.columns else c\n",
    "    else:\n",
    "        key = c\n",
    "    if key not in _seen:\n",
    "        num_cols_mlp.append(key)\n",
    "        _seen.add(key)\n",
    "\n",
    "def _col_values_for(mask: pd.Series, col: str) -> np.ndarray:\n",
    "    if col.endswith(\"_cumcount\") and f\"{col[:-9]}_logcount\" not in df.columns:\n",
    "        return np.log1p(df.loc[mask, col].to_numpy(dtype=np.float32, copy=False))\n",
    "    else:\n",
    "        return df.loc[mask, col].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "tr_cols, va_cols = [], []\n",
    "for col in num_cols_mlp:\n",
    "    tr_cols.append(_col_values_for(use_mask_tr, col).reshape(-1, 1))\n",
    "    va_cols.append(_col_values_for(use_mask_va, col).reshape(-1, 1))\n",
    "\n",
    "X_num_tr = (np.concatenate(tr_cols, axis=1).astype(np.float16, copy=False)\n",
    "            if tr_cols else np.zeros((use_mask_tr.sum(), 0), np.float16))\n",
    "X_num_va = (np.concatenate(va_cols, axis=1).astype(np.float16, copy=False)\n",
    "            if va_cols else np.zeros((use_mask_va.sum(), 0), np.float16))\n",
    "\n",
    "emb_tr = [emb_arrays_full[c][use_mask_tr] for c in emb_cols]\n",
    "emb_va = [emb_arrays_full[c][use_mask_va] for c in emb_cols]\n",
    "\n",
    "assert not np.isnan(X_num_tr).any(), \"NaN в X_num_tr\"\n",
    "assert not np.isnan(X_num_va).any(), \"NaN в X_num_va\"\n",
    "\n",
    "emb_sizes = []\n",
    "for c in emb_cols:\n",
    "    n_tok = n_tokens_per_col[c]\n",
    "    dim = int(min(32, max(4, round(n_tok**0.25 * 8))))\n",
    "    emb_sizes.append((n_tok, dim))\n",
    "\n",
    "_df_keep = [\"hour_dt\"] + emb_cols\n",
    "_drop = [c for c in list(df.columns) if c not in _df_keep]\n",
    "if _drop:\n",
    "    df.drop(columns=_drop, inplace=True)\n",
    "\n",
    "del tr_cols, va_cols, _seen\n",
    "gc.collect()\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    if str(train_df[c].dtype).startswith(\"int\") and train_df[c].dtype.itemsize > 2:\n",
    "        train_df[c] = train_df[c].astype(\"int16\")\n",
    "        valid_df[c] = valid_df[c].astype(\"int16\")\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RAT: Retrieval-Augmented Transformer\n",
    "# =========================\n",
    "RAT_K = 4\n",
    "RAT_MAX_PER_TOKEN = 256\n",
    "RAT_D_MODEL = 32\n",
    "RAT_NUM_BLOCKS = 2\n",
    "RAT_NUM_HEADS = 4\n",
    "RAT_DROPOUT = 0.1\n",
    "\n",
    "def _value_counts_map(series: pd.Series) -> dict:\n",
    "    vc = series.value_counts(dropna=False)\n",
    "    return {k: int(v) for k, v in vc.items()}\n",
    "\n",
    "# =========================\n",
    "# БЫСТРАЯ версия ретрива (векторизованная)\n",
    "# =========================\n",
    "def build_retrieval_indices_fast(\n",
    "    df_time_values,\n",
    "    emb_arrays_full: dict[str, np.ndarray],\n",
    "    emb_cols: list[str],\n",
    "    use_mask_tr: pd.Series,\n",
    "    use_mask_va: pd.Series,\n",
    "    K: int = 4,\n",
    "    max_per_token: int = 256,\n",
    "    top_fields: int | None = 3,\n",
    "):\n",
    "    pos = np.arange(df_time_values.shape[0])\n",
    "    pos_tr = pos[use_mask_tr.values]\n",
    "    pos_va = pos[use_mask_va.values]\n",
    "\n",
    "    t_tr = df_time_values[pos_tr].view(\"int64\")\n",
    "    order_tr = np.lexsort((pos_tr, t_tr))\n",
    "    pos_tr_sorted = pos_tr[order_tr]\n",
    "    n_tr = len(pos_tr_sorted)\n",
    "    n_va = len(pos_va)\n",
    "    if n_tr == 0:\n",
    "        return np.empty((0, K), dtype=np.int32), np.empty((n_va, K), dtype=np.int32)\n",
    "\n",
    "    codes_tr = {c: emb_arrays_full[c][use_mask_tr.values][order_tr].astype(np.int32, copy=False) for c in emb_cols}\n",
    "    codes_va = {c: emb_arrays_full[c][use_mask_va.values].astype(np.int32, copy=False) for c in emb_cols}\n",
    "\n",
    "    N = float(n_tr)\n",
    "    idf_map = {}\n",
    "    for c in emb_cols:\n",
    "        x = codes_tr[c]\n",
    "        if x.size == 0:\n",
    "            idf_map[c] = np.zeros(1, dtype=np.float32)\n",
    "            continue\n",
    "        vmax = int(x.max())\n",
    "        cnt = np.bincount(x, minlength=vmax + 1).astype(np.int32)\n",
    "        idf = np.zeros_like(cnt, dtype=np.float32)\n",
    "        nonzero = cnt > 0\n",
    "        idf[nonzero] = np.log((N - cnt[nonzero] + 0.5) / (cnt[nonzero] + 0.5)).astype(np.float32)\n",
    "        idf_map[c] = idf\n",
    "\n",
    "    from collections import deque, defaultdict\n",
    "    inv_train = {c: defaultdict(lambda: deque(maxlen=max_per_token)) for c in emb_cols}\n",
    "    inv_full  = {c: defaultdict(lambda: deque(maxlen=max_per_token)) for c in emb_cols}\n",
    "    for i in range(n_tr):\n",
    "        for c in emb_cols:\n",
    "            inv_full[c][int(codes_tr[c][i])].append(i)\n",
    "\n",
    "    retr_tr_idx = np.full((n_tr, K), -1, dtype=np.int32)\n",
    "    retr_va_idx = np.full((n_va, K), -1, dtype=np.int32)\n",
    "\n",
    "    scores = np.zeros(n_tr, dtype=np.float32)\n",
    "\n",
    "    def _pick_topk_from_touched(touched_arr):\n",
    "        if touched_arr.size == 0:\n",
    "            return []\n",
    "        s = scores[touched_arr]\n",
    "        if s.size <= K:\n",
    "            order = np.argsort(s)[::-1]\n",
    "            return touched_arr[order].tolist()\n",
    "        idxk = np.argpartition(s, -K)[-K:]\n",
    "        order = np.argsort(s[idxk])[::-1]\n",
    "        return touched_arr[idxk[order]].tolist()\n",
    "\n",
    "    def _select_cols_for_row(codes_row: dict[str, int]):\n",
    "        if top_fields is None or top_fields >= len(emb_cols):\n",
    "            return emb_cols\n",
    "        pairs = []\n",
    "        for c in emb_cols:\n",
    "            code = int(codes_row[c])\n",
    "            idf = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            pairs.append((c, idf))\n",
    "        pairs.sort(key=lambda t: t[1], reverse=True)\n",
    "        return [c for c, _ in pairs[:top_fields]]\n",
    "\n",
    "    # TRAIN: только ранее виденные\n",
    "    for i in range(n_tr):\n",
    "        touched_chunks = []\n",
    "        cols_use = _select_cols_for_row({c: codes_tr[c][i] for c in emb_cols})\n",
    "        for c in cols_use:\n",
    "            code = int(codes_tr[c][i])\n",
    "            lst = inv_train[c][code]\n",
    "            if not lst:\n",
    "                continue\n",
    "            w = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            if w == 0.0:\n",
    "                continue\n",
    "            arr = np.fromiter(lst, dtype=np.int32)\n",
    "            scores[arr] += w\n",
    "            touched_chunks.append(arr)\n",
    "        if touched_chunks:\n",
    "            touched = np.unique(np.concatenate(touched_chunks))\n",
    "            top = _pick_topk_from_touched(touched)\n",
    "            if top:\n",
    "                retr_tr_idx[i, :len(top)] = top[:K]\n",
    "            scores[touched] = 0.0\n",
    "        for c in emb_cols:\n",
    "            inv_train[c][int(codes_tr[c][i])].append(i)\n",
    "\n",
    "    for j in range(n_va):\n",
    "        touched_chunks = []\n",
    "        cols_use = _select_cols_for_row({c: codes_va[c][j] for c in emb_cols})\n",
    "        for c in cols_use:\n",
    "            code = int(codes_va[c][j])\n",
    "            lst = inv_full[c][code]\n",
    "            if not lst:\n",
    "                continue\n",
    "            w = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            if w == 0.0:\n",
    "                continue\n",
    "            arr = np.fromiter(lst, dtype=np.int32)\n",
    "            scores[arr] += w\n",
    "            touched_chunks.append(arr)\n",
    "        if touched_chunks:\n",
    "            touched = np.unique(np.concatenate(touched_chunks))\n",
    "            top = _pick_topk_from_touched(touched)\n",
    "            if top:\n",
    "                retr_va_idx[j, :len(top)] = top[:K]\n",
    "            scores[touched] = 0.0\n",
    "\n",
    "    return retr_tr_idx, retr_va_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_tr_idx, retr_va_idx = build_retrieval_indices_fast(\n",
    "    df_time_values=df[\"hour_dt\"].values,\n",
    "    emb_arrays_full=emb_arrays_full,\n",
    "    emb_cols=emb_cols,\n",
    "    use_mask_tr=use_mask_tr,\n",
    "    use_mask_va=use_mask_va,\n",
    "    K=RAT_K,\n",
    "    max_per_token=RAT_MAX_PER_TOKEN,\n",
    "    top_fields=3,\n",
    ")\n",
    "\n",
    "pos = np.arange(len(df))\n",
    "pos_tr = pos[use_mask_tr.values]\n",
    "t_tr = df[\"hour_dt\"].values[pos_tr].view(\"int64\")\n",
    "order_tr = np.lexsort((pos_tr, t_tr))\n",
    "\n",
    "def _remap_sorted_to_mask(retr_idx_sorted: np.ndarray, order_tr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Переводит индексы из пространства [0..n_tr) 'time-sorted' в индексы по маске train (исходный порядок).\"\"\"\n",
    "    out = np.full_like(retr_idx_sorted, -1)\n",
    "    m = retr_idx_sorted >= 0\n",
    "    out[m] = order_tr[retr_idx_sorted[m]]\n",
    "    return out\n",
    "\n",
    "retr_tr_idx_mask = _remap_sorted_to_mask(retr_tr_idx, order_tr)\n",
    "retr_va_idx_mask = _remap_sorted_to_mask(retr_va_idx, order_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53 min on local maschine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CTRDatasetRAT(Dataset):\n",
    "    def __init__(self, emb_target, emb_pool, num_target, y_target, retr_idx, pool_labels):\n",
    "        self.emb_target  = emb_target\n",
    "        self.emb_pool    = emb_pool\n",
    "        self.num_target  = num_target\n",
    "        self.y_target    = y_target\n",
    "        self.retr_idx    = retr_idx\n",
    "        self.pool_labels = pool_labels\n",
    "        self.F = len(emb_target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_target.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        K = self.retr_idx.shape[1]\n",
    "        cats_all = np.zeros((K+1, self.F), dtype=np.int64)\n",
    "        for f in range(self.F):\n",
    "            cats_all[0, f] = int(self.emb_target[f][idx])\n",
    "\n",
    "        retr = self.retr_idx[idx]\n",
    "        valid = (retr >= 0)\n",
    "        if valid.any():\n",
    "            rpos = np.where(valid)[0]\n",
    "            rids = retr[valid]\n",
    "            for f in range(self.F):\n",
    "                tmp = cats_all[1:, f]\n",
    "                tmp[rpos] = self.emb_pool[f][rids]\n",
    "                cats_all[1:, f] = tmp\n",
    "\n",
    "        labs_all = np.full(K+1, 2, dtype=np.int64) \n",
    "        if valid.any():\n",
    "            labs_all[1:][valid] = self.pool_labels[retr[valid]].astype(np.int64)\n",
    "\n",
    "        nums = self.num_target[idx].astype(np.float32)\n",
    "\n",
    "        if self.y_target is None:\n",
    "            return cats_all, labs_all, nums\n",
    "        else:\n",
    "            y = float(self.y_target[idx])\n",
    "            return cats_all, labs_all, nums, y\n",
    "\n",
    "\n",
    "def rat_collate_train(batch):\n",
    "    cats, labs, nums, y = zip(*batch)\n",
    "    return (\n",
    "        torch.tensor(np.stack(cats), dtype=torch.long),\n",
    "        torch.tensor(np.stack(labs), dtype=torch.long),\n",
    "        torch.tensor(np.stack(nums), dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32).view(-1, 1),\n",
    "    )\n",
    "\n",
    "def rat_collate_infer(batch):\n",
    "    cats, labs, nums = zip(*batch)\n",
    "    return (\n",
    "        torch.tensor(np.stack(cats), dtype=torch.long),\n",
    "        torch.tensor(np.stack(labs), dtype=torch.long),\n",
    "        torch.tensor(np.stack(nums), dtype=torch.float32),\n",
    "    )\n",
    "\n",
    "\n",
    "class RatBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ln3 = nn.LayerNorm(d_model)\n",
    "        self.mha_intra = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.mha_cross = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        B, Ks, Fp, D = x.shape\n",
    "        h1 = self.ln1(x).reshape(B * Ks, Fp, D)\n",
    "        a1, _ = self.mha_intra(h1, h1, h1)\n",
    "        x = x + a1.reshape(B, Ks, Fp, D)\n",
    "\n",
    "        h2 = self.ln2(x).permute(0, 2, 1, 3).reshape(B * Fp, Ks, D)\n",
    "        a2, _ = self.mha_cross(h2, h2, h2)\n",
    "        x = x + a2.reshape(B, Fp, Ks, D).permute(0, 2, 1, 3)\n",
    "\n",
    "        x = x + self.ff(self.ln3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class RATModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, d_model, n_blocks, n_heads, d_ff=128, dropout=0.1, num_dim=0):\n",
    "        super().__init__()\n",
    "        self.F = len(emb_sizes)\n",
    "        self.embs = nn.ModuleList([nn.Embedding(n, d) for (n, d) in emb_sizes])\n",
    "        self.projs = nn.ModuleList([\n",
    "            nn.Identity() if d == d_model else nn.Linear(d, d_model, bias=False)\n",
    "            for (_, d) in emb_sizes\n",
    "        ])\n",
    "        self.label_emb = nn.Embedding(3, d_model)\n",
    "        self.blocks = nn.ModuleList([RatBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_blocks)])\n",
    "        self.num_proj = nn.Identity() if num_dim == 0 else nn.Sequential(\n",
    "            nn.Linear(num_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model * (2 if num_dim > 0 else 1), d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, cats_all, label_ids, nums=None):\n",
    "        B, Ks, F = cats_all.shape\n",
    "        feats = []\n",
    "        for f in range(self.F):\n",
    "            e = self.embs[f](cats_all[:, :, f]) \n",
    "            e = self.projs[f](e)                 \n",
    "            feats.append(e.unsqueeze(2))           \n",
    "        feat_stack = torch.cat(feats, dim=2)   \n",
    "        lab = self.label_emb(label_ids).unsqueeze(2) \n",
    "        x = torch.cat([lab, feat_stack], dim=2)     \n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        pooled = x[:, 0, 0, :]                    \n",
    "        if nums is not None and nums.numel() > 0:\n",
    "            pooled = torch.cat([pooled, self.num_proj(nums)], dim=1)\n",
    "        return self.head(pooled)                   \n",
    "\n",
    "\n",
    "# Балансировщик батчей\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, y_array, batch_size, pos_frac, num_batches, seed=42):\n",
    "        self.y = y_array\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pos_bs = max(1, int(round(batch_size * pos_frac)))\n",
    "        self.neg_bs = self.batch_size - self.pos_bs\n",
    "        self.num_batches = int(num_batches)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.pos_idx = np.where(self.y == 1)[0]\n",
    "        self.neg_idx = np.where(self.y == 0)[0]\n",
    "        if len(self.pos_idx) == 0 or len(self.neg_idx) == 0:\n",
    "            raise ValueError(\"Нет положительных или отрицательных примеров.\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            pos = self.rng.choice(self.pos_idx, size=self.pos_bs, replace=True)\n",
    "            neg = self.rng.choice(self.neg_idx, size=self.neg_bs, replace=True)\n",
    "            idx = np.concatenate([pos, neg])\n",
    "            self.rng.shuffle(idx)\n",
    "            yield idx.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "\n",
    "\n",
    "tr_dataset = CTRDatasetRAT(emb_tr, emb_tr, X_num_tr, y_tr, retr_tr_idx_mask, y_tr)\n",
    "va_dataset = CTRDatasetRAT(emb_va, emb_tr, X_num_va, y_va, retr_va_idx_mask, y_tr)\n",
    "\n",
    "target_pos_frac = 0.25\n",
    "bs_train = 4096                   \n",
    "epoch_samples = min(len(y_tr), 5_000_000)\n",
    "num_batches = math.ceil(epoch_samples / bs_train)\n",
    "\n",
    "balanced_sampler = BalancedBatchSampler(\n",
    "    y_tr, batch_size=bs_train, pos_frac=target_pos_frac, num_batches=num_batches\n",
    ")\n",
    "\n",
    "tr_loader = DataLoader(\n",
    "    tr_dataset, batch_sampler=balanced_sampler,\n",
    "    num_workers=0, pin_memory=False, collate_fn=rat_collate_train\n",
    ")\n",
    "\n",
    "va_loader = DataLoader(\n",
    "    va_dataset, batch_size=16384, shuffle=False,\n",
    "    num_workers=0, pin_memory=False, collate_fn=rat_collate_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RATModel(\n",
    "    emb_sizes=emb_sizes, d_model=RAT_D_MODEL, n_blocks=RAT_NUM_BLOCKS,\n",
    "    n_heads=RAT_NUM_HEADS, d_ff=128, dropout=RAT_DROPOUT, num_dim=X_num_tr.shape[1]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    model = model.half()\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "target_effective_bs = 8192\n",
    "accum_steps = max(1, target_effective_bs // bs_train)\n",
    "\n",
    "total_steps = (num_epochs * len(tr_loader) + accum_steps - 1) // accum_steps\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, total_steps=total_steps,\n",
    "    pct_start=0.1, div_factor=10, final_div_factor=100\n",
    ")\n",
    "\n",
    "scaler = amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [train]:   0%|          | 1/1221 [00:01<29:25,  1.45s/it]/home/misha/lgbm_cuda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "Epoch 1/3 [train]: 100%|██████████| 1221/1221 [06:20<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 1 train loss: 0.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [valid]: 100%|██████████| 258/258 [02:41<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 1  Val AUC: 0.7237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [train]: 100%|██████████| 1221/1221 [07:20<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 2 train loss: 0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [valid]: 100%|██████████| 258/258 [02:54<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 2  Val AUC: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [train]: 100%|██████████| 1221/1221 [04:30<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 3 train loss: 0.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [valid]: 100%|██████████| 258/258 [02:23<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 3  Val AUC: 0.7280\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Обучение RAT \n",
    "# =========================\n",
    "\n",
    "model = model.to(device).float()\n",
    "\n",
    "_non_fp32 = []\n",
    "for n, p in model.named_parameters():\n",
    "    if p.is_floating_point() and p.dtype != torch.float32:\n",
    "        _non_fp32.append((f\"param:{n}\", str(p.dtype)))\n",
    "for n, b in model.named_buffers():\n",
    "    if b.is_floating_point() and b.dtype != torch.float32:\n",
    "        _non_fp32.append((f\"buffer:{n}\", str(b.dtype)))\n",
    "if _non_fp32:\n",
    "    print(\"WARN: upcasting non-FP32 tensors:\", _non_fp32)\n",
    "\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    scaler = amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "steps_per_epoch_eff = math.ceil(len(tr_loader) / max(1, accum_steps))\n",
    "try:\n",
    "    del scheduler\n",
    "except NameError:\n",
    "    pass\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch_eff,\n",
    "    pct_start=0.1,\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=100.0,\n",
    ")\n",
    "\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    step_accum = 0\n",
    "    opt_steps_done = 0\n",
    "\n",
    "    for it, (cats_all, labs_all, nums, tgt) in enumerate(\n",
    "        tqdm(tr_loader, desc=f\"Epoch {ep}/{num_epochs} [train]\"), start=1\n",
    "    ):\n",
    "        cats_all = cats_all.to(device, non_blocking=True)\n",
    "        labs_all = labs_all.to(device, non_blocking=True)\n",
    "        nums     = nums.to(device, non_blocking=True)\n",
    "        tgt      = tgt.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logit = model(cats_all, labs_all, nums)\n",
    "            loss = criterion(logit.float(), tgt) / accum_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        step_accum += 1\n",
    "\n",
    "        if step_accum % accum_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            scheduler.step() \n",
    "            opt_steps_done += 1\n",
    "            step_accum = 0\n",
    "\n",
    "        running += float(loss.detach().cpu())\n",
    "\n",
    "        # ранняя очистка временных тензоров\n",
    "        del cats_all, labs_all, nums, tgt, logit, loss\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if step_accum > 0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        scheduler.step()\n",
    "        opt_steps_done += 1\n",
    "\n",
    "    print(f\"[RAT] Epoch {ep} train loss: {running / max(1, len(tr_loader)):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    try:\n",
    "        n_va = len(va_loader.dataset)\n",
    "    except Exception:\n",
    "        n_va = int(use_mask_va.sum())\n",
    "    va_buf = np.empty(n_va, dtype=np.float32)\n",
    "    write_ptr = 0\n",
    "\n",
    "    with torch.no_grad(), amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "        for cats_all, labs_all, nums, tgt in tqdm(va_loader, desc=f\"Epoch {ep}/{num_epochs} [valid]\"):\n",
    "            cats_all = cats_all.to(device, non_blocking=True)\n",
    "            labs_all = labs_all.to(device, non_blocking=True)\n",
    "            nums     = nums.to(device, non_blocking=True)\n",
    "\n",
    "            logit = model(cats_all, labs_all, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "\n",
    "            b = prob.shape[0]\n",
    "            va_buf[write_ptr:write_ptr + b] = prob.detach().cpu().numpy().astype(np.float32, copy=False)\n",
    "            write_ptr += b\n",
    "\n",
    "            del cats_all, labs_all, nums, logit, prob, tgt\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    va_auc = roc_auc_score(y_va[:write_ptr], va_buf[:write_ptr])\n",
    "    print(f\"[RAT] Epoch {ep}  Val AUC: {va_auc:.4f}\")\n",
    "\n",
    "    del va_buf\n",
    "    gc.collect()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Final Val AUC = 0.7280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x7efe4f4e2690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Экстракция вероятностей RAT для LGBM init_score (OOM-safe)\n",
    "# =========================\n",
    "def extract_probs_rat(ds: CTRDatasetRAT, bs=8192):\n",
    "    pin = (device.type == \"cuda\")\n",
    "    model.eval()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            dl = DataLoader(\n",
    "                ds,\n",
    "                batch_size=bs,\n",
    "                shuffle=False,\n",
    "                num_workers=0,              \n",
    "                pin_memory=pin,\n",
    "                persistent_workers=False,\n",
    "                collate_fn=rat_collate_infer,\n",
    "                prefetch_factor=None,        \n",
    "            )\n",
    "\n",
    "            n = len(ds)\n",
    "            out = np.empty(n, dtype=np.float32)\n",
    "            idx = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for cats_all, labs_all, nums in tqdm(dl, desc=f\"Extract RAT probs (bs={bs})\", leave=False, disable=True):\n",
    "                    cats_all = cats_all.to(device, non_blocking=True)\n",
    "                    labs_all = labs_all.to(device, non_blocking=True)\n",
    "                    nums     = nums.to(device, non_blocking=True)\n",
    "\n",
    "                    with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                        logit = model(cats_all, labs_all, nums)\n",
    "                    prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "                    prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "\n",
    "                    bsz = prob.shape[0]\n",
    "                    out[idx:idx+bsz] = prob.detach().cpu().numpy().astype(np.float32, copy=False)\n",
    "                    idx += bsz\n",
    "\n",
    "                    # ранняя очистка\n",
    "                    del cats_all, labs_all, nums, logit, prob\n",
    "                    if device.type == \"cuda\":\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            del dl\n",
    "            gc.collect()\n",
    "            return out[:idx]\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            msg = str(e).lower()\n",
    "            # ловим CUDA OOM/инициализацию/abort и уменьшаем батч\n",
    "            if (\"cuda\" in msg) or (\"out of memory\" in msg) or (\"initialization error\" in msg) or (\"device-side assert\" in msg):\n",
    "                if bs <= 1024:\n",
    "                    raise\n",
    "                if device.type == \"cuda\":\n",
    "                    torch.cuda.empty_cache()\n",
    "                bs = max(1024, bs // 2)\n",
    "                print(f\"[extract_probs_rat] CUDA issue: уменьшаю batch size до {bs} и повторяю…\")\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "# корректные датасеты с РЕМЭПНУТЫМИ индексами (mask-индексы)\n",
    "tr_infer_ds = CTRDatasetRAT(emb_tr, emb_tr, X_num_tr, None, retr_tr_idx_mask, y_tr)\n",
    "va_infer_ds = CTRDatasetRAT(emb_va, emb_tr, X_num_va, None, retr_va_idx_mask, y_tr)\n",
    "\n",
    "# умеренный стартовый bs; функция сама уменьшит при необходимости\n",
    "tr_probs = extract_probs_rat(tr_infer_ds, bs=8192)\n",
    "va_probs = extract_probs_rat(va_infer_ds, bs=8192)\n",
    "\n",
    "rat_val_auc = roc_auc_score(y_va, va_probs.astype(np.float32, copy=False))\n",
    "print(f\"[RAT] Final Val AUC = {rat_val_auc:.4f}\")\n",
    "\n",
    "# подчистим всё, что могло держать CUDA/память, перед LGBM\n",
    "del tr_infer_ds, va_infer_ds\n",
    "if 'tr_loader' in globals(): del tr_loader\n",
    "if 'va_loader' in globals(): del va_loader\n",
    "if 'tr_dataset' in globals(): del tr_dataset\n",
    "if 'va_dataset' in globals(): del va_dataset\n",
    "gc.collect()\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# =========================\n",
    "# LightGBM поверх RAT (init_score) + engineered фичи\n",
    "# =========================\n",
    "lgb_train_df = pd.DataFrame(index=train_df.index)\n",
    "lgb_valid_df = pd.DataFrame(index=valid_df.index)\n",
    "for c in base_cat_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"int32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"int32\")\n",
    "cat_indices = [lgb_train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "for c in num_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"float32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"float32\")\n",
    "\n",
    "def probs_to_logit(p):\n",
    "    p = np.asarray(p, dtype=np.float32)\n",
    "    p = np.clip(p, 1e-6, 1-1e-6)\n",
    "    return np.log(p/(1-p)).astype(np.float32, copy=False)\n",
    "\n",
    "tr_logit = probs_to_logit(tr_probs)\n",
    "va_logit = probs_to_logit(va_probs)\n",
    "\n",
    "dtrain = lgb.Dataset(lgb_train_df, label=y_tr, categorical_feature=cat_indices, free_raw_data=True)\n",
    "dvalid = lgb.Dataset(lgb_valid_df, label=y_va, categorical_feature=cat_indices, reference=dtrain, free_raw_data=True)\n",
    "dtrain.set_init_score(tr_logit)\n",
    "dvalid.set_init_score(va_logit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Training on GPU with init_score ...\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[200]\tvalid's auc: 0.728693\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid's auc: 0.729797\n",
      "Evaluated only: auc\n"
     ]
    }
   ],
   "source": [
    "# LightGBM поверх RAT (init_score) + engineered фичи — версия с экономией RAM и безопасными удалениями\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    max_bin=255,\n",
    "    bin_construct_sample_cnt=50_000,  \n",
    "    histogram_pool_size=256,       \n",
    "    device_type=\"cuda\",\n",
    "    gpu_device_id=0,\n",
    "    gpu_use_dp=False,             \n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "print(\"[LGBM] Training on GPU with init_score ...\")\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=150, first_metric_only=True),\n",
    "    lgb.log_evaluation(period=200),\n",
    "]\n",
    "\n",
    "# init_score и немедленно освобождаем тяжёлые копии\n",
    "dtrain.set_init_score(tr_logit)\n",
    "dvalid.set_init_score(va_logit)\n",
    "for _name in (\"lgb_train_df\", \"lgb_valid_df\"):\n",
    "    if _name in globals():\n",
    "        del globals()[_name]\n",
    "gc.collect()\n",
    "\n",
    "booster = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dvalid],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=callbacks,\n",
    "    keep_training_booster=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM over RAT] Val AUC = 0.7298\n",
      "Готово за 8510.1 c\n"
     ]
    }
   ],
   "source": [
    "feature_cols = list(base_cat_cols) + list(num_cols)\n",
    "\n",
    "def predict_raw_score_in_chunks(booster, df, cols, num_iteration=None, chunk_rows=200_000):\n",
    "    n = df.shape[0]\n",
    "    out = np.empty(n, dtype=np.float32)\n",
    "    start = 0\n",
    "    while start < n:\n",
    "        end = min(n, start + chunk_rows)\n",
    "        X_chunk = df.iloc[start:end][cols]\n",
    "        raw = booster.predict(X_chunk, raw_score=True, num_iteration=num_iteration)\n",
    "        out[start:end] = np.asarray(raw, dtype=np.float32, order=\"C\")\n",
    "        start = end\n",
    "    return out\n",
    "\n",
    "tree_raw = predict_raw_score_in_chunks(\n",
    "    booster, valid_df, feature_cols, num_iteration=booster.best_iteration, chunk_rows=200_000\n",
    ")\n",
    "\n",
    "tree_raw += va_logit\n",
    "expit(tree_raw, out=tree_raw)\n",
    "final_prob = tree_raw\n",
    "\n",
    "print(f\"[LGBM over RAT] Val AUC = {roc_auc_score(y_va, final_prob):.4f}\")\n",
    "\n",
    "del dtrain, dvalid, tree_raw, final_prob\n",
    "gc.collect()\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Готово за {time.perf_counter()-t0:.1f} c\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lgbm_cuda)",
   "language": "python",
   "name": "lgbm_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
