{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Секция \"сабмит\" - это полное решение от загрузки данных до формирования сабмита на хакатоне\n",
    "\n",
    "- Секции \"без сабмита\" - это экспериментальная работа с train, без test, без сабмитов. Там идеи и реализация\n",
    "\n",
    "- Осталное можно не смотреть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Baseline\n",
    "   - Время/календарь: weekday, hour_of_day, hour_week, hod_sin, hod_cos, wkd_sin, wkd_cos\n",
    "   - CTR (time-aware, бета-сглаживание, без утечек): C15, C16, C17, C18, C19, C20, C21 - это  фичи вида Cxx_ctr\n",
    "   - Частотность появлений: cumcount для C15–C21 → фичи Cxx_cumcount\n",
    "   - Базовые категориальные (в модели): banner_pos, device_type, device_conn_type, C1\n",
    "\n",
    "2. SOTA\n",
    "   - Время/календарь: weekday, hour_of_day, hour_week, hod_sin, hod_cos, wkd_sin, wkd_cos\n",
    "   - CTR (time-aware, бета-сглаживание, без утечек): C15–C21, site_category, app_category, banner_pos, C1, device_type, device_conn_type → *_ctr\n",
    "   - OOF-CTR (для низко/средне-кардинальных): site_category, app_category, banner_pos, C1 → *_ctr_oof\n",
    "   - Частотность появления:\n",
    "     1. cumcount для C15–C21\n",
    "     2. дополнительные cumcount для: site_id, site_domain, app_id, app_domain, device_model\n",
    "     3. logcount = log1p(cumcount) для SOLO-колонок это *_logcount\n",
    "   - Базовые категориальные (в модели): banner_pos, device_type, device_conn_type, C1, weekday, hour_of_day (кодировались как каткоды)\n",
    "\n",
    "   - Примечание: recency и кросс-признаки сознательно не добавлялись (ограничения памяти и анти-утечки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## смотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18993</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20362</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17262</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1872</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100173</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23160</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2667</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20969</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2372</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16859</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100194</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22257</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>100084</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ... device_type  \\\n",
       "0           f3845767      28905ebd  ecad2386  ...           1   \n",
       "1           f3845767      28905ebd  ecad2386  ...           1   \n",
       "2           f3845767      28905ebd  ecad2386  ...           1   \n",
       "3           9166c161      0569f928  ecad2386  ...           1   \n",
       "4           25d4cfcd      f028772b  ecad2386  ...           1   \n",
       "...              ...           ...       ...  ...         ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ...           1   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ...           1   \n",
       "40388932    6b59f079      f028772b  ecad2386  ...           1   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ...           1   \n",
       "40388934    f3845767      28905ebd  ecad2386  ...           1   \n",
       "\n",
       "         device_conn_type    C14  C15 C16   C17  C18  C19     C20  C21  \n",
       "0                       2  15706  320  50  1722    0   35      -1   79  \n",
       "1                       0  15704  320  50  1722    0   35  100084   79  \n",
       "2                       0  15704  320  50  1722    0   35  100084   79  \n",
       "3                       0  18993  320  50  2161    0   35      -1  157  \n",
       "4                       0  20362  320  50  2333    0   39      -1  157  \n",
       "...                   ...    ...  ...  ..   ...  ...  ...     ...  ...  \n",
       "40388930                0  17262  320  50  1872    3   39  100173   23  \n",
       "40388931                2  23160  320  50  2667    0   47      -1  221  \n",
       "40388932                0  20969  320  50  2372    0  813      -1   46  \n",
       "40388933                0  16859  320  50  1887    3   39  100194   23  \n",
       "40388934                0  22257  320  50  2545    0  431  100084  221  \n",
       "\n",
       "[40388935 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40388935, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'id', 'click', 'hour', 'C1', 'banner_pos', 'site_id',\n",
       "       'site_domain', 'site_category', 'app_id', 'app_domain', 'app_category',\n",
       "       'device_id', 'device_ip', 'device_model', 'device_type',\n",
       "       'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20',\n",
       "       'C21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                 float64\n",
       "id                  float64\n",
       "click                 int64\n",
       "hour                  int64\n",
       "C1                    int64\n",
       "banner_pos            int64\n",
       "site_id              object\n",
       "site_domain          object\n",
       "site_category        object\n",
       "app_id               object\n",
       "app_domain           object\n",
       "app_category         object\n",
       "device_id            object\n",
       "device_ip            object\n",
       "device_model         object\n",
       "device_type           int64\n",
       "device_conn_type      int64\n",
       "C14                   int64\n",
       "C15                   int64\n",
       "C16                   int64\n",
       "C17                   int64\n",
       "C18                   int64\n",
       "C19                   int64\n",
       "C20                   int64\n",
       "C21                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                 40228967\n",
       "id                         0\n",
       "click                      0\n",
       "hour                       0\n",
       "C1                         0\n",
       "banner_pos                 0\n",
       "site_id                    0\n",
       "site_domain                0\n",
       "site_category              0\n",
       "app_id                     0\n",
       "app_domain                 0\n",
       "app_category               0\n",
       "device_id                  0\n",
       "device_ip                  0\n",
       "device_model               0\n",
       "device_type                0\n",
       "device_conn_type           0\n",
       "C14                        0\n",
       "C15                        0\n",
       "C16                        0\n",
       "C17                        0\n",
       "C18                        0\n",
       "C19                        0\n",
       "C20                        0\n",
       "C21                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click\n",
       "0    33530927\n",
       "1     6858008\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"click\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx                   159968\n",
       "id                  40388935\n",
       "click                      2\n",
       "hour                     240\n",
       "C1                         7\n",
       "banner_pos                 7\n",
       "site_id                 4736\n",
       "site_domain             7742\n",
       "site_category             26\n",
       "app_id                  8550\n",
       "app_domain               559\n",
       "app_category              36\n",
       "device_id            2684975\n",
       "device_ip            6725249\n",
       "device_model            8249\n",
       "device_type                5\n",
       "device_conn_type           4\n",
       "C14                     2626\n",
       "C15                        8\n",
       "C16                        9\n",
       "C17                      435\n",
       "C18                        4\n",
       "C19                       68\n",
       "C20                      172\n",
       "C21                       60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hour_dt\"] = pd.to_datetime(train[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "test[\"hour_dt\"]  = pd.to_datetime(test[\"hour\"].astype(str),  format=\"%y%m%d%H\", utc=True)\n",
    "\n",
    "train[\"weekday\"]     = train[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "train[\"hour_of_day\"] = train[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "test[\"weekday\"]      = test[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "test[\"hour_of_day\"]  = test[\"hour_dt\"].dt.hour.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman(hour_of_day, CTR) = -0.230\n",
      "Spearman(weekday, CTR) = 0.571\n"
     ]
    }
   ],
   "source": [
    "for c in [\"hour_of_day\", \"weekday\"]:\n",
    "    if c in train.columns:\n",
    "        g = train.groupby(c)[\"click\"].mean().sort_index()\n",
    "        rho = pd.Series(g.index).corr(pd.Series(g.values), method=\"spearman\")\n",
    "        print(f\"Spearman({c}, CTR) = {rho:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2333</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1872</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100173</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2667</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2372</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>-1</td>\n",
       "      <td>46</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1887</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100194</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "      <td>100084</td>\n",
       "      <td>221</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...  C15 C16   C17 C18  C19  \\\n",
       "0           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "1           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "2           f3845767      28905ebd  ecad2386  ...  320  50  1722   0   35   \n",
       "3           9166c161      0569f928  ecad2386  ...  320  50  2161   0   35   \n",
       "4           25d4cfcd      f028772b  ecad2386  ...  320  50  2333   0   39   \n",
       "...              ...           ...       ...  ...  ...  ..   ...  ..  ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ...  320  50  1872   3   39   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ...  320  50  2667   0   47   \n",
       "40388932    6b59f079      f028772b  ecad2386  ...  320  50  2372   0  813   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ...  320  50  1887   3   39   \n",
       "40388934    f3845767      28905ebd  ecad2386  ...  320  50  2545   0  431   \n",
       "\n",
       "             C20  C21                   hour_dt  weekday  hour_of_day  \n",
       "0             -1   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "1         100084   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "2         100084   79 2014-10-21 00:00:00+00:00        1            0  \n",
       "3             -1  157 2014-10-21 00:00:00+00:00        1            0  \n",
       "4             -1  157 2014-10-21 00:00:00+00:00        1            0  \n",
       "...          ...  ...                       ...      ...          ...  \n",
       "40388930  100173   23 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388931      -1  221 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388932      -1   46 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388933  100194   23 2014-10-30 23:00:00+00:00        3           23  \n",
       "40388934  100084  221 2014-10-30 23:00:00+00:00        3           23  \n",
       "\n",
       "[40388935 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5\n",
    "cols_ctr = [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_day = train[\"hour_dt\"].dt.date.max()\n",
    "\n",
    "mask_past  = train[\"hour_dt\"].dt.date < last_day\n",
    "mask_valid = train[\"hour_dt\"].dt.date == last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1698596491451188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_global = train.loc[mask_past, \"click\"].mean()\n",
    "p_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...                   hour_dt  \\\n",
       "0           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "1           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "2           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "3           9166c161      0569f928  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "4           25d4cfcd      f028772b  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "...              ...           ...       ...  ...                       ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ... 2014-10-30 23:00:00+00:00   \n",
       "40388932    6b59f079      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ... 2014-10-30 23:00:00+00:00   \n",
       "40388934    f3845767      28905ebd  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "\n",
       "         weekday hour_of_day C15_ctr C16_ctr  C17_ctr  C18_ctr  C19_ctr  \\\n",
       "0              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "1              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "2              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "3              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "4              1           0     NaN     NaN      NaN      NaN      NaN   \n",
       "...          ...         ...     ...     ...      ...      ...      ...   \n",
       "40388930       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388931       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388932       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388933       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "40388934       3          23     NaN     NaN      NaN      NaN      NaN   \n",
       "\n",
       "          C20_ctr  C21_ctr  \n",
       "0             NaN      NaN  \n",
       "1             NaN      NaN  \n",
       "2             NaN      NaN  \n",
       "3             NaN      NaN  \n",
       "4             NaN      NaN  \n",
       "...           ...      ...  \n",
       "40388930      NaN      NaN  \n",
       "40388931      NaN      NaN  \n",
       "40388932      NaN      NaN  \n",
       "40388933      NaN      NaN  \n",
       "40388934      NaN      NaN  \n",
       "\n",
       "[40388935 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in cols_ctr:\n",
    "    new_col = f\"{c}_ctr\"\n",
    "    train[new_col] = np.nan\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols_ctr:\n",
    "    past = train.loc[mask_past, [c, \"click\"]]\n",
    "    shows  = past.groupby(c)[\"click\"].count()\n",
    "    clicks = past.groupby(c)[\"click\"].sum()\n",
    "\n",
    "    ctr_raw = clicks / shows\n",
    "    ctr_raw.loc[shows < m] = p_global\n",
    "\n",
    "    new_col = f\"{c}_ctr\"\n",
    "\n",
    "    train.loc[mask_valid, new_col] = train.loc[mask_valid, c].map(ctr_raw.to_dict()).fillna(p_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000072e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>8fda644b</td>\n",
       "      <td>25d4cfcd</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-21 00:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388930</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.998753e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.302971</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.267409</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999038e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>9c13b419</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.138729</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.164029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388932</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999585e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>f61eaaae</td>\n",
       "      <td>6b59f079</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.114030</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.097772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999636e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>3c4b944d</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.082037</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40388934</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.999747e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14103023</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-10-30 23:00:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.222410</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.252750</td>\n",
       "      <td>0.213928</td>\n",
       "      <td>0.164029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40388935 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx            id  click      hour    C1  banner_pos   site_id  \\\n",
       "0         1.0  1.000009e+18      0  14102100  1005           0  1fbe01fe   \n",
       "1         2.0  1.000017e+19      0  14102100  1005           0  1fbe01fe   \n",
       "2         3.0  1.000037e+19      0  14102100  1005           0  1fbe01fe   \n",
       "3         5.0  1.000068e+19      0  14102100  1005           1  fe8cc448   \n",
       "4         7.0  1.000072e+19      0  14102100  1005           0  8fda644b   \n",
       "...       ...           ...    ...       ...   ...         ...       ...   \n",
       "40388930  NaN  9.998753e+18      1  14103023  1005           1  e151e245   \n",
       "40388931  NaN  9.999038e+18      0  14103023  1005           0  85f751fd   \n",
       "40388932  NaN  9.999585e+18      0  14103023  1005           1  f61eaaae   \n",
       "40388933  NaN  9.999636e+18      1  14103023  1005           0  85f751fd   \n",
       "40388934  NaN  9.999747e+18      0  14103023  1005           0  1fbe01fe   \n",
       "\n",
       "         site_domain site_category    app_id  ...                   hour_dt  \\\n",
       "0           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "1           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "2           f3845767      28905ebd  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "3           9166c161      0569f928  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "4           25d4cfcd      f028772b  ecad2386  ... 2014-10-21 00:00:00+00:00   \n",
       "...              ...           ...       ...  ...                       ...   \n",
       "40388930    7e091613      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388931    c4e18dd6      50e219e0  9c13b419  ... 2014-10-30 23:00:00+00:00   \n",
       "40388932    6b59f079      f028772b  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "40388933    c4e18dd6      50e219e0  3c4b944d  ... 2014-10-30 23:00:00+00:00   \n",
       "40388934    f3845767      28905ebd  ecad2386  ... 2014-10-30 23:00:00+00:00   \n",
       "\n",
       "         weekday hour_of_day   C15_ctr   C16_ctr   C17_ctr   C18_ctr  \\\n",
       "0              1           0       NaN       NaN       NaN       NaN   \n",
       "1              1           0       NaN       NaN       NaN       NaN   \n",
       "2              1           0       NaN       NaN       NaN       NaN   \n",
       "3              1           0       NaN       NaN       NaN       NaN   \n",
       "4              1           0       NaN       NaN       NaN       NaN   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "40388930       3          23  0.158597  0.158331  0.302971  0.148226   \n",
       "40388931       3          23  0.158597  0.158331  0.105378  0.159072   \n",
       "40388932       3          23  0.158597  0.158331  0.114030  0.159072   \n",
       "40388933       3          23  0.158597  0.158331  0.147488  0.148226   \n",
       "40388934       3          23  0.158597  0.158331  0.222410  0.159072   \n",
       "\n",
       "           C19_ctr   C20_ctr   C21_ctr  \n",
       "0              NaN       NaN       NaN  \n",
       "1              NaN       NaN       NaN  \n",
       "2              NaN       NaN       NaN  \n",
       "3              NaN       NaN       NaN  \n",
       "4              NaN       NaN       NaN  \n",
       "...            ...       ...       ...  \n",
       "40388930  0.243136  0.267409  0.211582  \n",
       "40388931  0.138729  0.193124  0.164029  \n",
       "40388932  0.114030  0.193124  0.097772  \n",
       "40388933  0.243136  0.082037  0.211582  \n",
       "40388934  0.252750  0.213928  0.164029  \n",
       "\n",
       "[40388935 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C15_ctr filled: 1.0\n",
      "C16_ctr filled: 1.0\n",
      "C17_ctr filled: 1.0\n",
      "C18_ctr filled: 1.0\n",
      "C19_ctr filled: 1.0\n",
      "C20_ctr filled: 1.0\n",
      "C21_ctr filled: 1.0\n"
     ]
    }
   ],
   "source": [
    "# быстрый контроль: сколько заполнилось в валид-день\n",
    "for c in cols_ctr:\n",
    "    nc = f\"{c}_ctr\"\n",
    "    print(nc, \"filled:\", train.loc[mask_valid, nc].notna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_dt</th>\n",
       "      <th>click</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C15_ctr</th>\n",
       "      <th>C16_ctr</th>\n",
       "      <th>C17_ctr</th>\n",
       "      <th>C18_ctr</th>\n",
       "      <th>C19_ctr</th>\n",
       "      <th>C20_ctr</th>\n",
       "      <th>C21_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36169997</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2695</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100019</td>\n",
       "      <td>51</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.166601</td>\n",
       "      <td>0.164256</td>\n",
       "      <td>0.183651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169998</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2695</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100020</td>\n",
       "      <td>51</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.114623</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.166601</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.183651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169999</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1973</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>100148</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.181369</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.243136</td>\n",
       "      <td>0.234147</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170000</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2227</td>\n",
       "      <td>0</td>\n",
       "      <td>935</td>\n",
       "      <td>-1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.112823</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>0.119831</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.138517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36170001</th>\n",
       "      <td>2014-10-30 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2716</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.158597</td>\n",
       "      <td>0.158331</td>\n",
       "      <td>0.204518</td>\n",
       "      <td>0.148226</td>\n",
       "      <td>0.138729</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.211582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           hour_dt  click  C15  C16   C17  C18  C19     C20  \\\n",
       "36169997 2014-10-30 00:00:00+00:00      0  320   50  2695    0   35  100019   \n",
       "36169998 2014-10-30 00:00:00+00:00      0  320   50  2695    0   35  100020   \n",
       "36169999 2014-10-30 00:00:00+00:00      0  320   50  1973    3   39  100148   \n",
       "36170000 2014-10-30 00:00:00+00:00      0  320   50  2227    0  935      -1   \n",
       "36170001 2014-10-30 00:00:00+00:00      0  320   50  2716    3   47      -1   \n",
       "\n",
       "          C21   C15_ctr   C16_ctr   C17_ctr   C18_ctr   C19_ctr   C20_ctr  \\\n",
       "36169997   51  0.158597  0.158331  0.114623  0.159072  0.166601  0.164256   \n",
       "36169998   51  0.158597  0.158331  0.114623  0.159072  0.166601  0.072760   \n",
       "36169999   23  0.158597  0.158331  0.181369  0.148226  0.243136  0.234147   \n",
       "36170000   48  0.158597  0.158331  0.112823  0.159072  0.119831  0.193124   \n",
       "36170001   23  0.158597  0.158331  0.204518  0.148226  0.138729  0.193124   \n",
       "\n",
       "           C21_ctr  \n",
       "36169997  0.183651  \n",
       "36169998  0.183651  \n",
       "36169999  0.211582  \n",
       "36170000  0.138517  \n",
       "36170001  0.211582  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[mask_valid, [\"hour_dt\",\"click\"] + cols_ctr + [f\"{c}_ctr\" for c in cols_ctr]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сабмит: SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Обучение (валидация последним днём)...\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid's auc: 0.693136\n",
      "[200]\tvalid's auc: 0.694732\n",
      "[300]\tvalid's auc: 0.696154\n",
      "[400]\tvalid's auc: 0.698204\n",
      "[500]\tvalid's auc: 0.700364\n",
      "[600]\tvalid's auc: 0.701686\n",
      "[700]\tvalid's auc: 0.701683\n",
      "[800]\tvalid's auc: 0.701823\n",
      "[900]\tvalid's auc: 0.702071\n",
      "[1000]\tvalid's auc: 0.701895\n",
      "Early stopping, best iteration is:\n",
      "[885]\tvalid's auc: 0.702134\n",
      "Evaluated only: auc\n",
      "Best iteration: 885\n",
      "===> Финальное обучение на всём train (train+valid)...\n",
      "===> Предсказания...\n",
      "Сохранено: submission.csv\n",
      "Готово за 1509.4 c\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            mn, mx = df[col].min(), df[col].max()\n",
    "            if mn >= 0:\n",
    "                if mx < 2**8:    df[col] = df[col].astype(\"uint8\")\n",
    "                elif mx < 2**16: df[col] = df[col].astype(\"uint16\")\n",
    "                elif mx < 2**32: df[col] = df[col].astype(\"uint32\")\n",
    "                else:            df[col] = df[col].astype(\"uint64\")\n",
    "            else:\n",
    "                if   -2**7  <= mn < 2**7:   df[col] = df[col].astype(\"int8\")\n",
    "                elif -2**15 <= mn < 2**15:  df[col] = df[col].astype(\"int16\")\n",
    "                elif -2**31 <= mn < 2**31:  df[col] = df[col].astype(\"int32\")\n",
    "                else:                        df[col] = df[col].astype(\"int64\")\n",
    "    return df\n",
    "\n",
    "def create_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"hour_dt\"]    = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "    df[\"weekday\"]    = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "    df[\"hour_of_day\"]= df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "    df[\"hour_week\"]  = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "    df[\"hod_sin\"]    = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "    df[\"hod_cos\"]    = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "    df[\"wkd_sin\"]    = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "    df[\"wkd_cos\"]    = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "    return df\n",
    "\n",
    "def time_aware_ctr_for_train(train: pd.DataFrame, cols: list, alpha: float=10.0):\n",
    "    dates = np.sort(train[\"hour_dt\"].dt.date.unique())\n",
    "    p_gl  = float(train[\"click\"].mean())\n",
    "    outnames=[]\n",
    "    for col in cols:\n",
    "        out=f\"{col}_ctr\"; train[out]=np.nan; outnames.append(out)\n",
    "    for i,d in enumerate(dates):\n",
    "        if i==0: continue\n",
    "        m_day  = (train[\"hour_dt\"].dt.date == d)\n",
    "        m_prev = (train[\"hour_dt\"].dt.date <  d)\n",
    "        prior  = float(train.loc[m_prev, \"click\"].mean()) if m_prev.any() else p_gl\n",
    "        for col in cols:\n",
    "            stats  = train.loc[m_prev, [col,\"click\"]].groupby(col, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "            smooth = (stats[\"sum\"] + alpha*prior) / (stats[\"count\"] + alpha)\n",
    "            train.loc[m_day, f\"{col}_ctr\"] = train.loc[m_day, col].map(smooth.to_dict()).fillna(prior).astype(\"float32\")\n",
    "    for col in cols:\n",
    "        train[f\"{col}_ctr\"] = train[f\"{col}_ctr\"].fillna(p_gl).astype(\"float32\")\n",
    "    return outnames\n",
    "\n",
    "def ctr_map_from_full_train(train: pd.DataFrame, cols: list, alpha: float=10.0):\n",
    "    p = float(train[\"click\"].mean()); maps={}\n",
    "    for col in cols:\n",
    "        agg = train.groupby(col, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        maps[col] = ((agg[\"sum\"] + alpha*p) / (agg[\"count\"] + alpha)).astype(\"float32\").to_dict()\n",
    "    return maps, p\n",
    "\n",
    "def apply_ctr_map(df: pd.DataFrame, maps: dict, default_ctr: float):\n",
    "    for col, mp in maps.items():\n",
    "        out=f\"{col}_ctr\"\n",
    "        df[out] = df[col].map(mp).fillna(default_ctr).astype(\"float32\")\n",
    "\n",
    "def add_oof_ctr_train_only(train_df: pd.DataFrame, col: str, dates_sorted, mask_past, mask_valid, alpha=5.0):\n",
    "    out=f\"{col}_ctr_oof\"; train_df[out]=np.nan\n",
    "    p_gl = float(train_df.loc[mask_past,\"click\"].mean())\n",
    "    agg  = train_df.loc[mask_past,[col,\"click\"]].groupby(col)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    ctr_valid = (agg[\"sum\"] + alpha*p_gl)/(agg[\"count\"] + alpha)\n",
    "    train_df.loc[mask_valid, out] = train_df.loc[mask_valid, col].map(ctr_valid.to_dict()).fillna(p_gl)\n",
    "    for i,d in enumerate(dates_sorted):\n",
    "        if i==0: continue\n",
    "        m_day  = (train_df[\"hour_dt\"].dt.date == d)\n",
    "        m_prev = (train_df[\"hour_dt\"].dt.date <  d)\n",
    "        p_prev = float(train_df.loc[m_prev,\"click\"].mean())\n",
    "        agg_p  = train_df.loc[m_prev,[col,\"click\"]].groupby(col)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        ctr_p  = (agg_p[\"sum\"] + alpha*p_prev)/(agg_p[\"count\"] + alpha)\n",
    "        train_df.loc[m_day,out] = train_df.loc[m_day,col].map(ctr_p.to_dict()).fillna(p_prev)\n",
    "    train_df[out] = train_df[out].astype(\"float32\"); return out\n",
    "\n",
    "def cumcount_train_and_test_map(train_df: pd.DataFrame, test_df: pd.DataFrame, col: str, time_col=\"hour_dt\"):\n",
    "    tmp = train_df[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = train_df.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False).cumcount().astype(\"int32\")\n",
    "    out = f\"{col}_cumcount\"\n",
    "    train_df[out] = 0\n",
    "    train_df.loc[tmp[\"_idx\"].values, out] = cc.values\n",
    "    train_df[out] = train_df[out].astype(\"float32\")\n",
    "    freq_map = train_df.groupby(col, observed=True).size().astype(\"int32\").to_dict()\n",
    "    test_df[out] = test_df[col].map(freq_map).fillna(0).astype(\"float32\")\n",
    "    del tmp, cc, freq_map; gc.collect()\n",
    "    return out\n",
    "\n",
    "def encode_cats_threeway(tr_df, va_df, te_df, cols):\n",
    "    code_cols=[]\n",
    "    for c in cols:\n",
    "        tr_cat = tr_df[c].astype(\"category\"); va_cat = va_df[c].astype(\"category\"); te_cat = te_df[c].astype(\"category\")\n",
    "        cats = tr_cat.cat.categories.union(va_cat.cat.categories).union(te_cat.cat.categories)\n",
    "        tr_df[f\"{c}__code\"] = tr_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        va_df[f\"{c}__code\"] = va_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        te_df[f\"{c}__code\"] = te_cat.cat.set_categories(cats).cat.codes.astype(\"int32\")\n",
    "        code_cols.append(f\"{c}__code\")\n",
    "    return code_cols\n",
    "\n",
    "def main():\n",
    "    t0 = time.perf_counter()\n",
    "    train  = pd.read_csv(\"train.csv\")\n",
    "    test   = pd.read_csv(\"test.csv\")\n",
    "    sample = pd.read_csv(\"sample_submission.csv\")\n",
    "    if \"idx\" not in sample.columns:\n",
    "        raise ValueError(\"В sample_submission.csv нет колонки 'idx'.\")\n",
    "\n",
    "    # Время/календарь\n",
    "    train = create_time_features(train)\n",
    "    test  = create_time_features(test)\n",
    "\n",
    "    # Даты/маски\n",
    "    dates_sorted = np.sort(train[\"hour_dt\"].dt.date.unique())\n",
    "    if len(dates_sorted) < 2:\n",
    "        raise ValueError(\"Нужно >=2 уникальных дат в train.\")\n",
    "    last_day  = dates_sorted[-1]\n",
    "    first_day = dates_sorted[0]\n",
    "    mask_valid = (train[\"hour_dt\"].dt.date == last_day)\n",
    "    mask_train = (train[\"hour_dt\"].dt.date < last_day) & (train[\"hour_dt\"].dt.date != first_day)\n",
    "    mask_past  = (train[\"hour_dt\"].dt.date < last_day)\n",
    "\n",
    "    # CTR: time-aware (train) + map (test)\n",
    "    ctr_cols = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\",\n",
    "                            \"device_type\",\"device_conn_type\",\n",
    "                            \"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in train.columns]\n",
    "    ctr_cols_created = time_aware_ctr_for_train(train, ctr_cols, alpha=10.0)\n",
    "    ctr_maps, default_ctr = ctr_map_from_full_train(train, ctr_cols, alpha=10.0)\n",
    "    apply_ctr_map(test, ctr_maps, default_ctr)\n",
    "\n",
    "    # OOF-CTR только для low-card\n",
    "    low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in train.columns]\n",
    "    ctr_low_cols=[]\n",
    "    for c in low_card_for_ctr:\n",
    "        ctr_low_cols.append(add_oof_ctr_train_only(train, c, dates_sorted, mask_past, mask_valid, alpha=5.0))\n",
    "    maps_low, def_low = ctr_map_from_full_train(train, low_card_for_ctr, alpha=5.0)\n",
    "    for col, mp in maps_low.items():\n",
    "        out = f\"{col}_ctr_oof\"\n",
    "        test[out] = test[col].map(mp).fillna(def_low).astype(\"float32\")\n",
    "\n",
    "    # Cumcount ТОЛЬКО для C15–C21: train честный, test = train_count map\n",
    "    cumcount_cols=[]\n",
    "    for c in [x for x in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if x in train.columns]:\n",
    "        cumcount_cols.append(cumcount_train_and_test_map(train, test, c))\n",
    "\n",
    "    # Признаки\n",
    "    base_cats = [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\",\"weekday\",\"hour_of_day\"]\n",
    "    base_cats = [c for c in base_cats if c in train.columns and c in test.columns]\n",
    "    time_num_cols = [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]\n",
    "    time_num_cols = [c for c in time_num_cols if c in train.columns]\n",
    "\n",
    "    num_cols = time_num_cols + cumcount_cols + ctr_low_cols + ctr_cols_created\n",
    "\n",
    "    cols_for_tr = base_cats + num_cols + [\"click\"]\n",
    "    cols_for_te = [c for c in base_cats + num_cols if c in test.columns]\n",
    "\n",
    "    mask_drop_first = (train[\"hour_dt\"].dt.date == first_day)\n",
    "    train_df = train.loc[mask_train & ~mask_drop_first, cols_for_tr].copy()\n",
    "    valid_df = train.loc[mask_valid,                          cols_for_tr].copy()\n",
    "    test_df  = test[cols_for_te].copy()\n",
    "\n",
    "    train_df = optimize_dtypes(train_df); valid_df = optimize_dtypes(valid_df); test_df = optimize_dtypes(test_df)\n",
    "    for df in (train_df, valid_df, test_df):\n",
    "        for c in num_cols:\n",
    "            if c in df.columns:\n",
    "                df[c] = df[c].astype(\"float32\", copy=False)\n",
    "\n",
    "    cat_code_cols = encode_cats_threeway(train_df, valid_df, test_df, base_cats)\n",
    "\n",
    "    X_tr = pd.concat([train_df[cat_code_cols], train_df[num_cols]], axis=1)\n",
    "    X_va = pd.concat([valid_df[cat_code_cols], valid_df[num_cols]], axis=1)\n",
    "    X_te = pd.concat([test_df[cat_code_cols],  test_df[num_cols]],  axis=1)\n",
    "    y_tr = train_df[\"click\"].astype(np.uint8).values\n",
    "    y_va = valid_df[\"click\"].astype(np.uint8).values\n",
    "\n",
    "    cat_idx = list(range(len(cat_code_cols)))\n",
    "\n",
    "    del train, test, train_df, valid_df, test_df\n",
    "    gc.collect()\n",
    "\n",
    "    lgb_params = dict(\n",
    "        objective=\"binary\", metric=\"auc\",\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=256,             \n",
    "        max_depth=-1,\n",
    "        min_data_in_leaf=50,        \n",
    "        lambda_l2=2.0,              \n",
    "        feature_fraction=0.75,\n",
    "        bagging_fraction=0.8, bagging_freq=1,\n",
    "        max_bin=255,\n",
    "        device_type=\"cuda\", gpu_device_id=0,\n",
    "        seed=42, verbosity=-1, num_threads=-1\n",
    "    )\n",
    "\n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_idx, free_raw_data=True)\n",
    "    dvalid = lgb.Dataset(X_va, label=y_va, categorical_feature=cat_idx, reference=dtrain, free_raw_data=True)\n",
    "\n",
    "    print(\"===> Обучение (валидация последним днём)...\")\n",
    "    cb = [lgb.early_stopping(stopping_rounds=75, first_metric_only=True),\n",
    "          lgb.log_evaluation(period=100)]\n",
    "    bst = lgb.train(lgb_params, dtrain, num_boost_round=700,\n",
    "                    valid_sets=[dvalid], valid_names=[\"valid\"], callbacks=cb)\n",
    "    best_iter = bst.best_iteration or bst.current_iteration()\n",
    "    print(f\"Best iteration: {best_iter}\")\n",
    "\n",
    "    # Финальное обучение (OOM-safe, GPU→CPU fallback)\n",
    "    print(\"===> Финальное обучение на всём train (train+valid)...\")\n",
    "    try:\n",
    "        X_full = pd.concat([X_tr, X_va], axis=0, ignore_index=True)\n",
    "        y_full = np.concatenate([y_tr, y_va])\n",
    "        del dtrain, dvalid, X_tr, X_va, y_tr, y_va, bst\n",
    "        gc.collect()\n",
    "        dfull = lgb.Dataset(X_full, label=y_full, categorical_feature=cat_idx, free_raw_data=True)\n",
    "        try:\n",
    "            bst_full = lgb.train(lgb_params, dfull, num_boost_round=best_iter)\n",
    "        except Exception as e:\n",
    "            print(\"GPU OOM, fallback CPU:\", repr(e))\n",
    "            lgb_params_cpu = {**lgb_params, \"device_type\": \"cpu\"}\n",
    "            bst_full = lgb.train(lgb_params_cpu, dfull, num_boost_round=best_iter)\n",
    "        del dfull, X_full, y_full\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(\"Не удалось собрать full train, используем модель с валидации:\", repr(e))\n",
    "        bst_full = bst\n",
    "\n",
    "    print(\"===> Предсказания...\")\n",
    "    test_pred = bst_full.predict(X_te, num_iteration=best_iter).astype(\"float32\")\n",
    "\n",
    "    test_idx = pd.read_csv(\"test.csv\", usecols=[\"idx\"]) if os.path.exists(\"test.csv\") else None\n",
    "    if test_idx is not None and len(test_idx)==len(test_pred):\n",
    "        pred_df = pd.DataFrame({\"idx\": test_idx[\"idx\"].values, \"click\": test_pred})\n",
    "        submit = sample[[\"idx\"]].merge(pred_df, on=\"idx\", how=\"left\")\n",
    "    else:\n",
    "        submit = pd.DataFrame({\"idx\": sample[\"idx\"].values, \"click\": test_pred})\n",
    "\n",
    "    if submit[\"click\"].isna().any():\n",
    "        submit[\"click\"] = submit[\"click\"].fillna(float(submit[\"click\"].mean()))\n",
    "\n",
    "    submit.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Сохранено: submission.csv\")\n",
    "    print(f\"Готово за {time.perf_counter()-t0:.1f} c\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сабмит: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5432663, number of negative: 26654371\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.399629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 589\n",
      "[LightGBM] [Info] Number of data points in the train set: 32087034, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.169310 -> initscore=-1.590524\n",
      "[LightGBM] [Info] Start training from score -1.590524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.42877\n",
      "[100]\tvalid_0's binary_logloss: 0.428194\n",
      "[150]\tvalid_0's binary_logloss: 0.427182\n",
      "[200]\tvalid_0's binary_logloss: 0.426687\n",
      "[250]\tvalid_0's binary_logloss: 0.426539\n",
      "[300]\tvalid_0's binary_logloss: 0.427236\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's binary_logloss: 0.426025\n",
      "LightGBM обучался 430.57 c, best_iter = 225\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    # \"device\": \"gpu\",\n",
    "}\n",
    "\n",
    "lgb_tr = lgb.Dataset(X_tr, label=y_tr, free_raw_data=False)\n",
    "lgb_va = lgb.Dataset(X_va, label=y_va, reference=lgb_tr, free_raw_data=False)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_tr,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_va],\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(50)]\n",
    ")\n",
    "print(f\"LightGBM обучался {time.perf_counter()-t0:.2f} c, best_iter =\", model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM VAL logloss: 0.426025\n",
      "LightGBM VAL ROC-AUC: 0.672475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "p_va_lgb = model.predict(X_va, num_iteration=model.best_iteration)\n",
    "print(\"LightGBM VAL logloss:\", f\"{log_loss(y_va, p_va_lgb):.6f}\")\n",
    "print(\"LightGBM VAL ROC-AUC:\", f\"{roc_auc_score(y_va, p_va_lgb):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP + lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch import amp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "torch.backends.cudnn.benchmark = True \n",
    "t0 = time.perf_counter()\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# =========================\n",
    "# Время/календарь\n",
    "# =========================\n",
    "df[\"hour_dt\"]     = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "df[\"weekday\"]     = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "df[\"hour_of_day\"] = df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "df[\"hour_week\"]   = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "df[\"hod_sin\"]     = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"hod_cos\"]     = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"wkd_sin\"]     = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "df[\"wkd_cos\"]     = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "\n",
    "# =========================\n",
    "# Временной сплит: valid = последний день\n",
    "# =========================\n",
    "dates = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "if len(dates) < 2:\n",
    "    raise ValueError(\"Нужно >= 2 уникальных дат для валидации.\")\n",
    "last_day = dates[-1]\n",
    "first_day = dates[0]\n",
    "mask_val = (df[\"hour_dt\"].dt.date == last_day)\n",
    "mask_trn = ~mask_val\n",
    "mask_drop_first = (df[\"hour_dt\"].dt.date == first_day)\n",
    "\n",
    "y = df[\"click\"].astype(np.uint8).values\n",
    "y_tr = y[mask_trn & ~mask_drop_first]\n",
    "y_va = y[mask_val]\n",
    "\n",
    "# =========================\n",
    "# CTR (time-aware, бета-сглаживание)\n",
    "# =========================\n",
    "alpha_ctr = 5.0\n",
    "cols_ctr = [c for c in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in df.columns]\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = np.nan\n",
    "\n",
    "p_global_all  = df.loc[mask_trn, \"click\"].mean()\n",
    "p_global_past = df.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "\n",
    "# валидный день\n",
    "for c in cols_ctr:\n",
    "    past = df.loc[mask_trn & ~mask_drop_first, [c, \"click\"]]\n",
    "    agg = past.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    smooth = (agg[\"sum\"] + alpha_ctr*p_global_past) / (agg[\"count\"] + alpha_ctr)\n",
    "    df.loc[mask_val, f\"{c}_ctr\"] = df.loc[mask_val, c].map(smooth.to_dict()).fillna(p_global_past)\n",
    "\n",
    "# прошлые дни\n",
    "dates_sorted = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "for i, d in enumerate(dates_sorted):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    mask_day  = (df[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "    mask_prev = (df[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "    if not mask_day.any():\n",
    "        continue\n",
    "    p_prev = df.loc[mask_prev, \"click\"].mean()\n",
    "    for c in cols_ctr:\n",
    "        prev = df.loc[mask_prev, [c, \"click\"]]\n",
    "        agg  = prev.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        smooth = (agg[\"sum\"] + alpha_ctr*p_prev) / (agg[\"count\"] + alpha_ctr)\n",
    "        df.loc[mask_day, f\"{c}_ctr\"] = df.loc[mask_day, c].map(smooth.to_dict()).fillna(p_prev)\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = df[f\"{c}_ctr\"].fillna(p_global_all).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Cumcount (train only) + logcount\n",
    "# =========================\n",
    "def cumcount_train_only(df_in, col, time_col=\"hour_dt\"):\n",
    "    tmp = df_in[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = df_in.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False, observed=True).cumcount().astype(\"int32\")\n",
    "    out = np.zeros(len(df_in), dtype=np.float32)\n",
    "    out[tmp[\"_idx\"].values] = cc.values\n",
    "    del tmp, cc\n",
    "    gc.collect()\n",
    "    return out\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_cumcount\"] = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "\n",
    "solo_high = [c for c in [\"site_id\",\"site_domain\",\"app_id\",\"app_domain\",\"device_model\"] if c in df.columns]\n",
    "for c in solo_high:\n",
    "    cc = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "    df[f\"{c}_cumcount\"] = cc\n",
    "    df[f\"{c}_logcount\"] = np.log1p(cc).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# OOF-CTR low-card (time-aware)\n",
    "# =========================\n",
    "def add_oof_ctr_train_only(df_in, col, alpha=5.0):\n",
    "    out_col = f\"{col}_ctr_oof\"\n",
    "    df_in[out_col] = np.nan\n",
    "\n",
    "    past = df_in.loc[mask_trn & ~mask_drop_first, [col, \"click\"]]\n",
    "    agg  = past.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "    p_gl = df_in.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "    ctr_map_valid = (agg[\"sum\"] + alpha * p_gl) / (agg[\"count\"] + alpha)\n",
    "    df_in.loc[mask_val, out_col] = df_in.loc[mask_val, col].map(ctr_map_valid.to_dict()).fillna(p_gl)\n",
    "\n",
    "    for i, d in enumerate(dates_sorted):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        mask_day  = (df_in[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "        mask_prev = (df_in[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "        if not mask_day.any():\n",
    "            continue\n",
    "        p_prev = df_in.loc[mask_prev, \"click\"].mean()\n",
    "        prev = df_in.loc[mask_prev, [col, \"click\"]]\n",
    "        agg_prev = prev.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "        ctr_map = (agg_prev[\"sum\"] + alpha * p_prev) / (agg_prev[\"count\"] + alpha)\n",
    "        df_in.loc[mask_day, out_col] = df_in.loc[mask_day, col].map(ctr_map.to_dict()).fillna(p_prev)\n",
    "\n",
    "    df_in[out_col] = df_in[out_col].astype(\"float32\", copy=False)\n",
    "    gc.collect()\n",
    "    return out_col\n",
    "\n",
    "low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in df.columns]\n",
    "ctr_low_cols = [add_oof_ctr_train_only(df, c, alpha=5.0) for c in low_card_for_ctr]\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Финальный список фич\n",
    "# =========================\n",
    "base_cat_cols = [c for c in [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\"] if c in df.columns]\n",
    "time_num_cols = [c for c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"] if c in df.columns]\n",
    "\n",
    "num_cols = []\n",
    "num_cols += [f\"{c}_ctr\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in solo_high]\n",
    "num_cols += [f\"{c}_logcount\"  for c in solo_high]\n",
    "num_cols += ctr_low_cols\n",
    "num_cols += time_num_cols\n",
    "\n",
    "# =========================\n",
    "# Санитация числовых фич — никаких NaN\n",
    "# =========================\n",
    "def sanitize_numeric_features(df_whole: pd.DataFrame, cols: list, default_ctr: float):\n",
    "    for c in cols:\n",
    "        if c.endswith(\"_ctr\") or c.endswith(\"_ctr_oof\"):\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(default_ctr)\n",
    "        elif c.endswith(\"_cumcount\") or c.endswith(\"_logcount\") or c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "        else:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "\n",
    "sanitize_numeric_features(df, num_cols, default_ctr=p_global_all)\n",
    "assert not df[num_cols].isna().any().any(), \"NaN в числовых фичах после санитации\"\n",
    "\n",
    "# маски\n",
    "use_mask_tr = mask_trn & ~mask_drop_first\n",
    "use_mask_va = mask_val\n",
    "\n",
    "# =========================\n",
    "# Фреймы для LGBM (категории кодами + numeric)\n",
    "# =========================\n",
    "train_df = pd.DataFrame(index=df.index[use_mask_tr])\n",
    "valid_df = pd.DataFrame(index=df.index[use_mask_va])\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    codes = df[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
    "    train_df[c] = codes[use_mask_tr].values\n",
    "    valid_df[c] = codes[use_mask_va].values\n",
    "cat_indices = [train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    train_df[c] = df.loc[use_mask_tr, c].astype(\"float32\").values\n",
    "    valid_df[c] = df.loc[use_mask_va, c].astype(\"float32\").values\n",
    "\n",
    "y_tr = df.loc[use_mask_tr, \"click\"].astype(np.uint8).values\n",
    "y_va = df.loc[use_mask_va, \"click\"].astype(np.uint8).values\n",
    "\n",
    "# =========================\n",
    "# Подготовка данных для MLP\n",
    "#  - эмбеддинги по ID (словари из train)\n",
    "#  - числовой блок для MLP БЕЗ сырых *_cumcount (только логарифмы)\n",
    "# =========================\n",
    "emb_cols_all = [\"site_id\",\"app_id\",\"device_model\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]\n",
    "emb_cols = [c for c in emb_cols_all if c in df.columns]\n",
    "\n",
    "id_mappings = {}\n",
    "for c in emb_cols:\n",
    "    cats = pd.Series(df.loc[use_mask_tr, c].astype(str).unique())\n",
    "    id_mappings[c] = {cat: i+1 for i, cat in enumerate(cats)}\n",
    "\n",
    "emb_arrays_full = {}\n",
    "for c in emb_cols:\n",
    "    emb_arrays_full[c] = df[c].astype(str).map(id_mappings[c]).fillna(0).astype(\"int64\").values\n",
    "\n",
    "# Числовые фичи для MLP\n",
    "num_cols_mlp = []\n",
    "for c in num_cols:\n",
    "    if c.endswith(\"_cumcount\"):\n",
    "        base = c[:-9]  \n",
    "        logc = f\"{base}_logcount\"\n",
    "        if logc in df.columns:\n",
    "            if logc not in num_cols_mlp:\n",
    "                num_cols_mlp.append(logc)\n",
    "        else:\n",
    "            tmp_col = f\"{c}__log1p_tmp\"\n",
    "            df[tmp_col] = np.log1p(df[c]).astype(\"float32\")\n",
    "            num_cols_mlp.append(tmp_col)\n",
    "    else:\n",
    "        if c not in num_cols_mlp:\n",
    "            num_cols_mlp.append(c)\n",
    "\n",
    "# Массивы для MLP\n",
    "X_num_full = df[num_cols_mlp].astype(\"float32\").values\n",
    "emb_tr = [emb_arrays_full[c][use_mask_tr] for c in emb_cols]\n",
    "emb_va = [emb_arrays_full[c][use_mask_va] for c in emb_cols]\n",
    "X_num_tr = X_num_full[use_mask_tr]\n",
    "X_num_va = X_num_full[use_mask_va]\n",
    "\n",
    "assert not np.isnan(X_num_tr).any(), \"NaN в X_num_tr\"\n",
    "assert not np.isnan(X_num_va).any(), \"NaN в X_num_va\"\n",
    "\n",
    "emb_sizes = []\n",
    "for c in emb_cols:\n",
    "    n_tok = len(id_mappings[c]) + 1\n",
    "    dim = int(min(32, max(4, round(n_tok**0.25 * 8))))\n",
    "    emb_sizes.append((n_tok, dim))\n",
    "\n",
    "# =========================\n",
    "# Torch Dataset + BalancedBatchSampler + OneCycleLR + AMP\n",
    "# =========================\n",
    "class CTRDataset(Dataset):\n",
    "    def __init__(self, emb_arrays, num_array, y=None):\n",
    "        self.emb_arrays = emb_arrays\n",
    "        self.num_array = num_array\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.num_array.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        cats = [torch.tensor(a[idx], dtype=torch.long) for a in self.emb_arrays]\n",
    "        nums = torch.tensor(self.num_array[idx], dtype=torch.float32)\n",
    "        if self.y is None:\n",
    "            return cats, nums\n",
    "        else:\n",
    "            return cats, nums, torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, y_array, batch_size, pos_frac, num_batches, seed=42):\n",
    "        self.y = y_array\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pos_bs = max(1, int(round(batch_size * pos_frac)))\n",
    "        self.neg_bs = self.batch_size - self.pos_bs\n",
    "        self.num_batches = int(num_batches)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.pos_idx = np.where(self.y == 1)[0]\n",
    "        self.neg_idx = np.where(self.y == 0)[0]\n",
    "        if len(self.pos_idx) == 0 or len(self.neg_idx) == 0:\n",
    "            raise ValueError(\"Нет положительных или отрицательных примеров.\")\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            pos = self.rng.choice(self.pos_idx, size=self.pos_bs, replace=True)\n",
    "            neg = self.rng.choice(self.neg_idx, size=self.neg_bs, replace=True)\n",
    "            idx = np.concatenate([pos, neg])\n",
    "            self.rng.shuffle(idx)\n",
    "            yield idx.tolist()\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "tr_dataset = CTRDataset(emb_tr, X_num_tr, y_tr)\n",
    "va_dataset = CTRDataset(emb_va, X_num_va, y_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6291a1b4242e4334b49de9cea50cae98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [train]:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 1 train loss: 0.5275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1139de25fe974ba58a28f54679a86179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [valid]:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 1  Val AUC: 0.7162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e01bbe822f440ca58c3645040d7ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [train]:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 2 train loss: 0.4971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7e9a7472dd4a45baa46ef1898dfebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [valid]:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 2  Val AUC: 0.7237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc985fd347b4215aba9658b8dc87d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [train]:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 3 train loss: 0.4947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ba5b33cd7a4afe8faf7233e4f85a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [valid]:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Epoch 3  Val AUC: 0.7251\n"
     ]
    }
   ],
   "source": [
    "target_pos_frac = 0.25\n",
    "bs_train = 16384\n",
    "\n",
    "epoch_samples = min(len(y_tr), 5_000_000)\n",
    "num_batches = math.ceil(epoch_samples / bs_train)\n",
    "\n",
    "balanced_sampler = BalancedBatchSampler(y_tr, batch_size=bs_train, pos_frac=target_pos_frac, num_batches=num_batches)\n",
    "tr_loader = DataLoader(tr_dataset, batch_sampler=balanced_sampler,\n",
    "                       num_workers=4, prefetch_factor=1, pin_memory=True, persistent_workers=True)\n",
    "va_loader = DataLoader(va_dataset, batch_size=32768, shuffle=False,\n",
    "                       num_workers=2, prefetch_factor=1, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# =========================\n",
    "# Модель MLP\n",
    "# =========================\n",
    "class MLPEmbModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, num_dim, hidden_dims=[128,64], dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(n, d) for n, d in emb_sizes])\n",
    "        emb_total = sum(d for _, d in emb_sizes)\n",
    "        in_dim = emb_total + num_dim\n",
    "        layers = []\n",
    "        last = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(last, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            last = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.out = nn.Linear(last, 1)\n",
    "    def forward(self, cats, nums):\n",
    "        if len(self.emb_layers) > 0:\n",
    "            emb_outs = [emb(c) for emb, c in zip(self.emb_layers, cats)]\n",
    "            x = torch.cat(emb_outs + [nums], dim=1)\n",
    "        else:\n",
    "            x = nums\n",
    "        h = self.mlp(x) if len(self.mlp) > 0 else x\n",
    "        logit = self.out(h)\n",
    "        return logit, h\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPEmbModel(emb_sizes=emb_sizes, num_dim=X_num_tr.shape[1], hidden_dims=[128,64], dropout=0.2).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "total_steps = num_epochs * len(tr_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, total_steps=total_steps,\n",
    "    pct_start=0.1, div_factor=10, final_div_factor=100\n",
    ")\n",
    "scaler = amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))\n",
    "\n",
    "# =========================\n",
    "# Обучение MLP (AMP + clip grad + OneCycleLR)\n",
    "# =========================\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for cats, nums, tgt in tqdm(tr_loader, desc=f\"Epoch {ep}/{num_epochs} [train]\"):\n",
    "        cats = [c.to(device, non_blocking=True) for c in cats]\n",
    "        nums = nums.to(device, non_blocking=True)\n",
    "        tgt  = tgt.to(device, non_blocking=True).view(-1,1).float()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logit, _ = model(cats, nums)\n",
    "        loss = criterion(logit.float(), tgt)\n",
    "\n",
    "        if not torch.isfinite(loss):\n",
    "            continue\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        running += float(loss.detach().cpu())\n",
    "\n",
    "    print(f\"[MLP] Epoch {ep} train loss: {running/max(1,len(tr_loader)):.4f}\")\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_preds, val_tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for cats, nums, tgt in tqdm(va_loader, desc=f\"Epoch {ep}/{num_epochs} [valid]\"):\n",
    "            cats = [c.to(device, non_blocking=True) for c in cats]\n",
    "            nums = nums.to(device, non_blocking=True)\n",
    "            with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                logit, _ = model(cats, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            val_preds.append(prob.cpu().numpy())\n",
    "            val_tgts.append(tgt.numpy())\n",
    "\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_tgts  = np.concatenate(val_tgts)\n",
    "    if np.isnan(val_preds).any():\n",
    "        val_preds = np.nan_to_num(val_preds, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "    va_auc = roc_auc_score(val_tgts, val_preds)\n",
    "    print(f\"[MLP] Epoch {ep}  Val AUC: {va_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbae6172abef401c9b8f4e11ffd79d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract MLP probs:   0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc763d194544a18aa90c12a67a8dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract MLP probs:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f352f756700><function _MultiProcessingDataLoaderIter.__del__ at 0x7f352f756700>\n",
      "Exception ignored in: \n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f352f756700>Traceback (most recent call last):\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "\n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "    \n",
      "self._shutdown_workers()  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "\n",
      "          File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "self._shutdown_workers()if w.is_alive():\n",
      "\n",
      "     if w.is_alive():  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      " \n",
      "       if w.is_alive():  \n",
      "       ^  ^  ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f352f756700>    ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^    Traceback (most recent call last):\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "\n",
      "^      ^ self._shutdown_workers()  \n",
      "\n",
      "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "            assert self._parent_pid == os.getpid(), 'can only test a child process'  if w.is_alive(): \n",
      " \n",
      "              ^  ^ ^ ^ ^  ^^ ^^^^ ^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
      "^^^^ ^^ ^^ ^^ ^^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ \n",
      "^^ ^AssertionError^^^: ^^^can only test a child process\n",
      "^\n",
      "^^AssertionError^^: ^^can only test a child process^^\n",
      "^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Final Val AUC = 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Извлекаем вероятности MLP\n",
    "# =========================\n",
    "def extract_probs(ds, model, device, bs=32768):\n",
    "    dl = DataLoader(\n",
    "        ds, \n",
    "        batch_size=bs, \n",
    "        shuffle=False, \n",
    "        num_workers=4,            \n",
    "        prefetch_factor=1, \n",
    "        pin_memory=True, \n",
    "        persistent_workers=True    \n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    n = len(ds)\n",
    "    out = np.empty(n, dtype=np.float16)\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for cats, nums in tqdm(dl, desc=\"Extract MLP probs\"):\n",
    "            bsz = nums.shape[0]\n",
    "            cats = [c.to(device, non_blocking=True) for c in cats]\n",
    "            nums = nums.to(device, non_blocking=True)\n",
    "            with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                logit, _ = model(cats, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            out[idx:idx+bsz] = prob.cpu().to(torch.float16).numpy()\n",
    "            idx += bsz\n",
    "    return out\n",
    "\n",
    "tr_infer_ds = CTRDataset(emb_tr, X_num_tr, None)\n",
    "va_infer_ds = CTRDataset(emb_va, X_num_va, None)\n",
    "tr_probs = extract_probs(tr_infer_ds, model, device, bs=32768)\n",
    "va_probs = extract_probs(va_infer_ds, model, device, bs=32768)\n",
    "\n",
    "mlp_val_auc = roc_auc_score(y_va, va_probs.astype(np.float32))\n",
    "print(f\"[MLP] Final Val AUC = {mlp_val_auc:.4f}\")\n",
    "\n",
    "# подчистим GPU перед LGBM\n",
    "del tr_loader, va_loader, tr_dataset, va_dataset, tr_infer_ds, va_infer_ds\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Training on GPU with init_score ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Собираем фичи для LGBM (категории + num_cols)\n",
    "lgb_train_df = pd.DataFrame(index=train_df.index)\n",
    "lgb_valid_df = pd.DataFrame(index=valid_df.index)\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"int32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"int32\")\n",
    "cat_indices = [lgb_train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"float32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"float32\")\n",
    "\n",
    "# init_score = логиты MLP\n",
    "def probs_to_logit(p):\n",
    "    p = np.asarray(p, dtype=np.float32)\n",
    "    p = np.clip(p, 1e-6, 1-1e-6)\n",
    "    return np.log(p/(1-p)).astype(np.float32)\n",
    "\n",
    "tr_logit = probs_to_logit(tr_probs)\n",
    "va_logit = probs_to_logit(va_probs)\n",
    "\n",
    "dtrain = lgb.Dataset(lgb_train_df, label=y_tr, categorical_feature=cat_indices, free_raw_data=True)\n",
    "dvalid = lgb.Dataset(lgb_valid_df, label=y_va, categorical_feature=cat_indices, reference=dtrain, free_raw_data=True)\n",
    "dtrain.set_init_score(tr_logit)\n",
    "dvalid.set_init_score(va_logit)\n",
    "\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=256,\n",
    "    min_data_in_leaf=50,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    lambda_l2=1.0,\n",
    "    max_bin=255,\n",
    "    device_type=\"cuda\",\n",
    "    gpu_device_id=0,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "print(\"[LGBM] Training on GPU with init_score ...\")\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=200, first_metric_only=True),\n",
    "    lgb.log_evaluation(period=100),\n",
    "]\n",
    "booster = lgb.train(\n",
    "    params, dtrain, \n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dvalid],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ядро падает из за градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_raw = booster.predict(lgb_valid_df, raw_score=True, num_iteration=booster.best_iteration)\n",
    "final_prob = expit(tree_raw.astype(np.float32) + va_logit)\n",
    "print(f\"[LGBM over MLP] Val AUC = {roc_auc_score(y_va, final_prob):.4f}\")\n",
    "print(f\"Готово за {time.perf_counter()-t0:.1f} c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc, time, math\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch import amp\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from scipy.special import expit \n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "torch.backends.cudnn.benchmark = True\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# =========================\n",
    "# Время/календарь\n",
    "# =========================\n",
    "df[\"hour_dt\"]     = pd.to_datetime(df[\"hour\"].astype(str), format=\"%y%m%d%H\", utc=True)\n",
    "df[\"weekday\"]     = df[\"hour_dt\"].dt.weekday.astype(\"int8\")\n",
    "df[\"hour_of_day\"] = df[\"hour_dt\"].dt.hour.astype(\"int8\")\n",
    "df[\"hour_week\"]   = (df[\"weekday\"].astype(\"int16\")*24 + df[\"hour_of_day\"].astype(\"int16\")).astype(\"int16\")\n",
    "df[\"hod_sin\"]     = np.sin(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"hod_cos\"]     = np.cos(2*np.pi*df[\"hour_of_day\"]/24).astype(\"float32\")\n",
    "df[\"wkd_sin\"]     = np.sin(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "df[\"wkd_cos\"]     = np.cos(2*np.pi*df[\"weekday\"]/7).astype(\"float32\")\n",
    "\n",
    "# =========================\n",
    "# Временной сплит: valid = последний день\n",
    "# =========================\n",
    "dates = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "if len(dates) < 2:\n",
    "    raise ValueError(\"Нужно >= 2 уникальных дат для валидации.\")\n",
    "last_day  = dates[-1]\n",
    "first_day = dates[0]\n",
    "mask_val = (df[\"hour_dt\"].dt.date == last_day)\n",
    "mask_trn = ~mask_val\n",
    "mask_drop_first = (df[\"hour_dt\"].dt.date == first_day)\n",
    "\n",
    "y = df[\"click\"].astype(np.uint8).values\n",
    "y_tr = y[mask_trn & ~mask_drop_first]\n",
    "y_va = y[mask_val]\n",
    "\n",
    "# =========================\n",
    "# CTR (time-aware, бета-сглаживание)\n",
    "# =========================\n",
    "alpha_ctr = 5.0\n",
    "cols_ctr = [c for c in [\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"] if c in df.columns]\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = np.nan\n",
    "\n",
    "p_global_all  = df.loc[mask_trn, \"click\"].mean()\n",
    "p_global_past = df.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "\n",
    "# валидный день\n",
    "for c in cols_ctr:\n",
    "    past = df.loc[mask_trn & ~mask_drop_first, [c, \"click\"]]\n",
    "    agg = past.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "    smooth = (agg[\"sum\"] + alpha_ctr*p_global_past) / (agg[\"count\"] + alpha_ctr)\n",
    "    df.loc[mask_val, f\"{c}_ctr\"] = df.loc[mask_val, c].map(smooth.to_dict()).fillna(p_global_past)\n",
    "\n",
    "# прошлые дни\n",
    "dates_sorted = np.sort(df[\"hour_dt\"].dt.date.unique())\n",
    "for i, d in enumerate(dates_sorted):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    mask_day  = (df[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "    mask_prev = (df[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "    if not mask_day.any():\n",
    "        continue\n",
    "    p_prev = df.loc[mask_prev, \"click\"].mean()\n",
    "    for c in cols_ctr:\n",
    "        prev = df.loc[mask_prev, [c, \"click\"]]\n",
    "        agg  = prev.groupby(c, observed=True)[\"click\"].agg([\"count\",\"sum\"])\n",
    "        smooth = (agg[\"sum\"] + alpha_ctr*p_prev) / (agg[\"count\"] + alpha_ctr)\n",
    "        df.loc[mask_day, f\"{c}_ctr\"] = df.loc[mask_day, c].map(smooth.to_dict()).fillna(p_prev)\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_ctr\"] = df[f\"{c}_ctr\"] .fillna(p_global_all).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Cumcount (train only) + logcount\n",
    "# =========================\n",
    "def cumcount_train_only(df_in, col, time_col=\"hour_dt\"):\n",
    "    tmp = df_in[[col, time_col]].copy()\n",
    "    tmp[\"_idx\"] = df_in.index\n",
    "    tmp.sort_values(time_col, inplace=True)\n",
    "    cc = tmp.groupby(col, sort=False, observed=True).cumcount().astype(\"int32\")\n",
    "    out = np.zeros(len(df_in), dtype=np.float32)\n",
    "    out[tmp[\"_idx\"].values] = cc.values\n",
    "    del tmp, cc\n",
    "    gc.collect()\n",
    "    return out\n",
    "\n",
    "for c in cols_ctr:\n",
    "    df[f\"{c}_cumcount\"] = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "\n",
    "solo_high = [c for c in [\"site_id\",\"site_domain\",\"app_id\",\"app_domain\",\"device_model\"] if c in df.columns]\n",
    "for c in solo_high:\n",
    "    cc = cumcount_train_only(df, c, \"hour_dt\").astype(\"float32\")\n",
    "    df[f\"{c}_cumcount\"] = cc\n",
    "    df[f\"{c}_logcount\"] = np.log1p(cc).astype(\"float32\")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# OOF-CTR low-card (time-aware)\n",
    "# =========================\n",
    "def add_oof_ctr_train_only(df_in, col, alpha=5.0):\n",
    "    out_col = f\"{col}_ctr_oof\"\n",
    "    df_in[out_col] = np.nan\n",
    "\n",
    "    past = df_in.loc[mask_trn & ~mask_drop_first, [col, \"click\"]]\n",
    "    agg  = past.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "    p_gl = df_in.loc[mask_trn & ~mask_drop_first, \"click\"].mean()\n",
    "    ctr_map_valid = (agg[\"sum\"] + alpha * p_gl) / (agg[\"count\"] + alpha)\n",
    "    df_in.loc[mask_val, out_col] = df_in.loc[mask_val, col].map(ctr_map_valid.to_dict()).fillna(p_gl)\n",
    "\n",
    "    for i, d in enumerate(dates_sorted):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        mask_day  = (df_in[\"hour_dt\"].dt.date == d) & ~mask_val\n",
    "        mask_prev = (df_in[\"hour_dt\"].dt.date <  d) & ~mask_val\n",
    "        if not mask_day.any():\n",
    "            continue\n",
    "        p_prev = df_in.loc[mask_prev, \"click\"].mean()   \n",
    "        prev = df_in.loc[mask_prev, [col, \"click\"]]\n",
    "        agg_prev = prev.groupby(col, observed=True)[\"click\"].agg([\"count\", \"sum\"])\n",
    "        ctr_map = (agg_prev[\"sum\"] + alpha * p_prev) / (agg_prev[\"count\"] + alpha)\n",
    "        df_in.loc[mask_day, out_col] = df_in.loc[mask_day, col].map(ctr_map.to_dict()).fillna(p_prev)\n",
    "\n",
    "    df_in[out_col] = df_in[out_col].astype(\"float32\", copy=False)\n",
    "    gc.collect()\n",
    "    return out_col\n",
    "\n",
    "low_card_for_ctr = [c for c in [\"site_category\",\"app_category\",\"banner_pos\",\"C1\"] if c in df.columns]\n",
    "ctr_low_cols = [add_oof_ctr_train_only(df, c, alpha=5.0) for c in low_card_for_ctr]\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# Финальный список фич\n",
    "# =========================\n",
    "base_cat_cols = [c for c in [\"banner_pos\",\"device_type\",\"device_conn_type\",\"C1\"] if c in df.columns]\n",
    "time_num_cols = [c for c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"] if c in df.columns]\n",
    "\n",
    "num_cols = []\n",
    "num_cols += [f\"{c}_ctr\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in cols_ctr]\n",
    "num_cols += [f\"{c}_cumcount\" for c in solo_high]\n",
    "num_cols += [f\"{c}_logcount\"  for c in solo_high]\n",
    "num_cols += ctr_low_cols\n",
    "num_cols += time_num_cols\n",
    "\n",
    "# =========================\n",
    "# Санитация числовых фич — никаких NaN\n",
    "# =========================\n",
    "def sanitize_numeric_features(df_whole: pd.DataFrame, cols: list, default_ctr: float):\n",
    "    for c in cols:\n",
    "        if c.endswith(\"_ctr\") or c.endswith(\"_ctr_oof\"):\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(default_ctr)\n",
    "        elif c.endswith(\"_cumcount\") or c.endswith(\"_logcount\") or c in [\"hour_week\",\"hod_sin\",\"hod_cos\",\"wkd_sin\",\"wkd_cos\"]:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "        else:\n",
    "            df_whole[c] = df_whole[c].astype(\"float32\", copy=False).fillna(0.0)\n",
    "\n",
    "sanitize_numeric_features(df, num_cols, default_ctr=p_global_all)\n",
    "assert not df[num_cols].isna().any().any(), \"NaN в числовых фичах после санитации\"\n",
    "\n",
    "# маски\n",
    "use_mask_tr = mask_trn & ~mask_drop_first\n",
    "use_mask_va = mask_val\n",
    "\n",
    "# =========================\n",
    "# Фреймы для LGBM (категории кодами + numeric)\n",
    "# =========================\n",
    "train_df = pd.DataFrame(index=df.index[use_mask_tr])\n",
    "valid_df = pd.DataFrame(index=df.index[use_mask_va])\n",
    "\n",
    "for c in base_cat_cols:\n",
    "    codes = df[c].astype(\"category\").cat.codes.astype(\"int32\")\n",
    "    train_df[c] = codes[use_mask_tr].values\n",
    "    valid_df[c] = codes[use_mask_va].values\n",
    "cat_indices = [train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "\n",
    "for c in num_cols:\n",
    "    train_df[c] = df.loc[use_mask_tr, c].astype(\"float32\").values\n",
    "    valid_df[c] = df.loc[use_mask_va, c].astype(\"float32\").values\n",
    "\n",
    "y_tr = df.loc[use_mask_tr, \"click\"].astype(np.uint8).values\n",
    "y_va = df.loc[use_mask_va, \"click\"].astype(np.uint8).values\n",
    "\n",
    "# =========================\n",
    "# Подготовка данных для эмбеддингов \n",
    "# =========================\n",
    "emb_cols_all = [\"site_id\",\"app_id\",\"device_model\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"]\n",
    "emb_cols = [c for c in emb_cols_all if c in df.columns]\n",
    "\n",
    "emb_arrays_full = {}\n",
    "n_tokens_per_col = {}\n",
    "for c in emb_cols:\n",
    "    train_cats = pd.Categorical(df.loc[use_mask_tr, c]).categories\n",
    "    cat_all = pd.Categorical(df[c], categories=train_cats)\n",
    "\n",
    "    codes_i32 = cat_all.codes.astype(np.int32, copy=False)  \n",
    "    codes_i32 += 1                                      \n",
    "    emb_arrays_full[c] = codes_i32.astype(np.uint32, copy=False)\n",
    "\n",
    "    n_tokens_per_col[c] = len(train_cats) + 1 \n",
    "\n",
    "\n",
    "num_cols_mlp = []\n",
    "_seen = set()\n",
    "for c in num_cols:\n",
    "    if c.endswith(\"_cumcount\"):\n",
    "        base = c[:-9]\n",
    "        logc = f\"{base}_logcount\"\n",
    "        key = logc if logc in df.columns else c\n",
    "    else:\n",
    "        key = c\n",
    "    if key not in _seen:\n",
    "        num_cols_mlp.append(key)\n",
    "        _seen.add(key)\n",
    "\n",
    "def _col_values_for(mask: pd.Series, col: str) -> np.ndarray:\n",
    "    if col.endswith(\"_cumcount\") and f\"{col[:-9]}_logcount\" not in df.columns:\n",
    "        return np.log1p(df.loc[mask, col].to_numpy(dtype=np.float32, copy=False))\n",
    "    else:\n",
    "        return df.loc[mask, col].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "tr_cols, va_cols = [], []\n",
    "for col in num_cols_mlp:\n",
    "    tr_cols.append(_col_values_for(use_mask_tr, col).reshape(-1, 1))\n",
    "    va_cols.append(_col_values_for(use_mask_va, col).reshape(-1, 1))\n",
    "\n",
    "X_num_tr = (np.concatenate(tr_cols, axis=1).astype(np.float16, copy=False)\n",
    "            if tr_cols else np.zeros((use_mask_tr.sum(), 0), np.float16))\n",
    "X_num_va = (np.concatenate(va_cols, axis=1).astype(np.float16, copy=False)\n",
    "            if va_cols else np.zeros((use_mask_va.sum(), 0), np.float16))\n",
    "\n",
    "emb_tr = [emb_arrays_full[c][use_mask_tr] for c in emb_cols]\n",
    "emb_va = [emb_arrays_full[c][use_mask_va] for c in emb_cols]\n",
    "\n",
    "assert not np.isnan(X_num_tr).any(), \"NaN в X_num_tr\"\n",
    "assert not np.isnan(X_num_va).any(), \"NaN в X_num_va\"\n",
    "\n",
    "emb_sizes = []\n",
    "for c in emb_cols:\n",
    "    n_tok = n_tokens_per_col[c]\n",
    "    dim = int(min(32, max(4, round(n_tok**0.25 * 8))))\n",
    "    emb_sizes.append((n_tok, dim))\n",
    "\n",
    "# Оставляем в df только то, что реально понадобится дальше: время и ID для ретрива\n",
    "_df_keep = [\"hour_dt\"] + emb_cols\n",
    "_drop = [c for c in list(df.columns) if c not in _df_keep]\n",
    "if _drop:\n",
    "    df.drop(columns=_drop, inplace=True)\n",
    "\n",
    "# Освобождаем временные массивы-списки\n",
    "del tr_cols, va_cols, _seen\n",
    "gc.collect()\n",
    "\n",
    "# Поджимаем типы в LGBM-фреймах\n",
    "for c in base_cat_cols:\n",
    "    if str(train_df[c].dtype).startswith(\"int\") and train_df[c].dtype.itemsize > 2:\n",
    "        train_df[c] = train_df[c].astype(\"int16\")\n",
    "        valid_df[c] = valid_df[c].astype(\"int16\")\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RAT: Retrieval-Augmented Transformer\n",
    "# =========================\n",
    "RAT_K = 4\n",
    "RAT_MAX_PER_TOKEN = 256\n",
    "RAT_D_MODEL = 32\n",
    "RAT_NUM_BLOCKS = 2\n",
    "RAT_NUM_HEADS = 4\n",
    "RAT_DROPOUT = 0.1\n",
    "\n",
    "def _value_counts_map(series: pd.Series) -> dict:\n",
    "    vc = series.value_counts(dropna=False)\n",
    "    return {k: int(v) for k, v in vc.items()}\n",
    "\n",
    "# =========================\n",
    "# БЫСТРАЯ версия ретрива (векторизованная)\n",
    "# =========================\n",
    "def build_retrieval_indices_fast(\n",
    "    df_time_values,\n",
    "    emb_arrays_full: dict[str, np.ndarray],\n",
    "    emb_cols: list[str],\n",
    "    use_mask_tr: pd.Series,\n",
    "    use_mask_va: pd.Series,\n",
    "    K: int = 4,\n",
    "    max_per_token: int = 256,\n",
    "    top_fields: int | None = 3,\n",
    "):\n",
    "    pos = np.arange(df_time_values.shape[0])\n",
    "    pos_tr = pos[use_mask_tr.values]\n",
    "    pos_va = pos[use_mask_va.values]\n",
    "\n",
    "    t_tr = df_time_values[pos_tr].view(\"int64\")\n",
    "    order_tr = np.lexsort((pos_tr, t_tr))\n",
    "    pos_tr_sorted = pos_tr[order_tr]\n",
    "    n_tr = len(pos_tr_sorted)\n",
    "    n_va = len(pos_va)\n",
    "    if n_tr == 0:\n",
    "        return np.empty((0, K), dtype=np.int32), np.empty((n_va, K), dtype=np.int32)\n",
    "\n",
    "    codes_tr = {c: emb_arrays_full[c][use_mask_tr.values][order_tr].astype(np.int32, copy=False) for c in emb_cols}\n",
    "    codes_va = {c: emb_arrays_full[c][use_mask_va.values].astype(np.int32, copy=False) for c in emb_cols}\n",
    "\n",
    "    N = float(n_tr)\n",
    "    idf_map = {}\n",
    "    for c in emb_cols:\n",
    "        x = codes_tr[c]\n",
    "        if x.size == 0:\n",
    "            idf_map[c] = np.zeros(1, dtype=np.float32)\n",
    "            continue\n",
    "        vmax = int(x.max())\n",
    "        cnt = np.bincount(x, minlength=vmax + 1).astype(np.int32)\n",
    "        idf = np.zeros_like(cnt, dtype=np.float32)\n",
    "        nonzero = cnt > 0\n",
    "        idf[nonzero] = np.log((N - cnt[nonzero] + 0.5) / (cnt[nonzero] + 0.5)).astype(np.float32)\n",
    "        idf_map[c] = idf\n",
    "\n",
    "    from collections import deque, defaultdict\n",
    "    inv_train = {c: defaultdict(lambda: deque(maxlen=max_per_token)) for c in emb_cols}\n",
    "    inv_full  = {c: defaultdict(lambda: deque(maxlen=max_per_token)) for c in emb_cols}\n",
    "    for i in range(n_tr):\n",
    "        for c in emb_cols:\n",
    "            inv_full[c][int(codes_tr[c][i])].append(i)\n",
    "\n",
    "    retr_tr_idx = np.full((n_tr, K), -1, dtype=np.int32)\n",
    "    retr_va_idx = np.full((n_va, K), -1, dtype=np.int32)\n",
    "\n",
    "    scores = np.zeros(n_tr, dtype=np.float32)\n",
    "\n",
    "    def _pick_topk_from_touched(touched_arr):\n",
    "        if touched_arr.size == 0:\n",
    "            return []\n",
    "        s = scores[touched_arr]\n",
    "        if s.size <= K:\n",
    "            order = np.argsort(s)[::-1]\n",
    "            return touched_arr[order].tolist()\n",
    "        idxk = np.argpartition(s, -K)[-K:]\n",
    "        order = np.argsort(s[idxk])[::-1]\n",
    "        return touched_arr[idxk[order]].tolist()\n",
    "\n",
    "    def _select_cols_for_row(codes_row: dict[str, int]):\n",
    "        if top_fields is None or top_fields >= len(emb_cols):\n",
    "            return emb_cols\n",
    "        pairs = []\n",
    "        for c in emb_cols:\n",
    "            code = int(codes_row[c])\n",
    "            idf = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            pairs.append((c, idf))\n",
    "        pairs.sort(key=lambda t: t[1], reverse=True)\n",
    "        return [c for c, _ in pairs[:top_fields]]\n",
    "\n",
    "    # TRAIN: только ранее виденные\n",
    "    for i in range(n_tr):\n",
    "        touched_chunks = []\n",
    "        cols_use = _select_cols_for_row({c: codes_tr[c][i] for c in emb_cols})\n",
    "        for c in cols_use:\n",
    "            code = int(codes_tr[c][i])\n",
    "            lst = inv_train[c][code]\n",
    "            if not lst:\n",
    "                continue\n",
    "            w = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            if w == 0.0:\n",
    "                continue\n",
    "            arr = np.fromiter(lst, dtype=np.int32)\n",
    "            scores[arr] += w\n",
    "            touched_chunks.append(arr)\n",
    "        if touched_chunks:\n",
    "            touched = np.unique(np.concatenate(touched_chunks))\n",
    "            top = _pick_topk_from_touched(touched)\n",
    "            if top:\n",
    "                retr_tr_idx[i, :len(top)] = top[:K]\n",
    "            scores[touched] = 0.0\n",
    "        for c in emb_cols:\n",
    "            inv_train[c][int(codes_tr[c][i])].append(i)\n",
    "\n",
    "    for j in range(n_va):\n",
    "        touched_chunks = []\n",
    "        cols_use = _select_cols_for_row({c: codes_va[c][j] for c in emb_cols})\n",
    "        for c in cols_use:\n",
    "            code = int(codes_va[c][j])\n",
    "            lst = inv_full[c][code]\n",
    "            if not lst:\n",
    "                continue\n",
    "            w = idf_map[c][code] if code < idf_map[c].shape[0] else 0.0\n",
    "            if w == 0.0:\n",
    "                continue\n",
    "            arr = np.fromiter(lst, dtype=np.int32)\n",
    "            scores[arr] += w\n",
    "            touched_chunks.append(arr)\n",
    "        if touched_chunks:\n",
    "            touched = np.unique(np.concatenate(touched_chunks))\n",
    "            top = _pick_topk_from_touched(touched)\n",
    "            if top:\n",
    "                retr_va_idx[j, :len(top)] = top[:K]\n",
    "            scores[touched] = 0.0\n",
    "\n",
    "    return retr_tr_idx, retr_va_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retr_tr_idx, retr_va_idx = build_retrieval_indices_fast(\n",
    "    df_time_values=df[\"hour_dt\"].values,\n",
    "    emb_arrays_full=emb_arrays_full,\n",
    "    emb_cols=emb_cols,\n",
    "    use_mask_tr=use_mask_tr,\n",
    "    use_mask_va=use_mask_va,\n",
    "    K=RAT_K,\n",
    "    max_per_token=RAT_MAX_PER_TOKEN,\n",
    "    top_fields=3,\n",
    ")\n",
    "\n",
    "pos = np.arange(len(df))\n",
    "pos_tr = pos[use_mask_tr.values]\n",
    "t_tr = df[\"hour_dt\"].values[pos_tr].view(\"int64\")\n",
    "order_tr = np.lexsort((pos_tr, t_tr))\n",
    "\n",
    "def _remap_sorted_to_mask(retr_idx_sorted: np.ndarray, order_tr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Переводит индексы из пространства [0..n_tr) 'time-sorted' в индексы по маске train (исходный порядок).\"\"\"\n",
    "    out = np.full_like(retr_idx_sorted, -1)\n",
    "    m = retr_idx_sorted >= 0\n",
    "    out[m] = order_tr[retr_idx_sorted[m]]\n",
    "    return out\n",
    "\n",
    "retr_tr_idx_mask = _remap_sorted_to_mask(retr_tr_idx, order_tr)\n",
    "retr_va_idx_mask = _remap_sorted_to_mask(retr_va_idx, order_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53 min on local maschine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CTRDatasetRAT(Dataset):\n",
    "    def __init__(self, emb_target, emb_pool, num_target, y_target, retr_idx, pool_labels):\n",
    "        self.emb_target  = emb_target\n",
    "        self.emb_pool    = emb_pool\n",
    "        self.num_target  = num_target\n",
    "        self.y_target    = y_target\n",
    "        self.retr_idx    = retr_idx\n",
    "        self.pool_labels = pool_labels\n",
    "        self.F = len(emb_target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_target.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        K = self.retr_idx.shape[1]\n",
    "        cats_all = np.zeros((K+1, self.F), dtype=np.int64)\n",
    "        for f in range(self.F):\n",
    "            cats_all[0, f] = int(self.emb_target[f][idx])\n",
    "\n",
    "        retr = self.retr_idx[idx]\n",
    "        valid = (retr >= 0)\n",
    "        if valid.any():\n",
    "            rpos = np.where(valid)[0]\n",
    "            rids = retr[valid]\n",
    "            for f in range(self.F):\n",
    "                tmp = cats_all[1:, f]\n",
    "                tmp[rpos] = self.emb_pool[f][rids]\n",
    "                cats_all[1:, f] = tmp\n",
    "\n",
    "        labs_all = np.full(K+1, 2, dtype=np.int64)  # 2 = [UNK]\n",
    "        if valid.any():\n",
    "            labs_all[1:][valid] = self.pool_labels[retr[valid]].astype(np.int64)\n",
    "\n",
    "        nums = self.num_target[idx].astype(np.float32)\n",
    "\n",
    "        if self.y_target is None:\n",
    "            return cats_all, labs_all, nums\n",
    "        else:\n",
    "            y = float(self.y_target[idx])\n",
    "            return cats_all, labs_all, nums, y\n",
    "\n",
    "\n",
    "def rat_collate_train(batch):\n",
    "    cats, labs, nums, y = zip(*batch)\n",
    "    return (\n",
    "        torch.tensor(np.stack(cats), dtype=torch.long),\n",
    "        torch.tensor(np.stack(labs), dtype=torch.long),\n",
    "        torch.tensor(np.stack(nums), dtype=torch.float32),\n",
    "        torch.tensor(y, dtype=torch.float32).view(-1, 1),\n",
    "    )\n",
    "\n",
    "def rat_collate_infer(batch):\n",
    "    cats, labs, nums = zip(*batch)\n",
    "    return (\n",
    "        torch.tensor(np.stack(cats), dtype=torch.long),\n",
    "        torch.tensor(np.stack(labs), dtype=torch.long),\n",
    "        torch.tensor(np.stack(nums), dtype=torch.float32),\n",
    "    )\n",
    "\n",
    "\n",
    "class RatBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.ln3 = nn.LayerNorm(d_model)\n",
    "        self.mha_intra = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.mha_cross = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, K+1, F+1, D]\n",
    "        B, Ks, Fp, D = x.shape\n",
    "        h1 = self.ln1(x).reshape(B * Ks, Fp, D)\n",
    "        a1, _ = self.mha_intra(h1, h1, h1)\n",
    "        x = x + a1.reshape(B, Ks, Fp, D)\n",
    "\n",
    "        h2 = self.ln2(x).permute(0, 2, 1, 3).reshape(B * Fp, Ks, D)\n",
    "        a2, _ = self.mha_cross(h2, h2, h2)\n",
    "        x = x + a2.reshape(B, Fp, Ks, D).permute(0, 2, 1, 3)\n",
    "\n",
    "        x = x + self.ff(self.ln3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class RATModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, d_model, n_blocks, n_heads, d_ff=128, dropout=0.1, num_dim=0):\n",
    "        super().__init__()\n",
    "        self.F = len(emb_sizes)\n",
    "        self.embs = nn.ModuleList([nn.Embedding(n, d) for (n, d) in emb_sizes])\n",
    "        self.projs = nn.ModuleList([\n",
    "            nn.Identity() if d == d_model else nn.Linear(d, d_model, bias=False)\n",
    "            for (_, d) in emb_sizes\n",
    "        ])\n",
    "        self.label_emb = nn.Embedding(3, d_model)\n",
    "        self.blocks = nn.ModuleList([RatBlock(d_model, n_heads, d_ff, dropout) for _ in range(n_blocks)])\n",
    "        self.num_proj = nn.Identity() if num_dim == 0 else nn.Sequential(\n",
    "            nn.Linear(num_dim, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model * (2 if num_dim > 0 else 1), d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, cats_all, label_ids, nums=None):\n",
    "        B, Ks, F = cats_all.shape\n",
    "        feats = []\n",
    "        for f in range(self.F):\n",
    "            e = self.embs[f](cats_all[:, :, f])      # [B, K+1, d_f]\n",
    "            e = self.projs[f](e)                     # [B, K+1, d_model]\n",
    "            feats.append(e.unsqueeze(2))             # [B, K+1, 1, d_model]\n",
    "        feat_stack = torch.cat(feats, dim=2)         # [B, K+1, F, d_model]\n",
    "        lab = self.label_emb(label_ids).unsqueeze(2) # [B, K+1, 1, d_model]\n",
    "        x = torch.cat([lab, feat_stack], dim=2)      # [B, K+1, F+1, d_model]\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        pooled = x[:, 0, 0, :]                       # [B, d_model]\n",
    "        if nums is not None and nums.numel() > 0:\n",
    "            pooled = torch.cat([pooled, self.num_proj(nums)], dim=1)\n",
    "        return self.head(pooled)                     # [B, 1]\n",
    "\n",
    "\n",
    "# Балансировщик батчей\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, y_array, batch_size, pos_frac, num_batches, seed=42):\n",
    "        self.y = y_array\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.pos_bs = max(1, int(round(batch_size * pos_frac)))\n",
    "        self.neg_bs = self.batch_size - self.pos_bs\n",
    "        self.num_batches = int(num_batches)\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.pos_idx = np.where(self.y == 1)[0]\n",
    "        self.neg_idx = np.where(self.y == 0)[0]\n",
    "        if len(self.pos_idx) == 0 or len(self.neg_idx) == 0:\n",
    "            raise ValueError(\"Нет положительных или отрицательных примеров.\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            pos = self.rng.choice(self.pos_idx, size=self.pos_bs, replace=True)\n",
    "            neg = self.rng.choice(self.neg_idx, size=self.neg_bs, replace=True)\n",
    "            idx = np.concatenate([pos, neg])\n",
    "            self.rng.shuffle(idx)\n",
    "            yield idx.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "\n",
    "\n",
    "tr_dataset = CTRDatasetRAT(emb_tr, emb_tr, X_num_tr, y_tr, retr_tr_idx_mask, y_tr)\n",
    "va_dataset = CTRDatasetRAT(emb_va, emb_tr, X_num_va, y_va, retr_va_idx_mask, y_tr)\n",
    "\n",
    "target_pos_frac = 0.25\n",
    "bs_train = 4096                   \n",
    "epoch_samples = min(len(y_tr), 5_000_000)\n",
    "num_batches = math.ceil(epoch_samples / bs_train)\n",
    "\n",
    "balanced_sampler = BalancedBatchSampler(\n",
    "    y_tr, batch_size=bs_train, pos_frac=target_pos_frac, num_batches=num_batches\n",
    ")\n",
    "\n",
    "tr_loader = DataLoader(\n",
    "    tr_dataset, batch_sampler=balanced_sampler,\n",
    "    num_workers=0, pin_memory=False, collate_fn=rat_collate_train\n",
    ")\n",
    "\n",
    "va_loader = DataLoader(\n",
    "    va_dataset, batch_size=16384, shuffle=False,\n",
    "    num_workers=0, pin_memory=False, collate_fn=rat_collate_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RATModel(\n",
    "    emb_sizes=emb_sizes, d_model=RAT_D_MODEL, n_blocks=RAT_NUM_BLOCKS,\n",
    "    n_heads=RAT_NUM_HEADS, d_ff=128, dropout=RAT_DROPOUT, num_dim=X_num_tr.shape[1]\n",
    ").to(device)\n",
    "\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    model = model.half()\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "target_effective_bs = 8192\n",
    "accum_steps = max(1, target_effective_bs // bs_train)\n",
    "\n",
    "total_steps = (num_epochs * len(tr_loader) + accum_steps - 1) // accum_steps\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=1e-3, total_steps=total_steps,\n",
    "    pct_start=0.1, div_factor=10, final_div_factor=100\n",
    ")\n",
    "\n",
    "scaler = amp.GradScaler('cuda', enabled=(device.type == \"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2905a3a27a64fe8925ceb0d3ad4e337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [train]:   0%|          | 0/1221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 1 train loss: 0.2605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c6c62916ac4792a748e54176d5930e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [valid]:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 1  Val AUC: 0.7270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf2d71b2e46477dbad2d64e1c4a3b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [train]:   0%|          | 0/1221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 2 train loss: 0.2441\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9440a5ec68403294100f2766aa53e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [valid]:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 2  Val AUC: 0.7324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a643f616d547dfb73fe48c6244487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [train]:   0%|          | 0/1221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 3 train loss: 0.2431\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9338fc30834712abe18da6ae3965ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [valid]:   0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RAT] Epoch 3  Val AUC: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Обучение RAT \n",
    "# =========================\n",
    "\n",
    "model = model.to(device).float()\n",
    "\n",
    "_non_fp32 = []\n",
    "for n, p in model.named_parameters():\n",
    "    if p.is_floating_point() and p.dtype != torch.float32:\n",
    "        _non_fp32.append((f\"param:{n}\", str(p.dtype)))\n",
    "for n, b in model.named_buffers():\n",
    "    if b.is_floating_point() and b.dtype != torch.float32:\n",
    "        _non_fp32.append((f\"buffer:{n}\", str(b.dtype)))\n",
    "if _non_fp32:\n",
    "    print(\"WARN: upcasting non-FP32 tensors:\", _non_fp32)\n",
    "\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    scaler = amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "steps_per_epoch_eff = math.ceil(len(tr_loader) / max(1, accum_steps))\n",
    "try:\n",
    "    del scheduler\n",
    "except NameError:\n",
    "    pass\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch_eff,\n",
    "    pct_start=0.1,\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=100.0,\n",
    ")\n",
    "\n",
    "for ep in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    step_accum = 0\n",
    "    opt_steps_done = 0\n",
    "\n",
    "    for it, (cats_all, labs_all, nums, tgt) in enumerate(\n",
    "        tqdm(tr_loader, desc=f\"Epoch {ep}/{num_epochs} [train]\"), start=1\n",
    "    ):\n",
    "        cats_all = cats_all.to(device, non_blocking=True)\n",
    "        labs_all = labs_all.to(device, non_blocking=True)\n",
    "        nums     = nums.to(device, non_blocking=True)\n",
    "        tgt      = tgt.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "            logit = model(cats_all, labs_all, nums)\n",
    "            loss = criterion(logit.float(), tgt) / accum_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        step_accum += 1\n",
    "\n",
    "        if step_accum % accum_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            scheduler.step() \n",
    "            opt_steps_done += 1\n",
    "            step_accum = 0\n",
    "\n",
    "        running += float(loss.detach().cpu())\n",
    "\n",
    "        # ранняя очистка временных тензоров\n",
    "        del cats_all, labs_all, nums, tgt, logit, loss\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if step_accum > 0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        scheduler.step()\n",
    "        opt_steps_done += 1\n",
    "\n",
    "    print(f\"[RAT] Epoch {ep} train loss: {running / max(1, len(tr_loader)):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    try:\n",
    "        n_va = len(va_loader.dataset)\n",
    "    except Exception:\n",
    "        n_va = int(use_mask_va.sum())\n",
    "    va_buf = np.empty(n_va, dtype=np.float32)\n",
    "    write_ptr = 0\n",
    "\n",
    "    with torch.no_grad(), amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "        for cats_all, labs_all, nums, tgt in tqdm(va_loader, desc=f\"Epoch {ep}/{num_epochs} [valid]\"):\n",
    "            cats_all = cats_all.to(device, non_blocking=True)\n",
    "            labs_all = labs_all.to(device, non_blocking=True)\n",
    "            nums     = nums.to(device, non_blocking=True)\n",
    "\n",
    "            logit = model(cats_all, labs_all, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "\n",
    "            b = prob.shape[0]\n",
    "            va_buf[write_ptr:write_ptr + b] = prob.detach().cpu().numpy().astype(np.float32, copy=False)\n",
    "            write_ptr += b\n",
    "\n",
    "            del cats_all, labs_all, nums, logit, prob, tgt\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    va_auc = roc_auc_score(y_va[:write_ptr], va_buf[:write_ptr])\n",
    "    print(f\"[RAT] Epoch {ep}  Val AUC: {va_auc:.4f}\")\n",
    "\n",
    "    del va_buf\n",
    "    gc.collect()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a10b5145e47e59c46347f23f4a025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extract RAT probs:   0%|          | 0/980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc8d0156700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: terminate called after throwing an instance of 'c10::Error'\n",
      "  what():  CUDA error: initialization error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Exception raised from c10_cuda_check_implementation at /pytorch/c10/cuda/CUDAException.cpp:43 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fc973d785e8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xe0 (0x7fc973d0d4a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3c2 (0x7fc9804a62a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: c10::cuda::ExchangeDevice(signed char) + 0x9a (0x7fc9804a665a in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: <unknown function> + 0xb3bfde (0x7fc90953bfde in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xb38cab (0x7fc909538cab in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xb3f5f4 (0x7fc90953f5f4 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x456ea2 (0x7fc972e56ea2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7fc973d52f39 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #9: <unknown function> + 0x7158d8 (0x7fc9731158d8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #10: <unknown function> + 0x715cf1 (0x7fc973115cf1 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #11: /home/misha/tensorflow_env/bin/python() [0x579db8]\n",
      "frame #12: /home/misha/tensorflow_env/bin/python() [0x50b588]\n",
      "frame #13: /home/misha/tensorflow_env/bin/python() [0x6327e7]\n",
      "frame #14: /home/misha/tensorflow_env/bin/python() [0x514dae]\n",
      "frame #15: /home/misha/tensorflow_env/bin/python() [0x5c0122]\n",
      "frame #16: /home/misha/tensorflow_env/bin/python() [0x518c18]\n",
      "frame #17: PyObject_Call + 0x1c3 (0x56b193 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #18: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #19: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #20: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #21: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #22: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #23: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #25: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #26: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #27: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #28: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #29: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #30: PyObject_CallOneArg + 0x42 (0x5636e2 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #31: /home/misha/tensorflow_env/bin/python() [0x5ddf16]\n",
      "frame #32: PyObject_GetIter + 0x13 (0x514a13 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1970 (0x52d370 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #34: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #35: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #36: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #37: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #38: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #39: _PyObject_FastCallDictTstate + 0x2e6 (0x51fb46 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #40: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #41: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #43: PyEval_EvalCode + 0xbb (0x523fab in /home/misha/tensorflow_env/bin/python)\n",
      "frame #44: /home/misha/tensorflow_env/bin/python() [0x58f3ce]\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x3c78 (0x52f678 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #46: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #47: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #48: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #50: /home/misha/tensorflow_env/bin/python() [0x6442da]\n",
      "frame #51: /home/misha/tensorflow_env/bin/python() [0x644db8]\n",
      "frame #52: _PyEval_EvalFrameDefault + 0x375d (0x52f15d in /home/misha/tensorflow_env/bin/python)\n",
      "frame #53: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #54: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #55: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #56: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #57: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #58: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #59: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #60: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #61: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #62: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "\n",
      "terminate called after throwing an instance of 'c10::Error'\n",
      "  what():  CUDA error: initialization error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Exception raised from c10_cuda_check_implementation at /pytorch/c10/cuda/CUDAException.cpp:43 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fc973d785e8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xe0 (0x7fc973d0d4a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3c2 (0x7fc9804a62a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: c10::cuda::ExchangeDevice(signed char) + 0x9a (0x7fc9804a665a in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: <unknown function> + 0xb3bfde (0x7fc90953bfde in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xb38cab (0x7fc909538cab in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xb3f5f4 (0x7fc90953f5f4 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x456ea2 (0x7fc972e56ea2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7fc973d52f39 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #9: <unknown function> + 0x7158d8 (0x7fc9731158d8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #10: <unknown function> + 0x715cf1 (0x7fc973115cf1 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #11: /home/misha/tensorflow_env/bin/python() [0x579db8]\n",
      "frame #12: /home/misha/tensorflow_env/bin/python() [0x50b588]\n",
      "frame #13: /home/misha/tensorflow_env/bin/python() [0x6327e7]\n",
      "frame #14: /home/misha/tensorflow_env/bin/python() [0x514dae]\n",
      "frame #15: /home/misha/tensorflow_env/bin/python() [0x5c0122]\n",
      "frame #16: /home/misha/tensorflow_env/bin/python() [0x518c18]\n",
      "frame #17: PyObject_Call + 0x1c3 (0x56b193 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #18: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #19: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #20: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #21: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #22: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #23: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #25: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #26: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #27: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #28: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #29: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #30: PyObject_CallOneArg + 0x42 (0x5636e2 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #31: /home/misha/tensorflow_env/bin/python() [0x5ddf16]\n",
      "frame #32: PyObject_GetIter + 0x13 (0x514a13 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1970 (0x52d370 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #34: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #35: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #36: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #37: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #38: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #39: _PyObject_FastCallDictTstate + 0x2e6 (0x51fb46 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #40: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #41: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #43: PyEval_EvalCode + 0xbb (0x523fab in /home/misha/tensorflow_env/bin/python)\n",
      "frame #44: /home/misha/tensorflow_env/bin/python() [0x58f3ce]\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x3c78 (0x52f678 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #46: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #47: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #48: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #50: /home/misha/tensorflow_env/bin/python() [0x6442da]\n",
      "frame #51: /home/misha/tensorflow_env/bin/python() [0x644db8]\n",
      "frame #52: _PyEval_EvalFrameDefault + 0x375d (0x52f15d in /home/misha/tensorflow_env/bin/python)\n",
      "frame #53: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #54: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #55: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #56: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #57: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #58: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #59: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #60: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #61: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #62: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fc8d0156700>\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 324694) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1283\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 324694) is killed by signal: Aborted. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m tr_infer_ds \u001b[38;5;241m=\u001b[39m CTRDatasetRAT(emb_tr, emb_tr, X_num_tr, \u001b[38;5;28;01mNone\u001b[39;00m, retr_tr_idx_mask, y_tr)\n\u001b[1;32m     27\u001b[0m va_infer_ds \u001b[38;5;241m=\u001b[39m CTRDatasetRAT(emb_va, emb_tr, X_num_va, \u001b[38;5;28;01mNone\u001b[39;00m, retr_va_idx_mask, y_tr)\n\u001b[0;32m---> 29\u001b[0m tr_probs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_probs_rat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_infer_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32768\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m va_probs \u001b[38;5;241m=\u001b[39m extract_probs_rat(va_infer_ds, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32768\u001b[39m)\n\u001b[1;32m     32\u001b[0m rat_val_auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_va, va_probs\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mextract_probs_rat\u001b[0;34m(ds, bs)\u001b[0m\n\u001b[1;32m     11\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcats_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnums\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtract RAT probs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcats_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcats_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabs_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabs_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1490\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1490\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1442\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1444\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1296\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1295\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1298\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 324694) exited unexpectedly"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc8d0156700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "terminate called after throwing an instance of 'c10::Error'\n",
      "  what():  CUDA error: initialization error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Exception raised from c10_cuda_check_implementation at /pytorch/c10/cuda/CUDAException.cpp:43 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fc973d785e8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xe0 (0x7fc973d0d4a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3c2 (0x7fc9804a62a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: c10::cuda::ExchangeDevice(signed char) + 0x9a (0x7fc9804a665a in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: <unknown function> + 0xb3bfde (0x7fc90953bfde in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xb38cab (0x7fc909538cab in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xb3f5f4 (0x7fc90953f5f4 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x456ea2 (0x7fc972e56ea2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7fc973d52f39 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #9: <unknown function> + 0x7158d8 (0x7fc9731158d8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #10: <unknown function> + 0x715cf1 (0x7fc973115cf1 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #11: /home/misha/tensorflow_env/bin/python() [0x579db8]\n",
      "frame #12: /home/misha/tensorflow_env/bin/python() [0x50b588]\n",
      "frame #13: /home/misha/tensorflow_env/bin/python() [0x6327e7]\n",
      "frame #14: /home/misha/tensorflow_env/bin/python() [0x514dae]\n",
      "frame #15: /home/misha/tensorflow_env/bin/python() [0x5c0122]\n",
      "frame #16: /home/misha/tensorflow_env/bin/python() [0x518c18]\n",
      "frame #17: PyObject_Call + 0x1c3 (0x56b193 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #18: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #19: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #20: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #21: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #22: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #23: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #25: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #26: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #27: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #28: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #29: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #30: PyObject_CallOneArg + 0x42 (0x5636e2 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #31: /home/misha/tensorflow_env/bin/python() [0x5ddf16]\n",
      "frame #32: PyObject_GetIter + 0x13 (0x514a13 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1970 (0x52d370 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #34: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #35: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #36: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #37: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #38: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #39: _PyObject_FastCallDictTstate + 0x2e6 (0x51fb46 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #40: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #41: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #43: PyEval_EvalCode + 0xbb (0x523fab in /home/misha/tensorflow_env/bin/python)\n",
      "frame #44: /home/misha/tensorflow_env/bin/python() [0x58f3ce]\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x3c78 (0x52f678 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #46: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #47: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #48: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #50: /home/misha/tensorflow_env/bin/python() [0x6442da]\n",
      "frame #51: /home/misha/tensorflow_env/bin/python() [0x644db8]\n",
      "frame #52: _PyEval_EvalFrameDefault + 0x375d (0x52f15d in /home/misha/tensorflow_env/bin/python)\n",
      "frame #53: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #54: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #55: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #56: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #57: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #58: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #59: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #60: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #61: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #62: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fc8d0156700>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1662, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/misha/tensorflow_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1645, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: can only test a child process\n",
      "terminate called after throwing an instance of 'c10::Error'\n",
      "  what():  CUDA error: initialization error\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Exception raised from c10_cuda_check_implementation at /pytorch/c10/cuda/CUDAException.cpp:43 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x98 (0x7fc973d785e8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xe0 (0x7fc973d0d4a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3c2 (0x7fc9804a62a2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #3: c10::cuda::ExchangeDevice(signed char) + 0x9a (0x7fc9804a665a in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)\n",
      "frame #4: <unknown function> + 0xb3bfde (0x7fc90953bfde in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #5: <unknown function> + 0xb38cab (0x7fc909538cab in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #6: <unknown function> + 0xb3f5f4 (0x7fc90953f5f4 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\n",
      "frame #7: <unknown function> + 0x456ea2 (0x7fc972e56ea2 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7fc973d52f39 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #9: <unknown function> + 0x7158d8 (0x7fc9731158d8 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #10: <unknown function> + 0x715cf1 (0x7fc973115cf1 in /home/misha/tensorflow_env/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #11: /home/misha/tensorflow_env/bin/python() [0x579db8]\n",
      "frame #12: /home/misha/tensorflow_env/bin/python() [0x50b588]\n",
      "frame #13: /home/misha/tensorflow_env/bin/python() [0x6327e7]\n",
      "frame #14: /home/misha/tensorflow_env/bin/python() [0x514dae]\n",
      "frame #15: /home/misha/tensorflow_env/bin/python() [0x5c0122]\n",
      "frame #16: /home/misha/tensorflow_env/bin/python() [0x518c18]\n",
      "frame #17: PyObject_Call + 0x1c3 (0x56b193 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #18: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #19: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #20: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #21: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #22: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #23: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #25: _PyObject_FastCallDictTstate + 0x1c7 (0x51fa27 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #26: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #27: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #28: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #29: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #30: PyObject_CallOneArg + 0x42 (0x5636e2 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #31: /home/misha/tensorflow_env/bin/python() [0x5ddf16]\n",
      "frame #32: PyObject_GetIter + 0x13 (0x514a13 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #33: _PyEval_EvalFrameDefault + 0x1970 (0x52d370 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #34: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #35: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #36: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #37: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #38: _PyFunction_Vectorcall + 0x191 (0x55d961 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #39: _PyObject_FastCallDictTstate + 0x2e6 (0x51fb46 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #40: /home/misha/tensorflow_env/bin/python() [0x5666d3]\n",
      "frame #41: _PyObject_MakeTpCall + 0x1c5 (0x518855 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #42: _PyEval_EvalFrameDefault + 0x8f0 (0x52c2f0 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #43: PyEval_EvalCode + 0xbb (0x523fab in /home/misha/tensorflow_env/bin/python)\n",
      "frame #44: /home/misha/tensorflow_env/bin/python() [0x58f3ce]\n",
      "frame #45: _PyEval_EvalFrameDefault + 0x3c78 (0x52f678 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #46: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #47: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #48: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #50: /home/misha/tensorflow_env/bin/python() [0x6442da]\n",
      "frame #51: /home/misha/tensorflow_env/bin/python() [0x644db8]\n",
      "frame #52: _PyEval_EvalFrameDefault + 0x375d (0x52f15d in /home/misha/tensorflow_env/bin/python)\n",
      "frame #53: /home/misha/tensorflow_env/bin/python() [0x585e54]\n",
      "frame #54: /home/misha/tensorflow_env/bin/python() [0x584ec4]\n",
      "frame #55: PyObject_Call + 0xb1 (0x56b081 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #56: _PyEval_EvalFrameDefault + 0x494e (0x53034e in /home/misha/tensorflow_env/bin/python)\n",
      "frame #57: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #58: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #59: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #60: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #61: PyIter_Send + 0xe0 (0x5de810 in /home/misha/tensorflow_env/bin/python)\n",
      "frame #62: _PyEval_EvalFrameDefault + 0x5156 (0x530b56 in /home/misha/tensorflow_env/bin/python)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# Экстракция вероятностей RAT для LGBM init_score\n",
    "# =========================\n",
    "def extract_probs_rat(ds: CTRDatasetRAT, bs=32768):\n",
    "    dl = DataLoader(ds, batch_size=bs, shuffle=False, num_workers=4,\n",
    "                    prefetch_factor=1, pin_memory=True, persistent_workers=True,\n",
    "                    collate_fn=rat_collate_infer)\n",
    "    model.eval()\n",
    "    n = len(ds)\n",
    "    out = np.empty(n, dtype=np.float16)\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for cats_all, labs_all, nums in tqdm(dl, desc=\"Extract RAT probs\"):\n",
    "            cats_all = cats_all.to(device, non_blocking=True)\n",
    "            labs_all = labs_all.to(device, non_blocking=True)\n",
    "            nums     = nums.to(device, non_blocking=True)\n",
    "            with amp.autocast('cuda', enabled=(device.type == \"cuda\")):\n",
    "                logit = model(cats_all, labs_all, nums)\n",
    "            prob = torch.sigmoid(logit.float()).squeeze(1)\n",
    "            prob = torch.nan_to_num(prob, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "            bsz = prob.shape[0]\n",
    "            out[idx:idx+bsz] = prob.cpu().to(torch.float16).numpy()\n",
    "            idx += bsz\n",
    "    return out\n",
    "\n",
    "tr_infer_ds = CTRDatasetRAT(emb_tr, emb_tr, X_num_tr, None, retr_tr_idx_mask, y_tr)\n",
    "va_infer_ds = CTRDatasetRAT(emb_va, emb_tr, X_num_va, None, retr_va_idx_mask, y_tr)\n",
    "\n",
    "tr_probs = extract_probs_rat(tr_infer_ds, bs=32768)\n",
    "va_probs = extract_probs_rat(va_infer_ds, bs=32768)\n",
    "\n",
    "rat_val_auc = roc_auc_score(y_va, va_probs.astype(np.float32))\n",
    "print(f\"[RAT] Final Val AUC = {rat_val_auc:.4f}\")\n",
    "\n",
    "del tr_loader, va_loader, tr_dataset, va_dataset, tr_infer_ds, va_infer_ds\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# =========================\n",
    "# LightGBM поверх RAT (init_score) + engineered фичи\n",
    "# =========================\n",
    "lgb_train_df = pd.DataFrame(index=train_df.index)\n",
    "lgb_valid_df = pd.DataFrame(index=valid_df.index)\n",
    "for c in base_cat_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"int32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"int32\")\n",
    "cat_indices = [lgb_train_df.columns.get_loc(c) for c in base_cat_cols]\n",
    "for c in num_cols:\n",
    "    lgb_train_df[c] = train_df[c].astype(\"float32\")\n",
    "    lgb_valid_df[c] = valid_df[c].astype(\"float32\")\n",
    "\n",
    "def probs_to_logit(p):\n",
    "    p = np.asarray(p, dtype=np.float32)\n",
    "    p = np.clip(p, 1e-6, 1-1e-6)\n",
    "    return np.log(p/(1-p)).astype(np.float32)\n",
    "\n",
    "tr_logit = probs_to_logit(tr_probs)\n",
    "va_logit = probs_to_logit(va_probs)\n",
    "\n",
    "dtrain = lgb.Dataset(lgb_train_df, label=y_tr, categorical_feature=cat_indices, free_raw_data=True)\n",
    "dvalid = lgb.Dataset(lgb_valid_df, label=y_va, categorical_feature=cat_indices, reference=dtrain, free_raw_data=True)\n",
    "dtrain.set_init_score(tr_logit)\n",
    "dvalid.set_init_score(va_logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Training on GPU with init_score ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] CUDA Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_CUDA=1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "CUDA Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_CUDA=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LGBM] Training on GPU with init_score ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, first_metric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     20\u001b[0m     lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m),\n\u001b[1;32m     21\u001b[0m ]\n\u001b[0;32m---> 22\u001b[0m booster \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m tree_raw \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(lgb_valid_df, raw_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_iteration\u001b[38;5;241m=\u001b[39mbooster\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[1;32m     32\u001b[0m final_prob \u001b[38;5;241m=\u001b[39m expit(tree_raw\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m+\u001b[39m va_logit)\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/lightgbm/engine.py:297\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    299\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/lightgbm/basic.py:3660\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3658\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3659\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3660\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3663\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3665\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3666\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3667\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3668\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/tensorflow_env/lib/python3.11/site-packages/lightgbm/basic.py:313\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: CUDA Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_CUDA=1"
     ]
    }
   ],
   "source": [
    "\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=256,\n",
    "    #min_data_in_leaf=50,\n",
    "    #feature_fraction=0.8,\n",
    "    #bagging_fraction=0.8,\n",
    "    #bagging_freq=1,\n",
    "    #lambda_l2=1.0,\n",
    "    max_bin=255,\n",
    "    device_type=\"cuda\",\n",
    "    gpu_device_id=0,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "print(\"[LGBM] Training on GPU with init_score ...\")\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=150, first_metric_only=True),\n",
    "    lgb.log_evaluation(period=100),\n",
    "]\n",
    "booster = lgb.train(\n",
    "    params, \n",
    "    dtrain, \n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[dvalid], \n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=callbacks)\n",
    "\n",
    "\n",
    "tree_raw = booster.predict(lgb_valid_df, raw_score=True, num_iteration=booster.best_iteration)\n",
    "final_prob = expit(tree_raw.astype(np.float32) + va_logit)\n",
    "\n",
    "\n",
    "print(f\"[LGBM over RAT] Val AUC = {roc_auc_score(y_va, final_prob):.4f}\")\n",
    "print(f\"Готово за {time.perf_counter()-t0:.1f} c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
